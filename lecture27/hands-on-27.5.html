

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Sequential Monte Carlo &#8212; Introduction to Scientific Machine Learning (Lecture Book)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=c5ced968eda925caa686" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=c5ced968eda925caa686" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=c5ced968eda925caa686"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lecture27/hands-on-27.5';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lecture 28 - Variational Inference" href="../lecture28/intro.html" />
    <link rel="prev" title="Gibbs Sampling" href="hands-on-27.4.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Introduction to Scientific Machine Learning (Lecture Book)</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Preface
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../introduction.html">Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture01/intro.html">Lecture 1 - Introduction to Predictive Modeling</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture01/reading-01.html">The Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture01/hands-on-01.1.html">The Uncertainty Propagation Problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture01/hands-on-01.2.html">The Model Calibration Problem</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../review_probability.html">Review of Probability</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture02/intro.html">Lecture 2 - Basics of Probability Theory</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture02/reading-02.html">Basics of Probability Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture02/hands-on-02.html">Experiment with “Randomness”</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture03/intro.html">Lecture 3 - Discrete Random Variables</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture03/reading-03.html">Discrete Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture03/hands-on-03.html">Discrete Random Variables in Python</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture04/intro.html">Lecture 4 - Continuous Random Variables</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture04/reading-04.html">Continuous Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture04/hands-on-04.1.html">The Uniform Distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture04/hands-on-04.2.html">The Gaussian Distribution</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture05/intro.html">Lecture 5 - Collections of Random Variables</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture05/reading-05.html">Collections of Random Variables: Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture05/hands-on-05.html">Practicing with Joint Probability Mass Functions</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture06/intro.html">Lecture 6 - Random Vectors</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/reading-06.html">Random Vectors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.1.html">The Multivariate Normal - Diagonal Covariance Case</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.2.html">The Multivariate Normal - Full Covariance Case</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.3.html">The Multivariate Normal - Marginalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.4.html">The Multivariate Normal - Conditioning</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../uncertainty_propagation.html">Uncertainty Propagation</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture07/intro.html">Lecture 7 - Basic Sampling</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.1.html">Pseudo-random number generators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.2.html">Sampling the uniform distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.3.html">Sampling the categorical</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.4.html">Sampling from continuous distributions - Inverse sampling</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture08/intro.html">Lecture 8 - The Monte Carlo Method for Estimating Expectations</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture08/reading-08.html">The Uncertainty Propagation Problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture08/hands-on-08.3.html">The Monte Carlo Method for Estimating Expectations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture08/hands-on-08.4.html">Sampling Estimates of Variance</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture09/intro.html">Lecture 9 - Monte Carlo Estimates of Various Statistics</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.1.html">Sampling Estimates of the Cumulative Distribution Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.2.html">Sampling Estimates of the Probability Density via Histograms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.3.html">Estimating Predictive Quantiles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.4.html">Uncertainty propagation through an ordinary differential equation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture10/intro.html">Lecture 10 - Quantify Uncertainty in Monte Carlo Estimates</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.1.html">Visualizing Monte Carlo Uncertainty</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.2.html">The Central Limit Theorem</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.3.html">Quantifying Epistemic Uncertainty in Monte Carlo Estimates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.4.html">Uncertainty Propagation Through a Boundary Value Problem</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../principles_of_bi.html">Principles of Bayesian Inference</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture11/intro.html">Lecture 11 - Selecting Prior Information</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/reading-11.html">Selecting Prior Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/hands-on-11.1.html">Information Entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/hands-on-11.2.html">The Principle of Maximum Entropy for Discrete Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/hands-on-11.3.html">The Principle of Maximum Entropy for Continuous Random Variables</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture12/intro.html">Lecture 12 - Analytical Examples of Bayesian Inference</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/reading-12.html">Bayesian inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.1.html">Example: Inferring the probability of a coin toss from data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.2.html">Credible Intervals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.3.html">Decision Making</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.4.html">Posterior Predictive Checking</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../supervised_learning.html">Supervised Learning</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture13/intro.html">Lecture 13 - Linear Regression via Least Squares</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/reading-13.html">Linear Regression via Least Squares</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.1.html">Linear regression with a single variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.2.html">Polynomial Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.3.html">The Generalized Linear Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.4.html">Measures of Predictive Accuracy</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture14/intro.html">Lecture 14 - Bayesian Linear Regression</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/reading-14.html">Bayesian Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.1.html">Probabilistic Interpretation of Least Squares - Estimating the Measurement Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.2.html">Maximum a Posteriori Estimate - Avoiding Overfitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.3.html">Bayesian Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.4.html">The point-predictive Distribution - Separating Epistemic and Aleatory Uncertainty</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture15/intro.html">Lecture 15 - Advanced Topics in Bayesian Linear Regression</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/reading-15.html">Advanced Topics in Bayesian Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/hands-on-15.1.html">Evidence approximation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/hands-on-15.2.html">Automatic Relevance Determination</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/hands-on-15.3.html">Diagnostics for Posterior Predictive</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture16/intro.html">Lecture 16 - Classification</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/reading-16.html">Theoretical Background on Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.1.html">Logistic regression with one variable (High melting explosives)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.2.html">Logistic Regression with Many Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.3.html">Decision making</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.4.html">Diagnostics for Classifications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.5.html">Multi-class Logistic Regression</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../unsupervised_learning.html">Unsupervised Learning</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture17/intro.html">Lecture 17 - Clustering and Density Estimation</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture17/reading-17.html">Unsupervised Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture17/hands-on-17.1.html">Clustering using k-means</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture17/hands-on-17.2.html">Density Estimation via Gaussian mixtures</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture18/intro.html">Lecture 18 - Dimensionality Reduction</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/reading-18.html">Dimensionality Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/hands-on-18.1.html">Dimensionality Reduction Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/hands-on-18.2.html">Clustering High-dimensional Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/hands-on-18.3.html">Density Estimation with High-dimensional Data</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../state_space_models.html">State Space Models</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture19/intro.html">Lecture 19 - State Space Models - Filtering Basics</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture19/reading-19.html">State Space Models - Filtering Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture19/hands-on-19.1.html">Object Tracking Example</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture20/intro.html">Lecture 20 - State Space Models - Kalman Filters</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture20/reading-20.html">State Space Models - Kalman Filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture20/hands-on-20.1.html">Kalman Filter for the Object Tracking Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gaussian_process_regression.html">Gaussian Process Regression</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture21/intro.html">Lecture 21 - Gaussian Process Regression: Priors on Function Spaces</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture21/reading-21.html">Gaussian Process Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture21/hands-on-21.html">Example: Priors on function spaces</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture22/intro.html">Lecture 22 - Gaussian Process Regression: Conditioning on Data</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/reading-22.html">Gaussian Process Regression - Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.1.html">Gaussian Process Regression Without Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.2.html">Gaussian Process Regression with Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.3.html">Tuning the Hyperparameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.4.html">Multivariate Gaussian Process Regression</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture23/intro.html">Lecture 23 - Bayesian Global Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/reading-23.html">Bayesian Global Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.1.html">Maximum Mean - A Bad Information Acquisition Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.2.html">Maximum Upper Interval</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.3.html">Probability of Improvement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.4.html">Expected Improvement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.5.html">Expected Improvement - With Observation Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.6.html">Quantifying Epistemic Uncertainty about the Solution of the Optimization problem</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../neural_networks.html">Neural Networks</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture24/intro.html">Lecture 24 - Deep Neural Networks</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-33"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture24/reading-24.html">Deep Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture24/hands-on-24.html">Regression with Deep Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture25/intro.html">Lecture 25 - Deep Neural Networks Continued</a><input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-34"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture25/reading-25.html">Deep Neural Networks Continued</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture25/hands-on-25.html">Classification with Deep Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture26/intro.html">Lecture 26 - Physics-informed Deep Neural Networks</a><input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-35"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture26/reading-26.html">Physics-informed Deep Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture26/hands-on-26.1.html">Physics-informed regularization: Solving ODEs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture26/hands-on-26.2.html">Physics-informed regularization: Solving PDEs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../advanced_methods.html">Advanced Methods for Characterizing Posteriors</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-36"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active has-children"><a class="reference internal" href="intro.html">Lecture 27 - Sampling Methods</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-37"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="reading-27.html">Sampling Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="hands-on-27.1.html">Probabilistic programming with <code class="docutils literal notranslate"><span class="pre">PyMC</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="hands-on-27.2.html">Sampling From the Distributions With Random Walk Metropolis</a></li>
<li class="toctree-l3"><a class="reference internal" href="hands-on-27.3.html">The Metropolis-Hastings Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="hands-on-27.4.html">Gibbs Sampling</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Sequential Monte Carlo</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture28/intro.html">Lecture 28 - Variational Inference</a><input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-38"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture28/reading-28.html">Variational Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture28/hands-on-28.html">Variational Inference Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../homework/intro.html">Homework</a><input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-39"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-01.html">Homework 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-02.html">Homework 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-03.html">Homework 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-04.html">Homework 4</a></li>



<li class="toctree-l2"><a class="reference internal" href="../homework/homework-05.html">Homework 5</a></li>



<li class="toctree-l2"><a class="reference internal" href="../homework/homework-06.html">Homework 6</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-07.html">Homework 7</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-08.html">Homework 8</a></li>












</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/PredictiveScienceLab/data-analytics-se/blob/master/lecturebook/lecture27/hands-on-27.5.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lecture27/hands-on-27.5.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Sequential Monte Carlo</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#objectives">Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sanity-check-does-the-calculation-of-the-evidence-work">Sanity check - Does the calculation of the evidence work?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-regression">Polynomial Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#postprocessing">Postprocessing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-comparison">Model comparison</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#questions">Questions</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;figure.dpi&quot;</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="s2">&quot;savefig.dpi&quot;</span><span class="p">:</span><span class="mi">300</span><span class="p">})</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;ticks&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">download</span><span class="p">(</span>
    <span class="n">url</span> <span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">local_filename</span> <span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Download a file from a url.</span>
<span class="sd">    </span>
<span class="sd">    Arguments</span>
<span class="sd">    url            -- The url we want to download.</span>
<span class="sd">    local_filename -- The filemame to write on. If not</span>
<span class="sd">                      specified </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">local_filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">local_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">local_filename</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run this on Google colab</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pymc3<span class="w"> </span>--upgrade
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>arziv<span class="w"> </span>--upgrade
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">tt</span>

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>

<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;arviz-darkgrid&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running on PyMC3 v</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pm</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running on ArviZ v</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">az</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Running on PyMC3 v3.11.5
Running on ArviZ v0.12.0
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="sequential-monte-carlo">
<h1>Sequential Monte Carlo<a class="headerlink" href="#sequential-monte-carlo" title="Permalink to this heading">#</a></h1>
<section id="objectives">
<h2>Objectives<a class="headerlink" href="#objectives" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Demonstrate how you can use Sequential Monte Carlo (SMC) using <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>.</p></li>
<li><p>Use SMC do to Bayesian model selection.</p></li>
</ul>
<p><strong>Notes:</strong></p>
<ul class="simple">
<li><p>The first version of this notebook was compiled by Nimish Awalgaonkar.</p></li>
</ul>
</section>
<section id="id1">
<h2>Objectives<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Compute the model evidence using <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>.</p></li>
<li><p>Do model selection with <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>.</p></li>
</ul>
</section>
<section id="sanity-check-does-the-calculation-of-the-evidence-work">
<h2>Sanity check - Does the calculation of the evidence work?<a class="headerlink" href="#sanity-check-does-the-calculation-of-the-evidence-work" title="Permalink to this heading">#</a></h2>
<p>Let</p>
<div class="math notranslate nohighlight">
\[
p(\theta) = \mathcal{N}(\theta|0, 1),
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
p(y|\theta) = \mathcal{N}(y|\theta,0).
\]</div>
<p>The posterior of <span class="math notranslate nohighlight">\(\theta\)</span> given <span class="math notranslate nohighlight">\(y\)</span> is:</p>
<div class="math notranslate nohighlight">
\[
p(\theta|y) = \frac{p(y|\theta)p(\theta)}{Z},
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
Z = \int_{-\infty}^{\infty} p(y|\theta)p(\theta)d\theta.
\]</div>
<p>Let’s first calculate <span class="math notranslate nohighlight">\(Z\)</span> analytically.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sympy.stats</span>
<span class="n">sympy</span><span class="o">.</span><span class="n">init_printing</span><span class="p">()</span>
<span class="n">y</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">sympy</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;y </span><span class="se">\\</span><span class="s1">theta&#39;</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">sympy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">sympy</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="n">sympy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> \
    <span class="mf">1.</span> <span class="o">/</span> <span class="n">sympy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span> <span class="o">*</span> <span class="n">sympy</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="n">sympy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">t</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sympy</span><span class="o">.</span><span class="n">simplify</span><span class="p">(</span><span class="n">sympy</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="o">-</span><span class="n">sympy</span><span class="o">.</span><span class="n">oo</span><span class="p">,</span> <span class="n">sympy</span><span class="o">.</span><span class="n">oo</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>So, if the observed <span class="math notranslate nohighlight">\(y\)</span> was zero, then the Z should be:</p>
<div class="math notranslate nohighlight">
\[
Z = \frac{1}{2\sqrt{\pi}}.
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Z</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span>  <span class="mf">2.</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;log Z = </span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Z</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>log Z = -1.266
</pre></div>
</div>
</div>
</div>
<p>All, right. Now, let’s program this thing in PyMC3 and compare the results.</p>
<p>We start with the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span>
<span class="n">yobs</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># prior over theta </span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span><span class="n">testval</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
    
    <span class="c1"># log likelihood </span>
    <span class="n">llk</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Potential</span><span class="p">(</span><span class="s1">&#39;llk&#39;</span><span class="p">,</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span><span class="o">.</span><span class="n">logp</span><span class="p">(</span><span class="n">yobs</span><span class="p">))</span>
    
    <span class="c1"># This is the command use use SMC in PyMC3:</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_smc</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.99</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initializing SMC sampler...
Sampling 5 chains in 5 jobs
/opt/homebrew/lib/python3.9/site-packages/pymc3/sampling.py:1944: UserWarning: The effect of Potentials on other parameters is ignored during prior predictive sampling. This is likely to lead to invalid or biased predictive samples.
  warnings.warn(
Stage:   0 Beta: 0.172
Stage:   1 Beta: 0.358
Stage:   2 Beta: 0.563
Stage:   3 Beta: 0.787
Stage:   4 Beta: 1.000
/opt/homebrew/lib/python3.9/site-packages/pymc3/sampling.py:1944: UserWarning: The effect of Potentials on other parameters is ignored during prior predictive sampling. This is likely to lead to invalid or biased predictive samples.
  warnings.warn(
Stage:   0 Beta: 0.164
Stage:   1 Beta: 0.336
Stage:   2 Beta: 0.557
Stage:   3 Beta: 0.805
Stage:   4 Beta: 1.000
Stage:   0 Beta: 0.164
Stage:   1 Beta: 0.365
Stage:   2 Beta: 0.569
Stage:   3 Beta: 0.804
Stage:   4 Beta: 1.000
Stage:   0 Beta: 0.156
Stage:   1 Beta: 0.344
Stage:   2 Beta: 0.551
Stage:   3 Beta: 0.788
Stage:   4 Beta: 1.000
Stage:   0 Beta: 0.156
Stage:   1 Beta: 0.336
Stage:   2 Beta: 0.544
Stage:   3 Beta: 0.783
Stage:   4 Beta: 1.000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">log_Z_smc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trace</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">log_marginal_likelihood</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;log Z (smc) = </span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">log_Z_smc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>log Z (smc) = -1.265
</pre></div>
</div>
</div>
</div>
<p>Which is close to the truth.</p>
</section>
<section id="polynomial-regression">
<h2>Polynomial Regression<a class="headerlink" href="#polynomial-regression" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_design_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">phi</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Arguments:</span>
<span class="sd">    </span>
<span class="sd">    X   -  The observed inputs (1D array)</span>
<span class="sd">    phi -  The basis functions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_observations</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_basis</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">num_basis</span>
    <span class="n">Phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">((</span><span class="n">num_observations</span><span class="p">,</span> <span class="n">num_basis</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_observations</span><span class="p">):</span>
        <span class="n">Phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">phi</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:])</span>
    <span class="k">return</span> <span class="n">Phi</span>

<span class="k">class</span> <span class="nc">PolynomialBasis</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A set of linear basis functions.</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    degree  -  The degree of the polynomial.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">=</span> <span class="n">degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_basis</span> <span class="o">=</span> <span class="n">degree</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">**</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>
    

<span class="k">class</span> <span class="nc">FourierBasis</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A set of linear basis functions.</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    num_terms  -  The number of Fourier terms.</span>
<span class="sd">    L          -  The period of the function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_terms</span><span class="p">,</span> <span class="n">L</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_terms</span> <span class="o">=</span> <span class="n">num_terms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">L</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_basis</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">num_terms</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_basis</span><span class="p">,))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_terms</span><span class="p">):</span>
            <span class="n">res</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">res</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">res</span>
    

<span class="k">class</span> <span class="nc">RadialBasisFunctions</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A set of linear basis functions.</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    X   -  The centers of the radial basis functions.</span>
<span class="sd">    ell -  The assumed lengthscale.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">ell</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ell</span> <span class="o">=</span> <span class="n">ell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_basis</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">ell</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s generate some fake data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">getdata</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">X</span>  <span class="o">**</span> <span class="mi">3</span> <span class="o">-</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">X</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">sigma2</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">getdata</span><span class="p">(</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markeredgewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$y$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/3fb7254283c79319ad53130a085c3188ecf8e5aa9229cc471ef35383dbeba3d7.png" src="../_images/3fb7254283c79319ad53130a085c3188ecf8e5aa9229cc471ef35383dbeba3d7.png" />
</div>
</div>
<p>We are going to implement a standard Bayesian linear regression and train it with <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>.
We will compute the evidence in order to select the best class of basis functions.
The model is as follows:</p>
<p>The output <span class="math notranslate nohighlight">\(y\)</span> conditioned on the input <span class="math notranslate nohighlight">\(x\)</span>, the weights of the basis functions <span class="math notranslate nohighlight">\(w\)</span> and
the noise variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> has likelihood:</p>
<div class="math notranslate nohighlight">
\[
p(y|x,w,\sigma, \mathcal{M}) = \mathcal{N}(y|w^T\phi_{\mathcal{M}}(x), \sigma^2),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi_{\mathcal{M},1}(\cdot), \dots, \phi_{\mathcal{M},m_{\mathcal{M}}}(\cdot)\)</span> are the
<span class="math notranslate nohighlight">\(m_{\mathcal{M}}\)</span> basis functions of the model <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>.
We put a normal prior on the weights:</p>
<div class="math notranslate nohighlight">
\[
p(w|\alpha) = \mathcal{N}(w|0, \alpha I_{m_{\mathcal{M}}}),
\]</div>
<p>and an inverse Gamma prior for <span class="math notranslate nohighlight">\(\sigma\)</span> and <span class="math notranslate nohighlight">\(\alpha\)</span>:</p>
<div class="math notranslate nohighlight">
\[
p(\sigma^2) = \mathrm{IG}(\sigma^2|1, 1),
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
p(\alpha) = \mathrm{IG}(\alpha|1,1).
\]</div>
<p>Assume that the data we have observed are:</p>
<div class="math notranslate nohighlight">
\[
x_{1:n} = \{x_1,\dots,x_n\},\;\mathrm{and}\;y_{1:n} = \{y_1,\dots,y_n\}.
\]</div>
<p>Consider the design matrix <span class="math notranslate nohighlight">\(\Phi_{\mathcal{M}}\in\mathbb{R}^{n\times m}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\Phi_{\mathcal{M},ij} = \phi_{\mathcal{M},j}(x_i).
\]</div>
<p>The likelihood of the data is:</p>
<div class="math notranslate nohighlight">
\[
p(y_{1:n} | x_{1:n}, w, \sigma, \mathcal{M}) = \mathcal{N}(y_{1:n}|\Phi_{\mathcal{M}}w, \sigma^2I_n).
\]</div>
<p>Let’s turn this into <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_model</span><span class="p">(</span><span class="n">Phi</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    INPUTS:</span>
<span class="sd">        Phi -&gt; Design matrix.</span>
<span class="sd">        y   -&gt; Target vector. </span>
<span class="sd">        </span>
<span class="sd">    RETURNS:</span>
<span class="sd">        model -&gt; `pymc3.model` context.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_data</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">Phi</span><span class="o">.</span><span class="n">shape</span>
    
    <span class="c1"># define the model </span>
    <span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
        <span class="c1"># prior on the weights </span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">InverseGamma</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">num_features</span><span class="p">)</span>
        
        <span class="c1"># prior on the likelihood noise variance </span>
        <span class="n">sigma2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">InverseGamma</span><span class="p">(</span><span class="s1">&#39;sigma2&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">5.</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        
        <span class="c1"># the data likelihood mean </span>
        <span class="n">ymean</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;ymean&#39;</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Phi</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
        
        <span class="c1"># likelihood </span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">ymean</span><span class="p">,</span> <span class="n">sigma2</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">num_data</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="c1">#llk = pm.Potential(&#39;llk&#39;, pm.Normal.dist(ymean, tt.sqrt(sigma2)).logp_sum(y))</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s create a function that trains the model using pysmc for a polynomial basis with a given order.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit_poly</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">num_particles</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    RETURNS:</span>
<span class="sd">        1. An instance of pymc3.Model for the SMC model.</span>
<span class="sd">        2. The SMC trace.</span>
<span class="sd">        3. An instance of pymc3.smc.SMC containing sampling information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Phi</span> <span class="o">=</span> <span class="n">compute_design_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">phi</span><span class="p">)</span>
    <span class="n">smcmodel</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="n">Phi</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_smc</span><span class="p">(</span><span class="n">draws</span><span class="o">=</span><span class="n">num_particles</span><span class="p">,</span> 
                          <span class="n">model</span><span class="o">=</span><span class="n">smcmodel</span><span class="p">,</span> 
                          <span class="n">threshold</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">smcmodel</span><span class="p">,</span> <span class="n">trace</span>

<span class="n">phi</span> <span class="o">=</span> <span class="n">PolynomialBasis</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">trace</span> <span class="o">=</span> <span class="n">fit_poly</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initializing SMC sampler...
Sampling 5 chains in 5 jobs
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.005
Stage:   9 Beta: 0.009
Stage:  10 Beta: 0.014
Stage:  11 Beta: 0.021
Stage:  12 Beta: 0.031
Stage:  13 Beta: 0.045
Stage:  14 Beta: 0.062
Stage:  15 Beta: 0.083
Stage:  16 Beta: 0.111
Stage:  17 Beta: 0.145
Stage:  18 Beta: 0.184
Stage:  19 Beta: 0.237
Stage:  20 Beta: 0.297
Stage:  21 Beta: 0.380
Stage:  22 Beta: 0.482
Stage:  23 Beta: 0.603
Stage:  24 Beta: 0.772
Stage:  25 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.007
Stage:  10 Beta: 0.010
Stage:  11 Beta: 0.016
Stage:  12 Beta: 0.024
Stage:  13 Beta: 0.036
Stage:  14 Beta: 0.054
Stage:  15 Beta: 0.073
Stage:  16 Beta: 0.098
Stage:  17 Beta: 0.128
Stage:  18 Beta: 0.166
Stage:  19 Beta: 0.211
Stage:  20 Beta: 0.263
Stage:  21 Beta: 0.333
Stage:  22 Beta: 0.411
Stage:  23 Beta: 0.517
Stage:  24 Beta: 0.673
Stage:  25 Beta: 0.911
Stage:  26 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.007
Stage:  10 Beta: 0.011
Stage:  11 Beta: 0.017
Stage:  12 Beta: 0.026
Stage:  13 Beta: 0.038
Stage:  14 Beta: 0.053
Stage:  15 Beta: 0.074
Stage:  16 Beta: 0.098
Stage:  17 Beta: 0.128
Stage:  18 Beta: 0.161
Stage:  19 Beta: 0.204
Stage:  20 Beta: 0.258
Stage:  21 Beta: 0.326
Stage:  22 Beta: 0.434
Stage:  23 Beta: 0.547
Stage:  24 Beta: 0.672
Stage:  25 Beta: 0.869
Stage:  26 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.001
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.007
Stage:  10 Beta: 0.012
Stage:  11 Beta: 0.018
Stage:  12 Beta: 0.029
Stage:  13 Beta: 0.043
Stage:  14 Beta: 0.061
Stage:  15 Beta: 0.082
Stage:  16 Beta: 0.106
Stage:  17 Beta: 0.133
Stage:  18 Beta: 0.168
Stage:  19 Beta: 0.222
Stage:  20 Beta: 0.288
Stage:  21 Beta: 0.378
Stage:  22 Beta: 0.480
Stage:  23 Beta: 0.613
Stage:  24 Beta: 0.798
Stage:  25 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.006
Stage:   9 Beta: 0.010
Stage:  10 Beta: 0.015
Stage:  11 Beta: 0.024
Stage:  12 Beta: 0.036
Stage:  13 Beta: 0.052
Stage:  14 Beta: 0.070
Stage:  15 Beta: 0.096
Stage:  16 Beta: 0.126
Stage:  17 Beta: 0.161
Stage:  18 Beta: 0.199
Stage:  19 Beta: 0.251
Stage:  20 Beta: 0.316
Stage:  21 Beta: 0.408
Stage:  22 Beta: 0.508
Stage:  23 Beta: 0.648
Stage:  24 Beta: 0.854
Stage:  25 Beta: 1.000
</pre></div>
</div>
</div>
</details>
</div>
<section id="postprocessing">
<h3>Postprocessing<a class="headerlink" href="#postprocessing" title="Permalink to this heading">#</a></h3>
<p>Once you have the <code class="docutils literal notranslate"><span class="pre">trace</span></code> object for the SMC simulation you can apply all the standard postprocessing tools from <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> as usual.</p>
<p>Here’s the posterior distribution over the weights precision and the the likelihood noise, <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span> respectively:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="o">=</span><span class="n">pm</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;sigma2&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Got error No model on context stack. trying to find log_likelihood in translation.
</pre></div>
</div>
<img alt="../_images/f4dd0c8968574a555f57c05b4813182e1f6890132641f69e68f0582ac790e0f8.png" src="../_images/f4dd0c8968574a555f57c05b4813182e1f6890132641f69e68f0582ac790e0f8.png" />
</div>
</div>
<p>Here’s the posterior predictive mean of the output <span class="math notranslate nohighlight">\(y\)</span>, i.e., <span class="math notranslate nohighlight">\(\mathbb{E}[y|x, w, \sigma]\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ppsamples</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> 
                               <span class="n">trace</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ymean&#39;</span><span class="p">])[</span><span class="s1">&#39;ymean&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
    <div>
      <progress value='500' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [500/500 00:00<00:00]
    </div>
    </div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">ppsamples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="n">idx</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Posterior Predictive Mean&#39;</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">markeredgewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed data&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c76128d063d249482aed6bdab745b067c02b21799744fc8d7ec8e184ed3b134c.png" src="../_images/c76128d063d249482aed6bdab745b067c02b21799744fc8d7ec8e184ed3b134c.png" />
</div>
</div>
<p>SMC does a particle approximation of the posterior distribution. The particles themselves can be obtained from the <code class="docutils literal notranslate"><span class="pre">trace</span></code> object and the particle weights can be obtained from the  <code class="docutils literal notranslate"><span class="pre">res</span></code> object.</p>
<p>Recall that the approximate posterior distribution is of the form <span class="math notranslate nohighlight">\(p(\theta|\mathcal{D}) = \frac{1}{N}\sum_{j=1}^{N} \delta(\theta - \theta_j)\)</span> (the code renormalizes the particles).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">particles_w</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">w</span>
<span class="n">particles_alpha</span> <span class="o">=</span> <span class="n">trace</span><span class="o">.</span><span class="n">alpha</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="model-comparison">
<h2>Model comparison<a class="headerlink" href="#model-comparison" title="Permalink to this heading">#</a></h2>
<p>Since SMC can approximate the model evidence it provides a principled way of comparing models. Let’s compare 5 different polynomial regression models where we change the degree of the polynomial from 1 to 5.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Evaluate the evidence for the various degrees</span>
<span class="n">log_Zs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">D</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">D</span><span class="p">:</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="n">PolynomialBasis</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">smc_model</span><span class="p">,</span> <span class="n">trace</span> <span class="o">=</span> <span class="n">fit_poly</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">num_particles</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
    <span class="n">log_Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trace</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">log_marginal_likelihood</span><span class="p">)</span>
    <span class="n">log_Zs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_Z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initializing SMC sampler...
Sampling 5 chains in 5 jobs
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.001
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.004
Stage:   8 Beta: 0.006
Stage:   9 Beta: 0.009
Stage:  10 Beta: 0.015
Stage:  11 Beta: 0.025
Stage:  12 Beta: 0.041
Stage:  13 Beta: 0.066
Stage:  14 Beta: 0.104
Stage:  15 Beta: 0.163
Stage:  16 Beta: 0.258
Stage:  17 Beta: 0.419
Stage:  18 Beta: 0.674
Stage:  19 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.001
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.004
Stage:   8 Beta: 0.006
Stage:   9 Beta: 0.010
Stage:  10 Beta: 0.017
Stage:  11 Beta: 0.027
Stage:  12 Beta: 0.042
Stage:  13 Beta: 0.068
Stage:  14 Beta: 0.111
Stage:  15 Beta: 0.173
Stage:  16 Beta: 0.275
Stage:  17 Beta: 0.433
Stage:  18 Beta: 0.677
Stage:  19 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.001
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.006
Stage:   9 Beta: 0.010
Stage:  10 Beta: 0.016
Stage:  11 Beta: 0.026
Stage:  12 Beta: 0.041
Stage:  13 Beta: 0.066
Stage:  14 Beta: 0.106
Stage:  15 Beta: 0.169
Stage:  16 Beta: 0.271
Stage:  17 Beta: 0.431
Stage:  18 Beta: 0.707
Stage:  19 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.001
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.004
Stage:   8 Beta: 0.006
Stage:   9 Beta: 0.010
Stage:  10 Beta: 0.017
Stage:  11 Beta: 0.027
Stage:  12 Beta: 0.045
Stage:  13 Beta: 0.072
Stage:  14 Beta: 0.115
Stage:  15 Beta: 0.186
Stage:  16 Beta: 0.294
Stage:  17 Beta: 0.471
Stage:  18 Beta: 0.774
Stage:  19 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.005
Stage:   9 Beta: 0.009
Stage:  10 Beta: 0.014
Stage:  11 Beta: 0.023
Stage:  12 Beta: 0.037
Stage:  13 Beta: 0.059
Stage:  14 Beta: 0.094
Stage:  15 Beta: 0.152
Stage:  16 Beta: 0.247
Stage:  17 Beta: 0.391
Stage:  18 Beta: 0.614
Stage:  19 Beta: 0.977
Stage:  20 Beta: 1.000
Initializing SMC sampler...
Sampling 5 chains in 5 jobs
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.005
Stage:   9 Beta: 0.009
Stage:  10 Beta: 0.014
Stage:  11 Beta: 0.021
Stage:  12 Beta: 0.033
Stage:  13 Beta: 0.052
Stage:  14 Beta: 0.076
Stage:  15 Beta: 0.115
Stage:  16 Beta: 0.173
Stage:  17 Beta: 0.257
Stage:  18 Beta: 0.386
Stage:  19 Beta: 0.567
Stage:  20 Beta: 0.844
Stage:  21 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.005
Stage:   9 Beta: 0.008
Stage:  10 Beta: 0.013
Stage:  11 Beta: 0.020
Stage:  12 Beta: 0.032
Stage:  13 Beta: 0.051
Stage:  14 Beta: 0.079
Stage:  15 Beta: 0.119
Stage:  16 Beta: 0.175
Stage:  17 Beta: 0.268
Stage:  18 Beta: 0.410
Stage:  19 Beta: 0.610
Stage:  20 Beta: 0.885
Stage:  21 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.005
Stage:   9 Beta: 0.009
Stage:  10 Beta: 0.014
Stage:  11 Beta: 0.022
Stage:  12 Beta: 0.034
Stage:  13 Beta: 0.053
Stage:  14 Beta: 0.081
Stage:  15 Beta: 0.121
Stage:  16 Beta: 0.181
Stage:  17 Beta: 0.276
Stage:  18 Beta: 0.405
Stage:  19 Beta: 0.601
Stage:  20 Beta: 0.893
Stage:  21 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.001
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.005
Stage:   9 Beta: 0.009
Stage:  10 Beta: 0.014
Stage:  11 Beta: 0.023
Stage:  12 Beta: 0.036
Stage:  13 Beta: 0.056
Stage:  14 Beta: 0.085
Stage:  15 Beta: 0.128
Stage:  16 Beta: 0.194
Stage:  17 Beta: 0.293
Stage:  18 Beta: 0.437
Stage:  19 Beta: 0.658
Stage:  20 Beta: 0.980
Stage:  21 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.005
Stage:   9 Beta: 0.008
Stage:  10 Beta: 0.013
Stage:  11 Beta: 0.021
Stage:  12 Beta: 0.033
Stage:  13 Beta: 0.053
Stage:  14 Beta: 0.084
Stage:  15 Beta: 0.129
Stage:  16 Beta: 0.193
Stage:  17 Beta: 0.284
Stage:  18 Beta: 0.425
Stage:  19 Beta: 0.622
Stage:  20 Beta: 0.926
Stage:  21 Beta: 1.000
Initializing SMC sampler...
Sampling 5 chains in 5 jobs
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.006
Stage:  10 Beta: 0.011
Stage:  11 Beta: 0.017
Stage:  12 Beta: 0.025
Stage:  13 Beta: 0.036
Stage:  14 Beta: 0.050
Stage:  15 Beta: 0.068
Stage:  16 Beta: 0.090
Stage:  17 Beta: 0.114
Stage:  18 Beta: 0.144
Stage:  19 Beta: 0.183
Stage:  20 Beta: 0.233
Stage:  21 Beta: 0.298
Stage:  22 Beta: 0.374
Stage:  23 Beta: 0.478
Stage:  24 Beta: 0.618
Stage:  25 Beta: 0.821
Stage:  26 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.007
Stage:  10 Beta: 0.012
Stage:  11 Beta: 0.018
Stage:  12 Beta: 0.028
Stage:  13 Beta: 0.040
Stage:  14 Beta: 0.055
Stage:  15 Beta: 0.073
Stage:  16 Beta: 0.094
Stage:  17 Beta: 0.121
Stage:  18 Beta: 0.156
Stage:  19 Beta: 0.199
Stage:  20 Beta: 0.252
Stage:  21 Beta: 0.323
Stage:  22 Beta: 0.410
Stage:  23 Beta: 0.525
Stage:  24 Beta: 0.665
Stage:  25 Beta: 0.847
Stage:  26 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.007
Stage:  10 Beta: 0.011
Stage:  11 Beta: 0.017
Stage:  12 Beta: 0.025
Stage:  13 Beta: 0.036
Stage:  14 Beta: 0.048
Stage:  15 Beta: 0.065
Stage:  16 Beta: 0.086
Stage:  17 Beta: 0.114
Stage:  18 Beta: 0.148
Stage:  19 Beta: 0.190
Stage:  20 Beta: 0.241
Stage:  21 Beta: 0.303
Stage:  22 Beta: 0.381
Stage:  23 Beta: 0.483
Stage:  24 Beta: 0.618
Stage:  25 Beta: 0.811
Stage:  26 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.007
Stage:  10 Beta: 0.012
Stage:  11 Beta: 0.018
Stage:  12 Beta: 0.027
Stage:  13 Beta: 0.039
Stage:  14 Beta: 0.053
Stage:  15 Beta: 0.071
Stage:  16 Beta: 0.092
Stage:  17 Beta: 0.118
Stage:  18 Beta: 0.151
Stage:  19 Beta: 0.191
Stage:  20 Beta: 0.242
Stage:  21 Beta: 0.305
Stage:  22 Beta: 0.394
Stage:  23 Beta: 0.514
Stage:  24 Beta: 0.667
Stage:  25 Beta: 0.870
Stage:  26 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.005
Stage:   9 Beta: 0.007
Stage:  10 Beta: 0.011
Stage:  11 Beta: 0.017
Stage:  12 Beta: 0.027
Stage:  13 Beta: 0.038
Stage:  14 Beta: 0.052
Stage:  15 Beta: 0.069
Stage:  16 Beta: 0.091
Stage:  17 Beta: 0.116
Stage:  18 Beta: 0.143
Stage:  19 Beta: 0.175
Stage:  20 Beta: 0.218
Stage:  21 Beta: 0.274
Stage:  22 Beta: 0.345
Stage:  23 Beta: 0.441
Stage:  24 Beta: 0.571
Stage:  25 Beta: 0.744
Stage:  26 Beta: 0.989
Stage:  27 Beta: 1.000
Initializing SMC sampler...
Sampling 5 chains in 5 jobs
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.005
Stage:   9 Beta: 0.009
Stage:  10 Beta: 0.014
Stage:  11 Beta: 0.021
Stage:  12 Beta: 0.030
Stage:  13 Beta: 0.045
Stage:  14 Beta: 0.061
Stage:  15 Beta: 0.082
Stage:  16 Beta: 0.105
Stage:  17 Beta: 0.132
Stage:  18 Beta: 0.163
Stage:  19 Beta: 0.202
Stage:  20 Beta: 0.252
Stage:  21 Beta: 0.310
Stage:  22 Beta: 0.389
Stage:  23 Beta: 0.484
Stage:  24 Beta: 0.607
Stage:  25 Beta: 0.762
Stage:  26 Beta: 0.959
Stage:  27 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.002
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.007
Stage:  10 Beta: 0.011
Stage:  11 Beta: 0.017
Stage:  12 Beta: 0.027
Stage:  13 Beta: 0.038
Stage:  14 Beta: 0.052
Stage:  15 Beta: 0.069
Stage:  16 Beta: 0.090
Stage:  17 Beta: 0.114
Stage:  18 Beta: 0.144
Stage:  19 Beta: 0.181
Stage:  20 Beta: 0.230
Stage:  21 Beta: 0.283
Stage:  22 Beta: 0.350
Stage:  23 Beta: 0.429
Stage:  24 Beta: 0.530
Stage:  25 Beta: 0.668
Stage:  26 Beta: 0.850
Stage:  27 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.006
Stage:  10 Beta: 0.010
Stage:  11 Beta: 0.015
Stage:  12 Beta: 0.023
Stage:  13 Beta: 0.034
Stage:  14 Beta: 0.048
Stage:  15 Beta: 0.063
Stage:  16 Beta: 0.082
Stage:  17 Beta: 0.106
Stage:  18 Beta: 0.134
Stage:  19 Beta: 0.168
Stage:  20 Beta: 0.210
Stage:  21 Beta: 0.264
Stage:  22 Beta: 0.324
Stage:  23 Beta: 0.403
Stage:  24 Beta: 0.513
Stage:  25 Beta: 0.654
Stage:  26 Beta: 0.834
Stage:  27 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.006
Stage:  10 Beta: 0.010
Stage:  11 Beta: 0.016
Stage:  12 Beta: 0.024
Stage:  13 Beta: 0.036
Stage:  14 Beta: 0.050
Stage:  15 Beta: 0.067
Stage:  16 Beta: 0.084
Stage:  17 Beta: 0.101
Stage:  18 Beta: 0.122
Stage:  19 Beta: 0.149
Stage:  20 Beta: 0.185
Stage:  21 Beta: 0.232
Stage:  22 Beta: 0.290
Stage:  23 Beta: 0.364
Stage:  24 Beta: 0.455
Stage:  25 Beta: 0.572
Stage:  26 Beta: 0.730
Stage:  27 Beta: 0.947
Stage:  28 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.006
Stage:  10 Beta: 0.010
Stage:  11 Beta: 0.015
Stage:  12 Beta: 0.023
Stage:  13 Beta: 0.033
Stage:  14 Beta: 0.045
Stage:  15 Beta: 0.059
Stage:  16 Beta: 0.077
Stage:  17 Beta: 0.098
Stage:  18 Beta: 0.119
Stage:  19 Beta: 0.143
Stage:  20 Beta: 0.175
Stage:  21 Beta: 0.215
Stage:  22 Beta: 0.268
Stage:  23 Beta: 0.336
Stage:  24 Beta: 0.423
Stage:  25 Beta: 0.529
Stage:  26 Beta: 0.671
Stage:  27 Beta: 0.850
Stage:  28 Beta: 1.000
Initializing SMC sampler...
Sampling 5 chains in 5 jobs
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.003
Stage:   9 Beta: 0.006
Stage:  10 Beta: 0.009
Stage:  11 Beta: 0.015
Stage:  12 Beta: 0.023
Stage:  13 Beta: 0.035
Stage:  14 Beta: 0.048
Stage:  15 Beta: 0.065
Stage:  16 Beta: 0.086
Stage:  17 Beta: 0.110
Stage:  18 Beta: 0.139
Stage:  19 Beta: 0.174
Stage:  20 Beta: 0.217
Stage:  21 Beta: 0.268
Stage:  22 Beta: 0.326
Stage:  23 Beta: 0.396
Stage:  24 Beta: 0.489
Stage:  25 Beta: 0.604
Stage:  26 Beta: 0.754
Stage:  27 Beta: 0.945
Stage:  28 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.003
Stage:   9 Beta: 0.005
Stage:  10 Beta: 0.009
Stage:  11 Beta: 0.014
Stage:  12 Beta: 0.022
Stage:  13 Beta: 0.033
Stage:  14 Beta: 0.046
Stage:  15 Beta: 0.063
Stage:  16 Beta: 0.084
Stage:  17 Beta: 0.111
Stage:  18 Beta: 0.141
Stage:  19 Beta: 0.177
Stage:  20 Beta: 0.217
Stage:  21 Beta: 0.267
Stage:  22 Beta: 0.325
Stage:  23 Beta: 0.398
Stage:  24 Beta: 0.496
Stage:  25 Beta: 0.610
Stage:  26 Beta: 0.746
Stage:  27 Beta: 0.924
Stage:  28 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.003
Stage:   9 Beta: 0.006
Stage:  10 Beta: 0.009
Stage:  11 Beta: 0.014
Stage:  12 Beta: 0.023
Stage:  13 Beta: 0.034
Stage:  14 Beta: 0.048
Stage:  15 Beta: 0.067
Stage:  16 Beta: 0.089
Stage:  17 Beta: 0.114
Stage:  18 Beta: 0.146
Stage:  19 Beta: 0.183
Stage:  20 Beta: 0.225
Stage:  21 Beta: 0.274
Stage:  22 Beta: 0.330
Stage:  23 Beta: 0.403
Stage:  24 Beta: 0.489
Stage:  25 Beta: 0.601
Stage:  26 Beta: 0.752
Stage:  27 Beta: 0.944
Stage:  28 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.003
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.007
Stage:  10 Beta: 0.011
Stage:  11 Beta: 0.017
Stage:  12 Beta: 0.026
Stage:  13 Beta: 0.039
Stage:  14 Beta: 0.054
Stage:  15 Beta: 0.072
Stage:  16 Beta: 0.093
Stage:  17 Beta: 0.121
Stage:  18 Beta: 0.154
Stage:  19 Beta: 0.193
Stage:  20 Beta: 0.237
Stage:  21 Beta: 0.288
Stage:  22 Beta: 0.353
Stage:  23 Beta: 0.430
Stage:  24 Beta: 0.523
Stage:  25 Beta: 0.646
Stage:  26 Beta: 0.790
Stage:  27 Beta: 0.980
Stage:  28 Beta: 1.000
Stage:   0 Beta: 0.000
Stage:   1 Beta: 0.000
Stage:   2 Beta: 0.000
Stage:   3 Beta: 0.000
Stage:   4 Beta: 0.000
Stage:   5 Beta: 0.001
Stage:   6 Beta: 0.001
Stage:   7 Beta: 0.002
Stage:   8 Beta: 0.004
Stage:   9 Beta: 0.006
Stage:  10 Beta: 0.010
Stage:  11 Beta: 0.015
Stage:  12 Beta: 0.024
Stage:  13 Beta: 0.035
Stage:  14 Beta: 0.049
Stage:  15 Beta: 0.065
Stage:  16 Beta: 0.086
Stage:  17 Beta: 0.112
Stage:  18 Beta: 0.142
Stage:  19 Beta: 0.175
Stage:  20 Beta: 0.216
Stage:  21 Beta: 0.263
Stage:  22 Beta: 0.315
Stage:  23 Beta: 0.377
Stage:  24 Beta: 0.458
Stage:  25 Beta: 0.565
Stage:  26 Beta: 0.700
Stage:  27 Beta: 0.874
Stage:  28 Beta: 1.000
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">log_Z</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">log_Zs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;- degree </span><span class="si">%d</span><span class="s1"> gives log Z = </span><span class="si">%.4f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">log_Z</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>- degree 1 gives log Z = 25.1765
- degree 2 gives log Z = 41.3093
- degree 3 gives log Z = 139.4240
- degree 4 gives log Z = 136.3195
- degree 5 gives log Z = 133.2138
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">log_Zs</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">_</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Polynomial degree&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Model Evidence&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/11dc9cb1e836f677b70bc94738af5379a5a792c952730cb34fd8c9e3df9887ee.png" src="../_images/11dc9cb1e836f677b70bc94738af5379a5a792c952730cb34fd8c9e3df9887ee.png" />
</div>
</div>
</section>
<section id="questions">
<h2>Questions<a class="headerlink" href="#questions" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>The model with degree 3 polynomials has the gradest evidence. However, the degree 4 and 5 seem also very plausible. Is this a problem for the theory of Bayesian model selection? What complicates things here, is that model 3 is included in model 4 which is included in model 5. This requires us to design special priors for the models being right. They have to be consistent in some sense. For example, if model 3 is right then model 4 must be right, etc.</p></li>
<li><p>Revisit the motorcycle dataset problem. Evaluate the model evidence for a 1) Polynomial basis; 2) a Fourier basis; and 3) a Radial basis function basis.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lecture27"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="hands-on-27.4.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Gibbs Sampling</p>
      </div>
    </a>
    <a class="right-next"
       href="../lecture28/intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 28 - Variational Inference</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#objectives">Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sanity-check-does-the-calculation-of-the-evidence-work">Sanity check - Does the calculation of the evidence work?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-regression">Polynomial Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#postprocessing">Postprocessing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-comparison">Model comparison</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#questions">Questions</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ilias Bilionis (ibilion[at]purdue.edu)
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=c5ced968eda925caa686"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>