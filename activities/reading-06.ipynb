{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Activity 6: Random Vectors\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ To introduce the concept of the joint probability density function.\n",
    "+ To introduce the concept of marginalization.\n",
    "+ To introduce the conditional probability density function.\n",
    "+ To introduce the expectation of continuous random variables.\n",
    "\n",
    "## References\n",
    "\n",
    "+ None\n",
    "\n",
    "## Random Vectors\n",
    "\n",
    "### Definition\n",
    "Take $N$ random variables $X_1,\\dots,X_N$ and put them in a vector:\n",
    "$$\n",
    "\\mathbf{X} = (X_1,\\dots,X_N).\n",
    "$$\n",
    "We say that $\\mathbf{X}$ is a *random vector*.\n",
    "Random vectors are used to model *uncertain stuff* that require multiple numbers to be described.\n",
    "For example:\n",
    "\n",
    "+ The unobserved state of a multi-body system can be described by the random vector of coordinates and velocities.\n",
    "+ An \"uncertain function\" could be modeled by the random vector of its function values at $N$ test points.\n",
    "\n",
    "### Probability density function of a random vector\n",
    "The the PDF of the random vector is the joint PDF of the components.\n",
    "We write:\n",
    "$$\n",
    "p(\\mathbf{x}) = p(x_1,\\dots,x_N).\n",
    "$$\n",
    "\n",
    "### Expectation of a random vector\n",
    "The expectation of a random vector is the vector of expectations of each component:\n",
    "$$\n",
    "\\mathbb{E}[\\mathbf{X}] =\n",
    "\\begin{pmatrix}\n",
    "\\mathbb{E}[X_1]\\\\\n",
    "\\vdots\\\\\n",
    "\\mathbb{E}[X_N]\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "This satisfies properties similar to the expectation of scalar random variables.\n",
    "For example, for any real number $\\lambda$ we have that:\n",
    "$$\n",
    "\\mathbb{E}[\\lambda \\mathbf{X}] = \\lambda\\mathbb{E}[X].\n",
    "$$\n",
    "Also, if $\\mathbf{Y}$ is another $N$-dimensional random vector, we have:\n",
    "$$\n",
    "\\mathbb{E}[X+Y] = \\mathbb{E}[X] + \\mathbb{E}[Y].\n",
    "$$\n",
    "\n",
    "### Covariance matrix of two random vectors\n",
    "Let $\\mathbf{X}$ and $\\mathbf{Y}$ be $N$- and $M$-dimensional random vectors, respectively.\n",
    "The covariance of $\\mathbb{X}$ and $\\mathbf{Y}$ is the $N\\times M$ matrix consisting of all covariances between the components of $\\mathbf{X}$ and $\\mathbf{Y}$, i.e.,\n",
    "$$\n",
    "\\mathbb{C}[\\mathbf{X}, \\mathbf{Y}] = (\\mathbb{C}[X_i, Y_j]).\n",
    "$$\n",
    "It can also be rewritten as the expectation of a matrix:\n",
    "$$\n",
    "\\mathbb{C}[\\mathbf{X}, \\mathbf{Y}] = \\mathbb{C}[\\mathbf{X},\\mathbf{X}] = \\mathbb{E}\\left[\\left(\\mathbf{X}-\\mathbb{E}[\\mathbf{X}]\\right)\\left(\\mathbf{Y}-\\mathbb{E}[\\mathbf{Y}]\\right)^T\\right].\n",
    "$$\n",
    "Here we assumed that the expectation operator is applied on each one of the matrix components.\n",
    "\n",
    "It is easy to show that the covariance is a linear function of each argument.\n",
    "\n",
    "The $N\\times N$ matrix $\\mathbb{C}[X,X]$ is the *self covariance* matrix (or just covariance matrix) of $\\mathbf{X}$.\n",
    "The diagonal of the covariance matrix of $\\mathbf{X}$ contains the variances of each of the components of $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
