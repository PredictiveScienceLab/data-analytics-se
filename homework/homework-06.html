
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Homework 6 &#8212; Introduction to Scientific Machine Learning (Lecture Book)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'homework/homework-06';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Homework 7" href="homework-07.html" />
    <link rel="prev" title="Homework 5" href="homework-05.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Introduction to Scientific Machine Learning (Lecture Book)</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Preface
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../introduction.html">Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture01/intro.html">Lecture 1 - Introduction to Predictive Modeling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture01/reading-01.html">The Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture01/hands-on-01.1.html">The Uncertainty Propagation Problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture01/hands-on-01.2.html">The Model Calibration Problem</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../review_probability.html">Review of Probability</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture02/intro.html">Lecture 2 - Basics of Probability Theory</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture02/reading-02.html">Basics of Probability Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture02/hands-on-02.html">Experiment with “Randomness”</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture03/intro.html">Lecture 3 - Discrete Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture03/reading-03.html">Discrete Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture03/hands-on-03.html">Discrete Random Variables in Python</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture04/intro.html">Lecture 4 - Continuous Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture04/reading-04.html">Continuous Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture04/hands-on-04.1.html">The Uniform Distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture04/hands-on-04.2.html">The Gaussian Distribution</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture05/intro.html">Lecture 5 - Collections of Random Variables</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture05/reading-05.html">Collections of Random Variables: Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture05/hands-on-05.html">Practicing with Joint Probability Mass Functions</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture06/intro.html">Lecture 6 - Random Vectors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/reading-06.html">Random Vectors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.1.html">The Multivariate Normal - Diagonal Covariance Case</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.2.html">The Multivariate Normal - Full Covariance Case</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.3.html">The Multivariate Normal - Marginalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.4.html">The Multivariate Normal - Conditioning</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../uncertainty_propagation.html">Uncertainty Propagation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture07/intro.html">Lecture 7 - Basic Sampling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.1.html">Pseudo-random number generators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.2.html">Sampling the uniform distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.3.html">Sampling the categorical</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.4.html">Sampling from continuous distributions - Inverse sampling</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture08/intro.html">Lecture 8 - The Monte Carlo Method for Estimating Expectations</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture08/reading-08.html">The Uncertainty Propagation Problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture08/hands-on-08.3.html">The Monte Carlo Method for Estimating Expectations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture08/hands-on-08.4.html">Sampling Estimates of Variance</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture09/intro.html">Lecture 9 - Monte Carlo Estimates of Various Statistics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.1.html">Sampling Estimates of the Cumulative Distribution Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.2.html">Sampling Estimates of the Probability Density via Histograms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.3.html">Estimating Predictive Quantiles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.4.html">Uncertainty propagation through an ordinary differential equation</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture10/intro.html">Lecture 10 - Quantify Uncertainty in Monte Carlo Estimates</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.1.html">Visualizing Monte Carlo Uncertainty</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.2.html">The Central Limit Theorem</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.3.html">Quantifying Epistemic Uncertainty in Monte Carlo Estimates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.4.html">Uncertainty Propagation Through a Boundary Value Problem</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../principles_of_bi.html">Principles of Bayesian Inference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture11/intro.html">Lecture 11 - Selecting Prior Information</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/reading-11.html">Selecting Prior Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/hands-on-11.1.html">Information Entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/hands-on-11.2.html">The Principle of Maximum Entropy for Discrete Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/hands-on-11.3.html">The Principle of Maximum Entropy for Continuous Random Variables</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture12/intro.html">Lecture 12 - Analytical Examples of Bayesian Inference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/reading-12.html">Bayesian inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.1.html">Example: Inferring the probability of a coin toss from data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.2.html">Credible Intervals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.3.html">Decision Making</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.4.html">Posterior Predictive Checking</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../supervised_learning.html">Supervised Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture13/intro.html">Lecture 13 - Linear Regression via Least Squares</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/reading-13.html">Linear Regression via Least Squares</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.1.html">Linear regression with a single variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.2.html">Polynomial Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.3.html">The Generalized Linear Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.4.html">Measures of Predictive Accuracy</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture14/intro.html">Lecture 14 - Bayesian Linear Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/reading-14.html">Bayesian Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.1.html">Probabilistic Interpretation of Least Squares - Estimating the Measurement Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.2.html">Maximum a Posteriori Estimate - Avoiding Overfitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.3.html">Bayesian Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.4.html">The point-predictive Distribution - Separating Epistemic and Aleatory Uncertainty</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture15/intro.html">Lecture 15 - Advanced Topics in Bayesian Linear Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/reading-15.html">Advanced Topics in Bayesian Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/hands-on-15.1.html">Evidence approximation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/hands-on-15.2.html">Automatic Relevance Determination</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/hands-on-15.3.html">Diagnostics for Posterior Predictive</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture16/intro.html">Lecture 16 - Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/reading-16.html">Theoretical Background on Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.1.html">Logistic regression with one variable (High melting explosives)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.2.html">Logistic Regression with Many Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.3.html">Decision making</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.4.html">Diagnostics for Classifications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.5.html">Multi-class Logistic Regression</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../unsupervised_learning.html">Unsupervised Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture17/intro.html">Lecture 17 - Clustering and Density Estimation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture17/reading-17.html">Unsupervised Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture17/hands-on-17.1.html">Clustering using k-means</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture17/hands-on-17.2.html">Density Estimation via Gaussian mixtures</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture18/intro.html">Lecture 18 - Dimensionality Reduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/reading-18.html">Dimensionality Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/hands-on-18.1.html">Dimensionality Reduction Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/hands-on-18.2.html">Clustering High-dimensional Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/hands-on-18.3.html">Density Estimation with High-dimensional Data</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../state_space_models.html">State Space Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture19/intro.html">Lecture 19 - State Space Models - Filtering Basics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture19/reading-19.html">State Space Models - Filtering Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture19/hands-on-19.1.html">Object Tracking Example</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture20/intro.html">Lecture 20 - State Space Models - Kalman Filters</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture20/reading-20.html">State Space Models - Kalman Filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture20/hands-on-20.1.html">Kalman Filter for the Object Tracking Example</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gaussian_process_regression.html">Gaussian Process Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture21/intro.html">Lecture 21 - Gaussian Process Regression: Priors on Function Spaces</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture21/reading-21.html">Gaussian Process Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture21/hands-on-21.html">Example: Priors on function spaces</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture22/intro.html">Lecture 22 - Gaussian Process Regression: Conditioning on Data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/reading-22.html">Gaussian Process Regression - Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.1.html">Gaussian Process Regression Without Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.2.html">Gaussian Process Regression with Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.3.html">Tuning the Hyperparameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.4.html">Multivariate Gaussian Process Regression</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture23/intro.html">Lecture 23 - Bayesian Global Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/reading-23.html">Bayesian Global Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.1.html">Maximum Mean - A Bad Information Acquisition Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.2.html">Maximum Upper Interval</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.3.html">Probability of Improvement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.4.html">Expected Improvement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.5.html">Expected Improvement - With Observation Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.6.html">Quantifying Epistemic Uncertainty about the Solution of the Optimization problem</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../neural_networks.html">Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture24/intro.html">Lecture 24 - Deep Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture24/reading-24.html">Deep Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture24/hands-on-24.html">Regression with Deep Neural Networks</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture25/intro.html">Lecture 25 - Deep Neural Networks Continued</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture25/reading-25.html">Deep Neural Networks Continued</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture25/hands-on-25.html">Classification with Deep Neural Networks</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture26/intro.html">Lecture 26 - Physics-informed Deep Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture26/reading-26.html">Physics-informed Deep Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture26/hands-on-26.1.html">Physics-informed regularization: Solving ODEs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture26/hands-on-26.2.html">Physics-informed regularization: Solving PDEs</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../advanced_methods.html">Advanced Methods for Characterizing Posteriors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture27/intro.html">Lecture 27 - Sampling Methods</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/reading-27.html">Sampling Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/hands-on-27.1.html">Probabilistic numerics using <code class="docutils literal notranslate"><span class="pre">pyro</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/hands-on-27.2.html">Sampling From the Distributions With Random Walk Metropolis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/hands-on-27.3.html">The Metropolis-Hastings Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/hands-on-27.4.html">Hierarchical Bayesian Models</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture28/intro.html">Lecture 28 - Variational Inference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture28/reading-28.html">Variational Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture28/hands-on-28.html">Variational Inference Examples</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="intro.html">Homework</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="homework-01.html">Homework 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="homework-02.html">Homework 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="homework-03.html">Homework 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="homework-04.html">Homework 4</a></li>



<li class="toctree-l2"><a class="reference internal" href="homework-05.html">Homework 5</a></li>



<li class="toctree-l2 current active"><a class="current reference internal" href="#">Homework 6</a></li>
<li class="toctree-l2"><a class="reference internal" href="homework-07.html">Homework 7</a></li>
<li class="toctree-l2"><a class="reference internal" href="homework-08.html">Homework 8</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/PredictiveScienceLab/data-analytics-se/blob/master/lecturebook/homework/homework-06.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/homework/homework-06.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Homework 6</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instructions">Instructions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#student-details">Student details</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1-defining-priors-on-function-spaces">Problem 1 - Defining priors on function spaces</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-a-super-smooth-function-with-known-length-scale">Part A - Super smooth function with known length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-b-super-smooth-function-with-known-ultra-small-length-scale">Part B - Super smooth function with known ultra-small length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-c-continuous-function-with-known-length-scale">Part C - Continuous function with known length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-d-smooth-periodic-function-with-known-length-scale">Part D - Smooth periodic function with known length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-e-smooth-periodic-function-with-known-length-scale">Part E - Smooth periodic function with known length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-f-the-sum-of-two-functions">Part F - The sum of two functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-g-the-product-of-two-functions">Part G - The product of two functions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2">Problem 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-a-naive-approach">Part A - Naive approach</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-b-improving-the-prior-covariance">Part B - Improving the prior covariance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-c-predicting-the-future">Part C - Predicting the future</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-d-bayesian-information-criterion">Part D - Bayesian information criterion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3-bayesian-global-optimization">Problem 3 - Bayesian Global Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-a-visualize-the-function-and-generate-some-data">Part A - Visualize the function and generate some data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-b-set-up-the-gaussian-process-model">Part B - Set up the Gaussian process model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#now-train-the-model-on-the-data-points-to-optimize-the-rest-of-the-hyperparameters">Now train the model on the data points to optimize the rest of the hyperparameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-trained-model-along-with-some-sample-paths">Plot the trained model along with some sample paths</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-uncertainty-about-the-optimization-problem-for-the-initial-gaussian-process-surrogate">Plot the uncertainty about the optimization problem for the initial Gaussian process surrogate</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-c-expected-improvement-with-noise">Part C - Expected improvement with noise</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-algorithm">run the algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-many-iterations-does-the-algorithm-take-to-converge-that-is-how-quickly-does-it-identify-the-critical-point">How many iterations does the algorithm take to converge? That is, how quickly does it identify the critical point?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantify-the-uncertainty-about-the-solution-to-the-optimization-problem-with-the-trained-gaussian-process">Quantify the uncertainty about the solution to the optimization problem with the trained Gaussian process</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-d-testing-your-intuition">Part D - Testing your intuition</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="homework-6">
<h1>Homework 6<a class="headerlink" href="#homework-6" title="Link to this heading">#</a></h1>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Lectures 21-23 (inclusive).</p></li>
</ul>
</section>
<section id="instructions">
<h2>Instructions<a class="headerlink" href="#instructions" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Type your name and email in the “Student details” section below.</p></li>
<li><p>Develop the code and generate the figures you need to solve the problems using this notebook.</p></li>
<li><p>For the answers that require a mathematical proof or derivation you should type them using latex. If you have never written latex before and you find it exceedingly difficult, we will likely accept handwritten solutions.</p></li>
<li><p>The total homework points are 100. Please note that the problems are not weighed equally.</p></li>
</ul>
<p>If on Google Colab, install the following packages:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MAKE_BOOK_FIGURES</span><span class="o">=</span><span class="kc">True</span>

<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;paper&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;ticks&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">set_book_style</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-v0_8-white&#39;</span><span class="p">)</span> 
    <span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;ticks&quot;</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s2">&quot;deep&quot;</span><span class="p">)</span>

    <span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
        <span class="c1"># Font settings</span>
        <span class="s1">&#39;font.family&#39;</span><span class="p">:</span> <span class="s1">&#39;serif&#39;</span><span class="p">,</span>  <span class="c1"># For academic publishing</span>
        <span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>  <span class="c1"># As requested, 10pt font</span>
        <span class="s1">&#39;axes.labelsize&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s1">&#39;axes.titlesize&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span>  <span class="c1"># Slightly smaller for better readability</span>
        <span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span>
        <span class="s1">&#39;legend.fontsize&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span>
        
        <span class="c1"># Line and marker settings for consistency</span>
        <span class="s1">&#39;axes.linewidth&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="s1">&#39;grid.linewidth&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="s1">&#39;lines.linewidth&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s1">&#39;lines.markersize&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        
        <span class="c1"># Layout to prevent clipped labels</span>
        <span class="s1">&#39;figure.constrained_layout.use&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        
        <span class="c1"># Default DPI (will override when saving)</span>
        <span class="s1">&#39;figure.dpi&#39;</span><span class="p">:</span> <span class="mi">600</span><span class="p">,</span>
        <span class="s1">&#39;savefig.dpi&#39;</span><span class="p">:</span> <span class="mi">600</span><span class="p">,</span>
        
        <span class="c1"># Despine - remove top and right spines</span>
        <span class="s1">&#39;axes.spines.top&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;axes.spines.right&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        
        <span class="c1"># Remove legend frame</span>
        <span class="s1">&#39;legend.frameon&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        
        <span class="c1"># Additional trim settings</span>
        <span class="s1">&#39;figure.autolayout&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># Alternative to constrained_layout</span>
        <span class="s1">&#39;savefig.bbox&#39;</span><span class="p">:</span> <span class="s1">&#39;tight&#39;</span><span class="p">,</span>    <span class="c1"># Trim when saving</span>
        <span class="s1">&#39;savefig.pad_inches&#39;</span><span class="p">:</span> <span class="mf">0.1</span>   <span class="c1"># Small padding to ensure nothing gets cut off</span>
    <span class="p">})</span>

<span class="k">def</span> <span class="nf">set_notebook_style</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-v0_8-white&#39;</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;ticks&quot;</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s2">&quot;deep&quot;</span><span class="p">)</span>

    <span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
        <span class="c1"># Font settings - using default sizes</span>
        <span class="s1">&#39;font.family&#39;</span><span class="p">:</span> <span class="s1">&#39;serif&#39;</span><span class="p">,</span>
        <span class="s1">&#39;axes.labelsize&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s1">&#39;axes.titlesize&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span>
        <span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span>
        <span class="s1">&#39;legend.fontsize&#39;</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span>
        
        <span class="c1"># Line and marker settings</span>
        <span class="s1">&#39;axes.linewidth&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="s1">&#39;grid.linewidth&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="s1">&#39;lines.linewidth&#39;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s1">&#39;lines.markersize&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        
        <span class="c1"># Layout settings</span>
        <span class="s1">&#39;figure.constrained_layout.use&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        
        <span class="c1"># Remove only top and right spines</span>
        <span class="s1">&#39;axes.spines.top&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        <span class="s1">&#39;axes.spines.right&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        
        <span class="c1"># Remove legend frame</span>
        <span class="s1">&#39;legend.frameon&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
        
        <span class="c1"># Additional settings</span>
        <span class="s1">&#39;figure.autolayout&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;savefig.bbox&#39;</span><span class="p">:</span> <span class="s1">&#39;tight&#39;</span><span class="p">,</span>
        <span class="s1">&#39;savefig.pad_inches&#39;</span><span class="p">:</span> <span class="mf">0.1</span>
    <span class="p">})</span>

<span class="k">def</span> <span class="nf">save_for_book</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">is_vector</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save a figure with book-optimized settings.</span>
<span class="sd">    </span>
<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    fig : matplotlib figure</span>
<span class="sd">        The figure to save</span>
<span class="sd">    filename : str</span>
<span class="sd">        Filename without extension</span>
<span class="sd">    is_vector : bool</span>
<span class="sd">        If True, saves as vector at 1000 dpi. If False, saves as raster at 600 dpi.</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        Additional kwargs to pass to savefig</span>
<span class="sd">    &quot;&quot;&quot;</span>    
    <span class="c1"># Set appropriate DPI and format based on figure type</span>
    <span class="k">if</span> <span class="n">is_vector</span><span class="p">:</span>
        <span class="n">dpi</span> <span class="o">=</span> <span class="mi">1000</span>
        <span class="n">ext</span> <span class="o">=</span> <span class="s1">&#39;.pdf&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dpi</span> <span class="o">=</span> <span class="mi">600</span>
        <span class="n">ext</span> <span class="o">=</span> <span class="s1">&#39;.tif&#39;</span>
    
    <span class="c1"># Save the figure with book settings</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename</span><span class="si">}{</span><span class="n">ext</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="n">dpi</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">make_full_width_fig</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.7</span><span class="p">,</span> <span class="mf">2.9</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">make_half_width_fig</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">2.35</span><span class="p">,</span> <span class="mf">1.45</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">if</span> <span class="n">MAKE_BOOK_FIGURES</span><span class="p">:</span>
    <span class="n">set_book_style</span><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">set_notebook_style</span><span class="p">()</span>

<span class="n">make_full_width_fig</span> <span class="o">=</span> <span class="n">make_full_width_fig</span> <span class="k">if</span> <span class="n">MAKE_BOOK_FIGURES</span> <span class="k">else</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">make_half_width_fig</span> <span class="o">=</span> <span class="n">make_half_width_fig</span> <span class="k">if</span> <span class="n">MAKE_BOOK_FIGURES</span> <span class="k">else</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib_inline</span>
<span class="n">matplotlib_inline</span><span class="o">.</span><span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;paper&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;ticks&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">download</span><span class="p">(</span>
    <span class="n">url</span> <span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">local_filename</span> <span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Download a file from a url.</span>
<span class="sd">    </span>
<span class="sd">    Arguments</span>
<span class="sd">    url            -- The url we want to download.</span>
<span class="sd">    local_filename -- The filemame to write on. If not</span>
<span class="sd">                      specified </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">local_filename</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">local_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">local_filename</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sample_functions</span><span class="p">(</span><span class="n">mean_func</span><span class="p">,</span> <span class="n">kernel_func</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_test</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">nugget</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample functions from a Gaussian process.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        mean_func -- the mean function. It must be a callable that takes a tensor</span>
<span class="sd">            of shape (num_test, dim) and returns a tensor of shape (num_test, 1).</span>
<span class="sd">        kernel_func -- the covariance function. It must be a callable that takes</span>
<span class="sd">            a tensor of shape (num_test, dim) and returns a tensor of shape</span>
<span class="sd">            (num_test, num_test).</span>
<span class="sd">        num_samples -- the number of samples to take. Defaults to 10.</span>
<span class="sd">        num_test -- the number of test points. Defaults to 100.</span>
<span class="sd">        nugget -- a small number required for stability. Defaults to 1e-5.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_test</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">mean_func</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">kernel_func</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">nugget</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span> 
        <span class="n">f</span> <span class="o">=</span> <span class="n">m</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">L</span> <span class="o">@</span> <span class="n">z</span>  
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">f</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                <span class="n">label</span><span class="o">=</span><span class="s1">&#39;sample&#39;</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">trim</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>


<span class="kn">import</span> <span class="nn">gpytorch</span>

<span class="k">class</span> <span class="nc">ExactGP</span><span class="p">(</span><span class="n">gpytorch</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ExactGP</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">train_x</span><span class="p">,</span>
                 <span class="n">train_y</span><span class="p">,</span>
                 <span class="n">likelihood</span><span class="o">=</span><span class="n">gpytorch</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">GaussianLikelihood</span><span class="p">(),</span>
                <span class="n">mean_module</span><span class="o">=</span><span class="n">gpytorch</span><span class="o">.</span><span class="n">means</span><span class="o">.</span><span class="n">ConstantMean</span><span class="p">(),</span>
                <span class="n">covar_module</span><span class="o">=</span><span class="n">ScaleKernel</span><span class="p">(</span><span class="n">RBFKernel</span><span class="p">())</span>
        <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="n">mean_module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">covar_module</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mean_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">covar_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">covar_x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_1d_regression</span><span class="p">(</span>
    <span class="n">x_star</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">f_true</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;$x$&#39;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;$y$&#39;</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot the posterior predictive.</span>
<span class="sd">    </span>
<span class="sd">    Arguments</span>
<span class="sd">    x_start  --  The test points on which to evaluate.</span>
<span class="sd">    model    --  The trained model.</span>
<span class="sd">    </span>
<span class="sd">    Keyword Arguments</span>
<span class="sd">    ax          --  An axes object to write on.</span>
<span class="sd">    f_true      --  The true function.</span>
<span class="sd">    num_samples --  The number of samples.</span>
<span class="sd">    xlabel      --  The x-axis label.</span>
<span class="sd">    ylabel      --  The y-axis label.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f_star</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_star</span><span class="p">)</span>
    <span class="n">m_star</span> <span class="o">=</span> <span class="n">f_star</span><span class="o">.</span><span class="n">mean</span>
    <span class="n">v_star</span> <span class="o">=</span> <span class="n">f_star</span><span class="o">.</span><span class="n">variance</span>
    <span class="n">y_star</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">f_star</span><span class="p">)</span>
    <span class="n">yv_star</span> <span class="o">=</span> <span class="n">y_star</span><span class="o">.</span><span class="n">variance</span>

    <span class="n">f_lower</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">m_star</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_star</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">f_upper</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">m_star</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_star</span><span class="p">)</span>
    <span class="p">)</span>
    
    <span class="n">y_lower</span> <span class="o">=</span> <span class="n">m_star</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">yv_star</span><span class="p">)</span>
    <span class="n">y_upper</span> <span class="o">=</span> <span class="n">m_star</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">yv_star</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train_targets</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="s1">&#39;k.&#39;</span><span class="p">,</span>
            <span class="n">markersize</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">markeredgewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observations&#39;</span>
    <span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">x_star</span><span class="p">,</span>
        <span class="n">m_star</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Posterior mean&#39;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">x_star</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">f_lower</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">f_upper</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Epistemic uncertainty&#39;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">x_star</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">y_lower</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">f_lower</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Aleatory uncertainty&#39;</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">x_star</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">f_upper</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">y_upper</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span>

    
    <span class="k">if</span> <span class="n">f_true</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="n">x_star</span><span class="p">,</span>
            <span class="n">f_true</span><span class="p">(</span><span class="n">x_star</span><span class="p">),</span>
            <span class="s1">&#39;m-.&#39;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True function&#39;</span>
        <span class="p">)</span>
        
    <span class="k">if</span> <span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">f_post_samples</span> <span class="o">=</span> <span class="n">f_star</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="n">x_star</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="n">f_post_samples</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
            <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span>
        <span class="p">)</span>
        <span class="c1"># This is just to add the legend entry</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="p">[],</span>
            <span class="p">[],</span>
            <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
            <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Posterior samples&quot;</span>
        <span class="p">)</span>
        
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">trim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">m_star</span><span class="o">=</span><span class="n">m_star</span><span class="p">,</span> <span class="n">v_star</span><span class="o">=</span><span class="n">v_star</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train the model.</span>

<span class="sd">    Arguments</span>
<span class="sd">    model   --  The model to train.</span>
<span class="sd">    train_x --  The training inputs.</span>
<span class="sd">    train_y --  The training labels.</span>
<span class="sd">    n_iter  --  The number of iterations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">line_search_fn</span><span class="o">=</span><span class="s1">&#39;strong_wolfe&#39;</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">likelihood</span>
    <span class="n">mll</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">mlls</span><span class="o">.</span><span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">mll</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Iter </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">:</span><span class="s1">3d</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">n_iter</span><span class="si">}</span><span class="s1"> - Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="student-details">
<h2>Student details<a class="headerlink" href="#student-details" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>First Name:</strong></p></li>
<li><p><strong>Last Name:</strong></p></li>
<li><p><strong>Email:</strong></p></li>
</ul>
</section>
<section id="problem-1-defining-priors-on-function-spaces">
<h2>Problem 1 - Defining priors on function spaces<a class="headerlink" href="#problem-1-defining-priors-on-function-spaces" title="Link to this heading">#</a></h2>
<p>In this problem, we will explore further how Gaussian processes can be used to define probability measures over function spaces.
To this end, assume that there is a 1D function, call if <span class="math notranslate nohighlight">\(f(x)\)</span>, which we do not know.
For simplicity, assume that <span class="math notranslate nohighlight">\(x\)</span> takes values in <span class="math notranslate nohighlight">\([0,1]\)</span>.
We will employ Gaussian process regression to encode our state of knowledge about <span class="math notranslate nohighlight">\(f(x)\)</span> and sample some possibilities.
For each of the cases below:</p>
<ul class="simple">
<li><p>Assume that <span class="math notranslate nohighlight">\(f\sim \operatorname{GP}(m, k)\)</span> and pick a mean (<span class="math notranslate nohighlight">\(m(x)\)</span>) and a covariance function <span class="math notranslate nohighlight">\(f(x)\)</span> that match the provided information.</p></li>
<li><p>Write code that samples a few times (up to five) the values of <span class="math notranslate nohighlight">\(f(x)\)</span> at 100 equidistant points between 0 and 1.</p></li>
</ul>
<section id="part-a-super-smooth-function-with-known-length-scale">
<h3>Part A - Super smooth function with known length scale<a class="headerlink" href="#part-a-super-smooth-function-with-known-length-scale" title="Link to this heading">#</a></h3>
<p>Assume that you hold the following beliefs</p>
<ul class="simple">
<li><p>You know that <span class="math notranslate nohighlight">\(f(x)\)</span> has as many derivatives as you want and they are all continuous</p></li>
<li><p>You don’t know if <span class="math notranslate nohighlight">\(f(x)\)</span> has a specific trend.</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> has “wiggles” that are approximatly of size <span class="math notranslate nohighlight">\(\Delta x=0.1\)</span>.</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> is between -4 and 4.</p></li>
</ul>
<p><strong>Answer:</strong></p>
<p><strong>I am doing this for you so that you have a concrete example of what is requested.</strong></p>
<p>The mean function should be:</p>
<div class="math notranslate nohighlight">
\[
m(x) = 0.
\]</div>
<p>The covariance function should be a squared exponential:</p>
<div class="math notranslate nohighlight">
\[
k(x,x') = s^2\exp\left\{-\frac{(x-x')^2}{2\ell^2}\right\},
\]</div>
<p>with variance:</p>
<div class="math notranslate nohighlight">
\[
s^2 = k(x,x) = \mathbb{V}[f(x)] = 4,
\]</div>
<p>and lengthscale <span class="math notranslate nohighlight">\(\ell = 0.1\)</span>.
We chose the variance to be 4.0 so that with (about) 95% probability, the values of <span class="math notranslate nohighlight">\(f(x)\)</span> are between -4 and 4.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">gpytorch</span>
<span class="kn">from</span> <span class="nn">gpytorch.kernels</span> <span class="kn">import</span> <span class="n">RBFKernel</span><span class="p">,</span> <span class="n">ScaleKernel</span>

<span class="c1"># Define the covariance function</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">ScaleKernel</span><span class="p">(</span><span class="n">RBFKernel</span><span class="p">())</span>
<span class="n">k</span><span class="o">.</span><span class="n">outputscale</span> <span class="o">=</span> <span class="mf">4.0</span>
<span class="n">k</span><span class="o">.</span><span class="n">base_kernel</span><span class="o">.</span><span class="n">lengthscale</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># Define the mean function</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">means</span><span class="o">.</span><span class="n">ConstantMean</span><span class="p">()</span>
<span class="n">mean</span><span class="o">.</span><span class="n">constant</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="c1"># Sample functions</span>
<span class="n">sample_functions</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">nugget</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/1ad8431dc02857149d812a10c5be5fec7c71343ca45a2e12f3720700a2cba813.svg" src="../_images/1ad8431dc02857149d812a10c5be5fec7c71343ca45a2e12f3720700a2cba813.svg" />
</div>
</div>
</section>
<section id="part-b-super-smooth-function-with-known-ultra-small-length-scale">
<h3>Part B - Super smooth function with known ultra-small length scale<a class="headerlink" href="#part-b-super-smooth-function-with-known-ultra-small-length-scale" title="Link to this heading">#</a></h3>
<p>Assume that you hold the following beliefs</p>
<ul class="simple">
<li><p>You know that <span class="math notranslate nohighlight">\(f(x)\)</span> has as many derivatives as you want and they are all continuous</p></li>
<li><p>You don’t know if <span class="math notranslate nohighlight">\(f(x)\)</span> has a specific trend.</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> has “wiggles” that are approximatly of size <span class="math notranslate nohighlight">\(\Delta x=0.05\)</span>.</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> is between -3 and 3.</p></li>
</ul>
<p><strong>Answer:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="part-c-continuous-function-with-known-length-scale">
<h3>Part C - Continuous function with known length scale<a class="headerlink" href="#part-c-continuous-function-with-known-length-scale" title="Link to this heading">#</a></h3>
<p>Assume that you hold the following beliefs</p>
<ul class="simple">
<li><p>You know that <span class="math notranslate nohighlight">\(f(x)\)</span> is continuous, nowhere differentiable.</p></li>
<li><p>You don’t know if <span class="math notranslate nohighlight">\(f(x)\)</span> has a specific trend.</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> has “wiggles” that are approximately of size <span class="math notranslate nohighlight">\(\Delta x=0.1\)</span>.</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> is between -5 and 5.</p></li>
</ul>
<p>Hint: Use <code class="docutils literal notranslate"><span class="pre">gpytorch.kernels.MaternKernel</span></code> with <span class="math notranslate nohighlight">\(\nu=1/2\)</span>.</p>
<p><strong>Answer:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="part-d-smooth-periodic-function-with-known-length-scale">
<h3>Part D - Smooth periodic function with known length scale<a class="headerlink" href="#part-d-smooth-periodic-function-with-known-length-scale" title="Link to this heading">#</a></h3>
<p>Assume that you hold the following beliefs</p>
<ul class="simple">
<li><p>You know that <span class="math notranslate nohighlight">\(f(x)\)</span> is smooth.</p></li>
<li><p>You know that <span class="math notranslate nohighlight">\(f(x)\)</span> is periodic with period 0.1.</p></li>
<li><p>You don’t know if <span class="math notranslate nohighlight">\(f(x)\)</span> has a specific trend.</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> has “wiggles” that are approximately of size <span class="math notranslate nohighlight">\(\Delta x=0.5\)</span> of the period.</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> is between -5 and 5.</p></li>
</ul>
<p>Hint: Use <code class="docutils literal notranslate"><span class="pre">gpytorch.kernels.PeriodicKernel</span></code>.</p>
<p><strong>Answer:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="part-e-smooth-periodic-function-with-known-length-scale">
<h3>Part E - Smooth periodic function with known length scale<a class="headerlink" href="#part-e-smooth-periodic-function-with-known-length-scale" title="Link to this heading">#</a></h3>
<p>Assume that you hold the following beliefs</p>
<ul class="simple">
<li><p>You know that <span class="math notranslate nohighlight">\(f(x)\)</span> is smooth.</p></li>
<li><p>You know that <span class="math notranslate nohighlight">\(f(x)\)</span> is periodic with period 0.1.</p></li>
<li><p>You don’t know if <span class="math notranslate nohighlight">\(f(x)\)</span> has a specific trend.</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> has “wiggles” that are approximately of size <span class="math notranslate nohighlight">\(\Delta x=0.1\)</span> of the period (<strong>the only thing that is different compared to D</strong>).</p></li>
<li><p>You think that <span class="math notranslate nohighlight">\(f(x)\)</span> is between -5 and 5.</p></li>
</ul>
<p>Hint: Use <code class="docutils literal notranslate"><span class="pre">gpytorch.kernels.PeriodicKernel</span></code>.</p>
<p><strong>Answer:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="part-f-the-sum-of-two-functions">
<h3>Part F - The sum of two functions<a class="headerlink" href="#part-f-the-sum-of-two-functions" title="Link to this heading">#</a></h3>
<p>Assume that you hold the following beliefs</p>
<ul class="simple">
<li><p>You know that <span class="math notranslate nohighlight">\(f(x) = f_1(x) + f_2(x)\)</span>, where:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(f_1(x)\)</span> is smooth with variance 2 and length scale 0.5</p></li>
<li><p><span class="math notranslate nohighlight">\(f_2(x)\)</span> is continuous, nowhere differentiable with variance 0.1 and length scale 0.1</p></li>
</ul>
</li>
</ul>
<p>Hint: Use must create a new covariance function that is the sum of two other covariances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="part-g-the-product-of-two-functions">
<h3>Part G - The product of two functions<a class="headerlink" href="#part-g-the-product-of-two-functions" title="Link to this heading">#</a></h3>
<p>Assume that you hold the following beliefs</p>
<ul class="simple">
<li><p>You know that <span class="math notranslate nohighlight">\(f(x) = f_1(x)f_2(x)\)</span>, where:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(f_1(x)\)</span> is smooth, periodic (period = 0.1), length scale 0.1 (relative to the period), and variance 2.</p></li>
<li><p><span class="math notranslate nohighlight">\(f_2(x)\)</span> is smooth with length scale 0.5 and variance 1.</p></li>
</ul>
</li>
</ul>
<p>Hint: Use must create a new covariance function that is the product of two other covariances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="problem-2">
<h2>Problem 2<a class="headerlink" href="#problem-2" title="Link to this heading">#</a></h2>
<p>The National Oceanic and Atmospheric Administration (NOAA) has been measuring the levels of atmospheric CO2 at the Mauna Loa, Hawaii. The measurements start in March 1958 and go back to January 2016.
The data can be found <a class="reference external" href="http://www.esrl.noaa.gov/gmd/ccgg/trends/data.html">here</a>.
The Python cell below downloads and plots the data set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://github.com/PredictiveScienceLab/data-analytics-se/raw/master/lecturebook/data/mauna_loa_co2.txt&quot;</span>
<span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;mauna_loa_co2.txt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#load data </span>
<span class="n">t</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1">#time (in decimal dates)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">4</span><span class="p">]</span>  <span class="c1">#CO2 level (mole fraction in dry air, micromol/mol, abbreviated as ppm)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$t$ (year)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$y$ (CO2 level in ppm)&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">trim</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5db350ee886b2d98c45bac190d02de8f30d666b8d496a078968ad9508ddc02e6.svg" src="../_images/5db350ee886b2d98c45bac190d02de8f30d666b8d496a078968ad9508ddc02e6.svg" />
</div>
</div>
<p>Overall, we observe a steady growth of CO2 levels. The wiggles correspond to seasonal changes. Since most of the population inhabits the northern hemisphere, fuel consumption increases during the northern winters, and CO2 emissions follow. Our goal is to study this dataset with Gaussian process regression. Specifically, we would like to predict the evolution of the CO2 levels from Feb 2018 to Feb 2028 and quantify our uncertainty about this prediction.</p>
<p>Working with a scaled version of the inputs and outputs is always a good idea. We are going to scale the times as follows:</p>
<div class="math notranslate nohighlight">
\[
t_s = t - t_{\min}.
\]</div>
<p>So, time is still in fractional years, but we start counting at zero instead of 1950.
We scale the <span class="math notranslate nohighlight">\(y\)</span>’s as:</p>
<div class="math notranslate nohighlight">
\[
y_s = \frac{y - y_{\min}}{y_{\max}-y_{\min}}.
\]</div>
<p>This takes all the <span class="math notranslate nohighlight">\(y\)</span> between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>.
Here is what the scaled data look like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t_s</span> <span class="o">=</span> <span class="n">t</span> <span class="o">-</span> <span class="n">t</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">y_s</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_s</span><span class="p">,</span> <span class="n">y_s</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$t_s$ (Scaled year)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$y_s$ (Scaled CO2 level)&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">trim</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/98e5294f327ccad9570f68ace3e1002f84270c30ef2b1c943ed623fd27ac0241.svg" src="../_images/98e5294f327ccad9570f68ace3e1002f84270c30ef2b1c943ed623fd27ac0241.svg" />
</div>
</div>
<p>Work with the scaled data in what follows as you develop your model.
Scale back to the original units for your final predictions.</p>
</section>
<section id="part-a-naive-approach">
<h2>Part A - Naive approach<a class="headerlink" href="#part-a-naive-approach" title="Link to this heading">#</a></h2>
<p>Use a zero mean Gaussian process with a squared exponential covariance function to fit the data and make the required prediction (ten years after the last observation).</p>
<p><strong>Answer:</strong></p>
<p><strong>Again, this is done for you so that you have a concrete example of what is requested.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cov_module</span> <span class="o">=</span> <span class="n">ScaleKernel</span><span class="p">(</span><span class="n">RBFKernel</span><span class="p">())</span>
<span class="n">mean_module</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">means</span><span class="o">.</span><span class="n">ConstantMean</span><span class="p">()</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">t_s</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_s</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">naive_model</span> <span class="o">=</span> <span class="n">ExactGP</span><span class="p">(</span>
    <span class="n">train_x</span><span class="p">,</span>
    <span class="n">train_y</span><span class="p">,</span>
    <span class="n">mean_module</span><span class="o">=</span><span class="n">mean_module</span><span class="p">,</span>
    <span class="n">covar_module</span><span class="o">=</span><span class="n">cov_module</span>
<span class="p">)</span>
<span class="n">train</span><span class="p">(</span><span class="n">naive_model</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.8545, grad_fn=&lt;NegBackward0&gt;)
tensor(0.7392, grad_fn=&lt;NegBackward0&gt;)
tensor(-0.5164, grad_fn=&lt;NegBackward0&gt;)
tensor(-1.7390, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.1109, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.2523, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.0013, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.2894, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3039, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3159, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3302, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3335, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.2837, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3380, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3401, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3443, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3464, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3477, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3481, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3505, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3518, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3526, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3527, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3529, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3531, grad_fn=&lt;NegBackward0&gt;)
Iter   1/10 - Loss: 0.854
tensor(-2.3531, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3537, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3538, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3542, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3540, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3539, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
Iter   2/10 - Loss: -2.353
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3542, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3540, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3539, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
Iter   3/10 - Loss: -2.354
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3542, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3540, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3539, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
Iter   4/10 - Loss: -2.354
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3542, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3540, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3539, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
Iter   5/10 - Loss: -2.354
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3542, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3540, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3539, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
Iter   6/10 - Loss: -2.354
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3542, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3540, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3539, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
Iter   7/10 - Loss: -2.354
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3542, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3540, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3539, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
Iter   8/10 - Loss: -2.354
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3542, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3540, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3539, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
Iter   9/10 - Loss: -2.354
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3541, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3542, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3540, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3539, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
tensor(-2.3543, grad_fn=&lt;NegBackward0&gt;)
Iter  10/10 - Loss: -2.354
</pre></div>
</div>
</div>
</div>
<p>Predict everything:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_star</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plot_1d_regression</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">naive_model</span><span class="p">,</span> <span class="n">x_star</span><span class="o">=</span><span class="n">x_star</span><span class="p">,</span> 
                   <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;$t_s$ (Scaled year)&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;$y_s$ (Scaled CO2 level)&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e237a51cd6257f175474d58e43b68597e9e10af565f64a81eff01a9c9e144dc4.svg" src="../_images/e237a51cd6257f175474d58e43b68597e9e10af565f64a81eff01a9c9e144dc4.svg" />
</div>
</div>
<p>Notice that the squared exponential covariance captures the long terms but fails to capture the seasonal fluctuations. The seasonal fluctuations are treated as noise. This is wrong. You will have to fix this in the next part.</p>
</section>
<section id="part-b-improving-the-prior-covariance">
<h2>Part B - Improving the prior covariance<a class="headerlink" href="#part-b-improving-the-prior-covariance" title="Link to this heading">#</a></h2>
<p>Now, use the ideas of Problem 1 to develop a covariance function that exhibits the following characteristics visible in the data (call <span class="math notranslate nohighlight">\(f(x)\)</span> the scaled CO2 level.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(x)\)</span> is smooth.</p></li>
<li><p><span class="math notranslate nohighlight">\(f(x)\)</span> has a clear trend with a multi-year length scale.</p></li>
<li><p><span class="math notranslate nohighlight">\(f(x)\)</span> has seasonal fluctuations with a period of one year.</p></li>
<li><p><span class="math notranslate nohighlight">\(f(x)\)</span> exhibits small fluctuations within its period.</p></li>
</ul>
<p>There is more than one correct answer.</p>
<p><strong>Answer:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cov_module</span> <span class="o">=</span> <span class="c1"># Your choice of covariance here</span>
<span class="n">mean_module</span> <span class="o">=</span> <span class="c1"># Your choice of mean here</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ExactGP</span><span class="p">(</span>
    <span class="n">train_x</span><span class="p">,</span>
    <span class="n">train_y</span><span class="p">,</span>
    <span class="n">mean_module</span><span class="o">=</span><span class="n">mean_module</span><span class="p">,</span>
    <span class="n">covar_module</span><span class="o">=</span><span class="n">cov_module</span>
<span class="p">)</span>
<span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Plot using the following block:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_1d_regression</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">naive_model</span><span class="p">,</span> <span class="n">x_star</span><span class="o">=</span><span class="n">train_x</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="part-c-predicting-the-future">
<h2>Part C - Predicting the future<a class="headerlink" href="#part-c-predicting-the-future" title="Link to this heading">#</a></h2>
<p>How does your model predict the future? Why is it better than the naive model?</p>
<p><strong>Answer:</strong>
<em>Your answer here</em>
<br><br></p>
</section>
<section id="part-d-bayesian-information-criterion">
<h2>Part D - Bayesian information criterion<a class="headerlink" href="#part-d-bayesian-information-criterion" title="Link to this heading">#</a></h2>
<p>As we have seen in earlier lectures, the Bayesian informationc criterion (BIC), see <a class="reference external" href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">this</a>, can bse used to compare two models.
The criterion says that one should:</p>
<ul class="simple">
<li><p>fit the models with maximum likelihood,</p></li>
<li><p>and compute the quantity:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\text{BIC} = d\ln(n) - 2\ln(\hat{L}),
\]</div>
<p>where <span class="math notranslate nohighlight">\(d\)</span> is the number of model parameters, and <span class="math notranslate nohighlight">\(\hat{L}\)</span> the maximum likelihood.</p>
<ul class="simple">
<li><p>pick the model with the smallest BIC.</p></li>
</ul>
<p>Use BIC to show that the model you constructed in Part C is indeed better than the naïve model of Part A.</p>
<p><strong>Answer:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hint: You can find the parameters of a model like this</span>
<span class="nb">list</span><span class="p">(</span><span class="n">naive_model</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parameter containing:
 tensor([-7.8281], requires_grad=True),
 Parameter containing:
 tensor(0.8690, requires_grad=True),
 Parameter containing:
 tensor(-1.2034, requires_grad=True),
 Parameter containing:
 tensor([[32.5616]], requires_grad=True)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">naive_model</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hint: You can find the (marginal) log likelihood of a model like this</span>
<span class="n">mll</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">mlls</span><span class="o">.</span><span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">naive_model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">naive_model</span><span class="p">)</span>
<span class="n">log_like</span> <span class="o">=</span> <span class="n">mll</span><span class="p">(</span><span class="n">naive_model</span><span class="p">(</span><span class="n">train_x</span><span class="p">),</span> <span class="n">train_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">log_like</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(2.3863, grad_fn=&lt;DivBackward0&gt;)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ibilion/.pyenv/versions/3.11.6/lib/python3.11/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hint: The BIC is</span>
<span class="n">bic</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">log_like</span> <span class="o">+</span> <span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bic</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(21.5389, grad_fn=&lt;AddBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="problem-3-bayesian-global-optimization">
<h2>Problem 3 - Bayesian Global Optimization<a class="headerlink" href="#problem-3-bayesian-global-optimization" title="Link to this heading">#</a></h2>
<p>As a toy example, we will apply Bayesian Optimization to some synthetic data. We will study the classic <a class="reference external" href="https://www.sfu.ca/~ssurjano/forretal08.html">Forrester function</a></p>
<div class="math notranslate nohighlight">
\[
f(x) = (6x - 2)^2\sin(12x - 4)
\]</div>
<p>on the domain <span class="math notranslate nohighlight">\([0,1]\)</span>. We will also <span class="math notranslate nohighlight">\(\textit{standardize}\)</span> the output of the function, such that it has a mean of <span class="math notranslate nohighlight">\(0\)</span> and a standard deviation of <span class="math notranslate nohighlight">\(1\)</span>. This is a good habit to get into when working with Gaussian processes. We will stick to a zero mean prior, so ensuring that the data has a mean of zero aligns with this.</p>
<p>The mean and standard deviation of this function on <span class="math notranslate nohighlight">\([0,1]\)</span> are known:
$<span class="math notranslate nohighlight">\(
\begin{aligned}
 \mu &amp;= 0.45321 \\
 \mathrm{std} &amp;= 4.4248
\end{aligned}
\)</span>$</p>
<p>The goal is to find the minimum of this objective function.</p>
<section id="part-a-visualize-the-function-and-generate-some-data">
<h3>Part A - Visualize the function and generate some data<a class="headerlink" href="#part-a-visualize-the-function-and-generate-some-data" title="Link to this heading">#</a></h3>
<p>Let’s visualize the ground truth objective function and our synthetic data. First, code the <strong>standardized</strong> Forrester function in a way that allows for <strong>minimization</strong> using our Bayesian global <strong>maximization</strong> algorithms from the lecture book.</p>
<p>(Hint: to minimize a function, you can maximize the negative of that function)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
<span class="k">def</span> <span class="nf">Forrester</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;ground truth function to optimize&quot;&quot;&quot;</span>

    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># making synthetic data from your function</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">539</span><span class="p">)</span>

<span class="n">sigma_noise</span> <span class="o">=</span> <span class="mf">0.025</span>

<span class="c1"># noisy version of the above function</span>
<span class="n">F_noisy</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span>
    <span class="n">Forrester</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">sigma_noise</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="p">)</span>

<span class="c1"># generate synthetic data</span>
<span class="n">n_init</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_init</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">F_noisy</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Plot it on <span class="math notranslate nohighlight">\([0,1]\)</span> and make sure to include the data points</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="part-b-set-up-the-gaussian-process-model">
<h3>Part B - Set up the Gaussian process model<a class="headerlink" href="#part-b-set-up-the-gaussian-process-model" title="Link to this heading">#</a></h3>
<p>Set up the Gaussian process model.</p>
<p>Specifically, use this:</p>
<ol class="arabic simple">
<li><p>A Matern covariance kernel</p></li>
<li><p>Zero mean function</p></li>
<li><p>A Gaussian likelihood model</p></li>
<li><p>Set the likelihood noise to the ground truth noise (since we assume it is known)</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="now-train-the-model-on-the-data-points-to-optimize-the-rest-of-the-hyperparameters">
<h3>Now train the model on the data points to optimize the rest of the hyperparameters<a class="headerlink" href="#now-train-the-model-on-the-data-points-to-optimize-the-rest-of-the-hyperparameters" title="Link to this heading">#</a></h3>
<p>Here is the training function you should be using:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train the model.</span>

<span class="sd">    Arguments</span>
<span class="sd">    model   --  The model to train.</span>
<span class="sd">    train_x --  The training inputs.</span>
<span class="sd">    train_y --  The training labels.</span>
<span class="sd">    n_iter  --  The number of iterations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">line_search_fn</span><span class="o">=</span><span class="s1">&#39;strong_wolfe&#39;</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">likelihood</span>
    <span class="n">mll</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">mlls</span><span class="o">.</span><span class="n">ExactMarginalLogLikelihood</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">mll</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Iter </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">:</span><span class="s1">3d</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">n_iter</span><span class="si">}</span><span class="s1"> - Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-the-trained-model-along-with-some-sample-paths">
<h3>Plot the trained model along with some sample paths<a class="headerlink" href="#plot-the-trained-model-along-with-some-sample-paths" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-the-uncertainty-about-the-optimization-problem-for-the-initial-gaussian-process-surrogate">
<h3>Plot the uncertainty about the optimization problem for the initial Gaussian process surrogate<a class="headerlink" href="#plot-the-uncertainty-about-the-optimization-problem-for-the-initial-gaussian-process-surrogate" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="part-c-expected-improvement-with-noise">
<h2>Part C - Expected improvement with noise<a class="headerlink" href="#part-c-expected-improvement-with-noise" title="Link to this heading">#</a></h2>
<p>Solve the optimization problem by applying the expected improvement with noise algorithm</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_1d_regression</span><span class="p">(</span>
    <span class="n">x_star</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">f_true</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot the posterior predictive.</span>
<span class="sd">    </span>
<span class="sd">    Arguments</span>
<span class="sd">    x_start  --  The test points on which to evaluate.</span>
<span class="sd">    model    --  The trained model.</span>
<span class="sd">    </span>
<span class="sd">    Keyword Arguments</span>
<span class="sd">    ax          --  An axes object to write on.</span>
<span class="sd">    f_true      --  The true function.</span>
<span class="sd">    num_samples --  The number of samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f_star</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_star</span><span class="p">)</span>
    <span class="n">m_star</span> <span class="o">=</span> <span class="n">f_star</span><span class="o">.</span><span class="n">mean</span>
    <span class="n">v_star</span> <span class="o">=</span> <span class="n">f_star</span><span class="o">.</span><span class="n">variance</span>
    <span class="n">y_star</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">f_star</span><span class="p">)</span>
    <span class="n">yv_star</span> <span class="o">=</span> <span class="n">y_star</span><span class="o">.</span><span class="n">variance</span>

    <span class="n">f_lower</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">m_star</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_star</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">f_upper</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">m_star</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_star</span><span class="p">)</span>
    <span class="p">)</span>
    
    <span class="n">y_lower</span> <span class="o">=</span> <span class="n">m_star</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">yv_star</span><span class="p">)</span>
    <span class="n">y_upper</span> <span class="o">=</span> <span class="n">m_star</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">yv_star</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train_targets</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="s1">&#39;kx&#39;</span><span class="p">,</span>
            <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">markeredgewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observations&#39;</span>
    <span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">x_star</span><span class="p">,</span>
        <span class="n">m_star</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$m_n(x)$&#39;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">x_star</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">f_lower</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">f_upper</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$f(\mathbf</span><span class="si">{x}</span><span class="s1">^*)$ 95% pred.&#39;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">x_star</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">y_lower</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">f_lower</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$y^*$ 95% pred.&#39;</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">x_star</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">f_upper</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">y_upper</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span>

    
    <span class="k">if</span> <span class="n">f_true</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="n">x_star</span><span class="p">,</span>
            <span class="n">f_true</span><span class="p">(</span><span class="n">x_star</span><span class="p">),</span>
            <span class="s1">&#39;m-.&#39;</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True function&#39;</span>
        <span class="p">)</span>
        
    <span class="k">if</span> <span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">f_post_samples</span> <span class="o">=</span> <span class="n">f_star</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
            <span class="n">sample_shape</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="n">x_star</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="n">f_post_samples</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
            <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
            <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span>
        <span class="p">)</span>
        <span class="c1"># This is just to add the legend entry</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="p">[],</span>
            <span class="p">[],</span>
            <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
            <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Posterior samples&quot;</span>
        <span class="p">)</span>
        
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">(</span><span class="n">trim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">m_star</span><span class="p">,</span> <span class="n">v_star</span>

<span class="k">def</span> <span class="nf">plot_iaf</span><span class="p">(</span>
    <span class="n">x_star</span><span class="p">,</span>
    <span class="n">gpr</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">,</span>
    <span class="n">alpha_params</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">f_true</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">iaf_label</span><span class="o">=</span><span class="s2">&quot;Information Acquisition Function&quot;</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot the information acquisition function.</span>
<span class="sd">    </span>
<span class="sd">    Arguments</span>
<span class="sd">    x_star       -- A set of points to plot on.</span>
<span class="sd">    gpr          -- A rained Gaussian process regression</span>
<span class="sd">                    object.</span>
<span class="sd">    alpha        -- The information acquisition function.</span>
<span class="sd">                    This assumed to be a function of the</span>
<span class="sd">                    posterior mean and standard deviation.</span>
<span class="sd">              </span>
<span class="sd">    Keyword Arguments</span>
<span class="sd">    ax           -- An axes object to plot on.</span>
<span class="sd">    f_true       -- The true function - if available.</span>
<span class="sd">    alpha_params -- Extra parameters to the information</span>
<span class="sd">                    acquisition function.</span>
<span class="sd">    ax           -- An axes object to plot on.</span>
<span class="sd">    f_true       -- The true function - if available.</span>
<span class="sd">    iaf_label    -- The label for the information acquisition</span>
<span class="sd">                    function. Default is &quot;Information Acquisition&quot;.</span>
<span class="sd">    </span>
<span class="sd">    The evaluation of the information acquisition function</span>
<span class="sd">    is as follows:</span>
<span class="sd">    </span>
<span class="sd">        af_values = alpha(mu, sigma, y_max, **alpha_params)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
        <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">k</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">alpha_params</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">)</span>
    <span class="p">)</span>
    
    <span class="n">m</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">plot_1d_regression</span><span class="p">(</span>
        <span class="n">x_star</span><span class="p">,</span>
        <span class="n">gpr</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
        <span class="n">f_true</span><span class="o">=</span><span class="n">f_true</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">af_values</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">gpr</span><span class="o">.</span><span class="n">train_targets</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="o">**</span><span class="n">alpha_params</span><span class="p">)</span>
    <span class="n">next_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">af_values</span><span class="p">)</span>
    <span class="n">next_x</span> <span class="o">=</span> <span class="n">x_star</span><span class="p">[</span><span class="n">next_id</span><span class="p">]</span>
    <span class="n">af_max</span> <span class="o">=</span> <span class="n">af_values</span><span class="p">[</span><span class="n">next_id</span><span class="p">]</span>
    
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_star</span><span class="p">,</span> <span class="n">af_values</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span>
        <span class="n">iaf_label</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">get_yticklabels</span><span class="p">(),</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">next_x</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">af_max</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">100</span><span class="p">),</span>
        <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">ei</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">ymax</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the expected improvement.</span>
<span class="sd">    </span>
<span class="sd">    Arguments</span>
<span class="sd">    m     -- The predictive mean at the test points.</span>
<span class="sd">    sigma -- The predictive standard deviation at</span>
<span class="sd">             the test points.</span>
<span class="sd">    ymin  -- The minimum observed value (so far).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">m</span> <span class="o">-</span> <span class="n">ymax</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">diff</span> <span class="o">/</span> <span class="n">sigma</span>
    <span class="n">ei</span> <span class="o">=</span> <span class="p">(</span> <span class="n">diff</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="o">+</span> 
          <span class="n">sigma</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">ei</span><span class="p">[</span><span class="n">sigma</span> <span class="o">&lt;=</span> <span class="mf">0.</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">return</span> <span class="n">ei</span>

<span class="k">def</span> <span class="nf">maximize</span><span class="p">(</span>
    <span class="n">f</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">X_design</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">,</span>
    <span class="n">alpha_params</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">max_it</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">optimize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimize a function using a limited number of evaluations.</span>
<span class="sd">    </span>
<span class="sd">    Arguments</span>
<span class="sd">    f            -- The function to optimize.</span>
<span class="sd">    gpr          -- A Gaussian process model to use for representing</span>
<span class="sd">                    our state of knowledge.</span>
<span class="sd">    X_design     -- The set of candidate points for identifying the</span>
<span class="sd">                    maximum.</span>
<span class="sd">    alpha        -- The information acquisition function.</span>
<span class="sd">                    This assumed to be a function of the</span>
<span class="sd">                    posterior mean and standard deviation.</span>
<span class="sd">    </span>
<span class="sd">    Keyword Arguments</span>
<span class="sd">    alpha_params -- Extra parameters to the information</span>
<span class="sd">                    acquisition function.</span>
<span class="sd">    max_it       -- The maximum number of iterations.</span>
<span class="sd">    optimize     -- Whether or not to optimize the hyper-parameters.</span>
<span class="sd">    plot         -- Determines how often to plot. Make it one</span>
<span class="sd">                    to plot at each iteration. Make it max_it</span>
<span class="sd">                    to plot at the last iteration.</span>
<span class="sd">                    </span>
<span class="sd">    The rest of the keyword arguments are passed to plot_iaf().</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">af_all</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_it</span><span class="p">):</span>
        <span class="c1"># Predict</span>
        <span class="n">f_design</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_design</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">f_design</span><span class="o">.</span><span class="n">mean</span>
        <span class="n">sigma2</span> <span class="o">=</span> <span class="n">f_design</span><span class="o">.</span><span class="n">variance</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma2</span><span class="p">)</span>
        
        <span class="c1"># Evaluate information acquisition function</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train_targets</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">af_values</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">(</span>
            <span class="n">m</span><span class="p">,</span>
            <span class="n">sigma</span><span class="p">,</span>
            <span class="n">y_train</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span>
            <span class="o">**</span><span class="n">alpha_params</span>
        <span class="p">)</span>
        
        <span class="c1"># Find best point to include</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">af_values</span><span class="p">)</span>
        <span class="n">af_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">af_values</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        
        <span class="n">new_x</span> <span class="o">=</span> <span class="n">X_design</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">new_y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
        <span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">train_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]])</span>
        <span class="n">train_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">model</span><span class="o">.</span><span class="n">train_targets</span><span class="p">,</span> <span class="n">new_y</span><span class="p">])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">set_train_data</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">optimize</span><span class="p">:</span>
            <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
        <span class="c1"># Plot if required</span>
        <span class="k">if</span> <span class="n">count</span> <span class="o">%</span> <span class="n">plot</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;ax&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">ax</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">ax</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
            <span class="n">plot_iaf</span><span class="p">(</span>
                <span class="n">X_design</span><span class="p">,</span>
                <span class="n">model</span><span class="p">,</span>
                <span class="n">alpha</span><span class="p">,</span>
                <span class="n">alpha_params</span><span class="o">=</span><span class="n">alpha_params</span><span class="p">,</span>
                <span class="n">f_true</span><span class="o">=</span><span class="n">f</span><span class="p">,</span>
                <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;N=</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2">, &quot;</span> <span class="o">+</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_title</span><span class="p">()</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">af_all</span>
</pre></div>
</div>
</div>
</div>
<section id="run-the-algorithm">
<h3>run the algorithm<a class="headerlink" href="#run-the-algorithm" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># your code here</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="how-many-iterations-does-the-algorithm-take-to-converge-that-is-how-quickly-does-it-identify-the-critical-point">
<h3>How many iterations does the algorithm take to converge? That is, how quickly does it identify the critical point?<a class="headerlink" href="#how-many-iterations-does-the-algorithm-take-to-converge-that-is-how-quickly-does-it-identify-the-critical-point" title="Link to this heading">#</a></h3>
<p>Your answer here</p>
</section>
<section id="quantify-the-uncertainty-about-the-solution-to-the-optimization-problem-with-the-trained-gaussian-process">
<h3>Quantify the uncertainty about the solution to the optimization problem with the trained Gaussian process<a class="headerlink" href="#quantify-the-uncertainty-about-the-solution-to-the-optimization-problem-with-the-trained-gaussian-process" title="Link to this heading">#</a></h3>
<p>Your answer here</p>
</section>
</section>
<section id="part-d-testing-your-intuition">
<h2>Part D - Testing your intuition<a class="headerlink" href="#part-d-testing-your-intuition" title="Link to this heading">#</a></h2>
<p>In a real-world scenario, you may not be able to keep running experiments until the optimization problem has obviously converged due to time, budget considerations, etc. Imagine yourself in a situation where you are deciding whether or not to query the blackbox function an additional time.</p>
<p>Describe (in words) how you could make this decision using the principles you’ve learned in this course.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./homework"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="homework-05.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Homework 5</p>
      </div>
    </a>
    <a class="right-next"
       href="homework-07.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Homework 7</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instructions">Instructions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#student-details">Student details</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1-defining-priors-on-function-spaces">Problem 1 - Defining priors on function spaces</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-a-super-smooth-function-with-known-length-scale">Part A - Super smooth function with known length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-b-super-smooth-function-with-known-ultra-small-length-scale">Part B - Super smooth function with known ultra-small length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-c-continuous-function-with-known-length-scale">Part C - Continuous function with known length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-d-smooth-periodic-function-with-known-length-scale">Part D - Smooth periodic function with known length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-e-smooth-periodic-function-with-known-length-scale">Part E - Smooth periodic function with known length scale</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-f-the-sum-of-two-functions">Part F - The sum of two functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-g-the-product-of-two-functions">Part G - The product of two functions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2">Problem 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-a-naive-approach">Part A - Naive approach</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-b-improving-the-prior-covariance">Part B - Improving the prior covariance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-c-predicting-the-future">Part C - Predicting the future</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-d-bayesian-information-criterion">Part D - Bayesian information criterion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3-bayesian-global-optimization">Problem 3 - Bayesian Global Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-a-visualize-the-function-and-generate-some-data">Part A - Visualize the function and generate some data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#part-b-set-up-the-gaussian-process-model">Part B - Set up the Gaussian process model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#now-train-the-model-on-the-data-points-to-optimize-the-rest-of-the-hyperparameters">Now train the model on the data points to optimize the rest of the hyperparameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-trained-model-along-with-some-sample-paths">Plot the trained model along with some sample paths</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-uncertainty-about-the-optimization-problem-for-the-initial-gaussian-process-surrogate">Plot the uncertainty about the optimization problem for the initial Gaussian process surrogate</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-c-expected-improvement-with-noise">Part C - Expected improvement with noise</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-algorithm">run the algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-many-iterations-does-the-algorithm-take-to-converge-that-is-how-quickly-does-it-identify-the-critical-point">How many iterations does the algorithm take to converge? That is, how quickly does it identify the critical point?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quantify-the-uncertainty-about-the-solution-to-the-optimization-problem-with-the-trained-gaussian-process">Quantify the uncertainty about the solution to the optimization problem with the trained Gaussian process</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#part-d-testing-your-intuition">Part D - Testing your intuition</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ilias Bilionis (ibilion[at]purdue.edu)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>