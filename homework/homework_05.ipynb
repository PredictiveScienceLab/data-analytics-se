{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "**Due: 10/22/2020 on gradescope**\n",
    "\n",
    "## References\n",
    "\n",
    "+ Lectures 13-16 (inclusive).\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "+ Type your name and email in the \"Student details\" section below.\n",
    "+ Develop the code and generate the figures you need to solve the problems using this notebook.\n",
    "+ For the answers that require a mathematical proof or derivation you can either:\n",
    "    \n",
    "    - Type the answer using the built-in latex capabilities. In this case, simply export the notebook as a pdf and upload it on gradescope; or\n",
    "    - You can print the notebook (after you are done with all the code), write your answers by hand, scan, turn your response to a single pdf, and upload on gradescope.\n",
    "\n",
    "+ The total homework points are 100. Please note that the problems are not weighed equally.\n",
    "\n",
    "**Note**: Please match all the pages corresponding to each of the questions when you submit on gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student details\n",
    "\n",
    "+ **First Name:**\n",
    "+ **Last Name:**\n",
    "+ **Email:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "sns.set_style('white')\n",
    "import scipy.stats as st\n",
    "# A helper function for downloading files\n",
    "import requests\n",
    "import os\n",
    "def download(url, local_filename=None):\n",
    "    \"\"\"\n",
    "    Downloads the file in the ``url`` and saves it in the current working directory.\n",
    "    \"\"\"\n",
    "    data = requests.get(url)\n",
    "    if local_filename is None:\n",
    "        local_filename = os.path.basename(url)\n",
    "    with open(local_filename, 'wb') as fd:\n",
    "        fd.write(data.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Estimating the mechanical properties of a plastic material from molecular dynamics simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure that [this](https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/stress_strain.txt) dataset is visible from this Jupyter notebook.\n",
    "You may achieve this by either:\n",
    "\n",
    "+ Downloading the data file, putting it in your Google drive, mounting the drive, and changing to the directory of the file (see Problem 0 in [Homework](https://colab.research.google.com/github/PredictiveScienceLab/data-analytics-se/blob/master/homework/homework_03.ipynb); or\n",
    "+ Downloading the file to the working directory of this notebook with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/stress_strain.txt'\n",
    "download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's up to you what you choose to do.\n",
    "If the file is in the right place, the following code should work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  np.loadtxt('stress_strain.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was generated using a molecular dynamics simulation of a plastic material (thanks to [Professor Alejandro Strachan](https://engineering.purdue.edu/MSE/people/ptProfile?id=33239) for sharing the data!).\n",
    "Specifically, Strachan's group did the following:\n",
    "- They took a rectangular chunk of the material and marked the position of each one of its atoms;\n",
    "- They started applying a tensile force along one dimension.\n",
    "The atoms are coupled together through electromagnetic forces and they must all satisfy Newton's law of motion.\n",
    "- For each value of the applied tensile force they marked the stress (force be unit area) in the middle of the materail and the corresponding strain of the material (percent enlogation in the pulling direction).\n",
    "- Eventually the material entered the plastic regime and then it broke.\n",
    "Here is a visualization of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:, 0] # Strain \n",
    "y = data[:, 1] # Stress in MPa\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(x, y, 'ro', markersize=2, label = 'Stress-strain data')\n",
    "plt.xlabel('$\\epsilon$ (strain in %)', fontsize=14)\n",
    "plt.ylabel('$\\sigma$ (stress in MPa)', fontsize=14)\n",
    "plt.legend(loc='best', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for each particular value of the strain, you don't necessarily get a unique stress.\n",
    "This is because in molecular dynamics the atoms are jiggling around due to thermal effects.\n",
    "So there is always this \"jiggling\" noise when you are trying to measure the stress and the strain.\n",
    "We would like to process this noise in order to extract what is known as the [stress-strain curve](https://en.wikipedia.org/wiki/Stressâ€“strain_curve) of the material.\n",
    "The stress-strain curve is a macroscopic property of the the material which is affeted by the fine structure, e.g., the chemical bonds, the crystaline structure, any defects, etc.\n",
    "It is a required input to mechanics of materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Fitting the stress-strain curve in the elastic regime\n",
    "The very first part of the stress-strain curve should be linear.\n",
    "It is called the *elastic regime*.\n",
    "In that region, say $\\epsilon < \\epsilon_l=0.04$, the relationship between stress and strain is:\n",
    "$$\n",
    "\\sigma(\\epsilon) = E\\epsilon.\n",
    "$$\n",
    "The constant $E$ is known as the *Young modulus* of the material.\n",
    "Assume that you measure $\\epsilon$ without any noise, but your measured $\\sigma$ is noisy.\n",
    "\n",
    "### Subpart A.I\n",
    "First, extract the relevant data for this problem, split it into training and validation datasets, and visualize the training and validation datasets using different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The point at which the stress-strain curve stops being linear\n",
    "epsilon_l = 0.04\n",
    "# Relevant data (this is nice way to get the linear part of the stresses and straints)\n",
    "x_rel = x[x < 0.04]\n",
    "y_rel = y[x < 0.04]\n",
    "# Visualize to make sure you have the right data\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(x_rel, y_rel, 'ro', markersize=2, label = 'Stress-strain data')\n",
    "plt.xlabel('$\\epsilon$ (strain in %)', fontsize=14)\n",
    "plt.ylabel('$\\sigma$ (stress in MPa)', fontsize=14)\n",
    "plt.legend(loc='best', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split your data into training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation datasets\n",
    "# Hint: Consult the hands-on activities of the lectures\n",
    "x_train = # Your code\n",
    "y_train = # Your code\n",
    "x_valid = # Your code\n",
    "y_valid = # Your code\n",
    "# Your code to plot the two datasets here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following to visualize your split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x_train, y_train, 'ro', markersize=2, label = 'Training data')\n",
    "plt.plot(x_valid, y_valid, 'bx', markersize=2, label = 'Validation data')\n",
    "plt.xlabel('$\\epsilon$ (strain in %)', fontsize=14)\n",
    "plt.ylabel('$\\sigma$ (stress in MPa)', fontsize=14)\n",
    "plt.legend(loc='best', fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.II\n",
    "Perform Bayesian linear regression with the evidence approximation to estimate the noise variance and the hyperparameters of the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.III\n",
    "Calculate the mean square error of the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.IV\n",
    "Make the observations vs predictions plot for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.V\n",
    "Compute and plot the standarized errors for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.VI\n",
    "Make the quantile-quantile plot of the standarized errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.VII\n",
    "Visualize your epistemic and the aleatory uncertainty about the stress-strain curve in the elastic regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A. VIII\n",
    "Visualize the posterior of the Young modulus E conditioned on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.IX\n",
    "Take five samples of stress-strain curve in the elastic regime and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.X\n",
    "\n",
    "Find the 95% centered credible interval for the Young modulus $E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.XI\n",
    "If you had to pick a single value for the Young modulus $E$, what would it be and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Estimate the yield stress\n",
    "\n",
    "The pick of the stress-strain curve is known as the yield stress.\n",
    "We will like to estimate it.\n",
    "\n",
    "### Subpart B.I - Model the entire stress-strain relationship.\n",
    "To do this, we will set up a generalized linear model that can capture the entire stress-strain relationship.\n",
    "Remember, you can use any model you want as soon as:\n",
    "+ it is linear in the parameters to be estimated,\n",
    "+ it clearly has a well-defined elastic regime (see Part A).\n",
    "\n",
    "Describe your model clearly, justify why it is good, and visualize the epistemic and aleatory uncertainty for the entire stress-train curve.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- You can use the [Heavide step function](https://en.wikipedia.org/wiki/Heaviside_step_function) to turn on or off models for various ranges of $\\epsilon$. The idea is quite simple. Here is a model that has the right form in the elastic regime and an arbitrary form in the non-linear regime:\n",
    "$$\n",
    "f(\\epsilon;E,\\mathbf{w}_g) = E\\epsilon \\left[(1 - H(\\epsilon - \\epsilon_l)\\right] + g(\\epsilon;\\mathbf{w}_g)H(\\epsilon - \\epsilon_l),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "H(x) = \\begin{cases}\n",
    "0,\\;\\text{if}\\;x < 0\\\\\n",
    "1,\\;\\text{otherwise},\n",
    "\\end{cases}\n",
    "$$\n",
    "and $g$ is any function linear in the parameters $\\mathbf{w}_g$, e.g., a polynomial in $\\epsilon$.\n",
    "\n",
    "- Do not just pick any model. Justify why the model is a good choice by going through many of the steps you went through in part A of this problem, e.g., split the dataset in training and validation, do the mean square error, the observation vs predictions plots, standarized errors, etc.\n",
    "\n",
    "- You would have to write a function that computes the design matrix for your model. We have given you the skeleton for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter your model description/solution here. Delete that ``<br>`` line (it just makes some white space).*\n",
    "<br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this code to make your model:\n",
    "def compute_design_matrix(X):\n",
    "    \"\"\"\n",
    "    Computes the design matrix for the stress-strain curve problem.\n",
    "    \n",
    "    Arguments:\n",
    "        X     -     A 2D array. First dimension is the number of inputs N.\n",
    "                    Second dimension is not checked.\n",
    "    \n",
    "    Returns:\n",
    "        A design matrix N x M, where M is the number of basis functions you want\n",
    "        to use.\n",
    "    \"\"\"\n",
    "    # Sanity check\n",
    "    assert isinstance(X, np.ndarray)\n",
    "    assert X.ndim == 2, 'Pass the array as X[:, None] if it is one dimensional'\n",
    "    n = X.shape[0]\n",
    "    # The number of basis functions\n",
    "    m = # Your choice\n",
    "    # The design matrix:\n",
    "    Phi = np.ndarray((n, m))\n",
    "    # Loop over the input points\n",
    "    for i in range(n):\n",
    "        # Loop over the basis functions\n",
    "        for j in range(m):\n",
    "            # Your code here to compute your j-th basis function\n",
    "            # evaluated at X[i]\n",
    "            # You may of course use more than one line\n",
    "            Phi[i, j] = # Your code here. Use the vector X[i].\n",
    "    return Phi\n",
    "\n",
    "# Your code here - Repeat as many text and code blocks as you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart B.II - Extract the yield stress\n",
    "\n",
    "Now, you are going to quantify your epistemic uncertainty about the yield stress.\n",
    "The yield stress is the maximum of the stress-strain relationship.\n",
    "Since you have epistemic uncertainty about the stress-strain relationship, you also have epistemic uncertainty about the yield stress.\n",
    "\n",
    "Do the following:\n",
    "- Visualize posterior of the yield stress.\n",
    "- Find a 95% credible interval for the yield stress.\n",
    "- Pick a value for the yield stress.\n",
    "\n",
    "**Hint:**\n",
    "To characterize your epistemic uncertainty about the yield stress, you would have to do the following:\n",
    "- Define a dense set of strain points between 0 and 0.25.\n",
    "- Repeatedly:\n",
    "    + sample from the posterior of the weights of your model\n",
    "    + for each sample evaluate the stresses at the dense set of strain points defined earlier\n",
    "    + for each sampled stress vector, find the maximum. This is a sample of the yield stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here - Repeat as many text and code blocks as you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C - Improving your model\n",
    "\n",
    "The model you constructed in part B may have a disctontinuity at $\\epsilon=\\epsilon_l$.\n",
    "How can you enforce continuity of $\\sigma(\\epsilon)$ and its first derivative at that point?\n",
    "Can you reparameterize the model of part B, so that this condition is automatically satisfied?\n",
    "If yes, then repeat the analysis of part B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter your model description/solution here. Delete that ``<br>`` line (it just makes some white space).*\n",
    "<br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Optimizing the performance of a compressor\n",
    "\n",
    "In this problem we are going to need [this](https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/compressor_data.xlsx) dataset. The dataset was kindly provided to us by [Professor Davide Ziviani](https://scholar.google.com/citations?user=gPdAtg0AAAAJ&hl=en).\n",
    "As before, you can either put it on your Google drive or just download it with the code segment below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/compressor_data.xlsx'\n",
    "download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is an Excell file, so we are going to need pandas to read it.\n",
    "Here is how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('compressor_data.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are part of a an experimental study of a variable speed reciprocating compressor.\n",
    "The experimentalists varied two temperatures $T_e$ and $T_c$ (both in C) and they measured various other quantities.\n",
    "Our goal is to learn the map between $T_e$ and $T_c$ and measured Capacity and Power (both in W).\n",
    "First, let's see how you can extract only the relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how to extract the T_e and T_c columns and put them in a single numpy array\n",
    "x = data[['T_e','T_c']].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how to extract the Capacity\n",
    "y = data['Capacity'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the following multivariate polynomial model to **both the Capacity and the Power**:\n",
    "$$\n",
    "y = w_1 + w_2T_e + w_3 T_c + w_4 T_eT_c + w_5 T_e^2 + w_6T_c^2 + w_7 T_e^2T_c + w_8T_eT_c^2 + w_9 T_e^3 + w_{10}T_c^3 + \\epsilon,\n",
    "$$\n",
    "where $\\epsilon$ is a Gaussian noise term with unknown variance.\n",
    "**Hints:**\n",
    "+ You may use [sklearn.preprocessing.PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) to construct the design matrix of your polynomial features. Do not program the design matrix by hand.\n",
    "+ You should split your data into training and validation and use various validation metrics to make sure that your models make sense.\n",
    "+ Use [ARD Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ARDRegression.html#sklearn.linear_model.ARDRegression) to fit any hyperparameters and the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Fitting the Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here - Repeat as many text and code blocks as you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.I\n",
    "\n",
    "What is the noise variance you estimated for the Capacity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart A.II\n",
    "Which features of the temperatures (basis functions of your model) are the most important for predicting the Capacity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Fitting the Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here - Repeat as many text and code blocks as you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart B.I\n",
    "\n",
    "What is the noise variance you estimated for the Power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpart B.II\n",
    "Which features of the temperatures (basis functions of your model) are the most important for predicting the Power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 - Explaining the challenger disaster\n",
    "On January 28, 1986, the [Space Shuttle Challenger](https://en.wikipedia.org/wiki/Space_Shuttle_Challenger_disaster) disintegrated after 73 seconds from launch.\n",
    "The failure can be traced on the rubber O-rings which were used to seal the joints of the solid rocket boosters (required to force the hot, high-pressure gases generated by the burning solid propelant through the nozzles thus producing thrust).\n",
    "\n",
    "It turns out that the performance of the O-ring material was particularly sensitive on the external temperature during launch.\n",
    "This [dataset](https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/challenger_data.csv) contains records of different experiments with O-rings recorded at various times between 1981 and 1986.\n",
    "Download the data the usual way (either put them on Google drive or run the code cell below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/PredictiveScienceLab/data-analytics-se/master/homework/challenger_data.csv'\n",
    "download(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this is a csv file, you should load it with pandas because it contains some special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('challenger_data.csv')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is the date of the record. The second column is the external temperature of that day in degrees F.\n",
    "The third column labeled ``Damage Incident`` is has a binary coding (0=no damage, 1=damage).\n",
    "The very last row is the day of the Challenger accident.\n",
    "\n",
    "We are going to use the first 23 rows to solve a binary classification problem that will give us the probability of an accident conditioned on the observed external temperature in degrees F. Before we proceed to the analysis of the data, let's clean the data up.\n",
    "\n",
    "First, we drop all the bad records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_0 = raw_data.dropna()\n",
    "clean_data_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also don't need the last record. Just remember that the temperature the day of the Challenger accident was 31 degrees F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data_0[:-1]\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the features and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = clean_data['Temperature'].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clean_data['Damage Incident'].values.astype(np.float)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Perform logistic regression\n",
    "\n",
    "Perform logistic regression between the temperature ($x$) and the damage label ($y$).\n",
    "Notes:\n",
    "- Use any generalized linear model you like (e.g., linear, quadratic, or something more complex). \n",
    "- Make sure that  you split your dataset into training and validation subsets and that you use a classificiation diagnostic to assess how good your final model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here - Repeat as many text and code blocks as you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B - Plot the probability of damage as a function of temperature\n",
    "Plot the probability of damage as a function of temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C - Decide whether or not to launch\n",
    "\n",
    "The temperature the day of the Challenger accident was 31 degrees F.\n",
    "Use formal decision-making (i.e., define a cost matrix and make decisions by minimizing the expected loss) to decide whether or not to launch on that day.\n",
    "Also, plot your optimal decision as a function of the external temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here - Repeat as many text and code blocks as you like"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
