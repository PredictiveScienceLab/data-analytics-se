{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Space Models - Filtering Basics\n",
    "\n",
    "## Filtering problems\n",
    "In words, filtering problems are as follows:\n",
    "+ you have some sort of dynamical system (physical or engineered)\n",
    "+ you observe a noisy measurement of (part of) the state of the system\n",
    "+ you want to figure out what is the actual state of the system\n",
    "\n",
    "Here are some examples of this:\n",
    "+ Object tracking:\n",
    "    - you have a vehicle (e.g., a rocket) the motion of which is described by Newton's laws\n",
    "    - you have some noisy measurements of the state of the system (e.g., GPS, acceleratometers)\n",
    "    - you want to figure out where exactly the rocket is, so that you can control it\n",
    "+ Biomedical imaging:\n",
    "    - you have a biological organ (e.g., a heart) which consists of tissue and fluids that can be described with physical variables (the state) such as strains, stresses, velocity, and pressure which are governed by physical equations (elasticity equations and Navier-Stokes equations)\n",
    "    - you have some noisy measurements of the state of the system (e.g., accoustic doppler shifts, average velocity in small voxels (MRI))\n",
    "    - you want to figure out the underlying physical states because they may be indicative of disease\n",
    "\n",
    "In what follows we are going to define the filtering problem mathematically.\n",
    "To achieve this, we first need to explain the Markov property.\n",
    "**Note:** All the material in these notes is explained in the video lectures as well.\n",
    "Feel free to skip the following sections if they seem very difficult at the moment.\n",
    "You can revisit them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov model without external disturbances\n",
    "\n",
    "Assume that you have some sort of a stochastic dynamical system with state variables $\\mathbf{x}_t$.\n",
    "For simplicity, assume also that the time runs in discrete steps, $t=0,1,2,\\dots,n$.\n",
    "If the system doesn't have any external disturbances, i.e., if the system is closed, then the following property is valid:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{t+1}|\\mathbf{x}_{0:t}) = p(\\mathbf{x}_{t+1}|\\mathbf{x}_t).\n",
    "$$\n",
    "\n",
    "This simply says that the probability of the state at time $t+1$ given all the states up to the timestep $t$ depends only on the state of the system at time $t$.\n",
    "That is, the past states before $t$ do not affect the future states directly.\n",
    "This property is the *Markov property* and $p(\\mathbf{x}_{t+1}|\\mathbf{x}_t)$ is called the *transition probability*.\n",
    "\n",
    "If you have the transition probability, you can write the joint probability density of all states as follows:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{0:n}) = p(\\mathbf{x}_0)\\prod_{t=0}^{n-1}p(\\mathbf{x}_{t+1}|\\mathbf{x}_t),\n",
    "$$\n",
    "\n",
    "where $p(\\mathbf{x}_0)$ is the probability density of the initial conditions $\\mathbf{x}_0$.\n",
    "Once you spend a bit of time on this formula, you will start seeing why its valid.\n",
    "The proof goes like this.\n",
    "Let's start with the special case $n=1$.\n",
    "From the product rule we have that:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{0:1}) = p(\\mathbf{x}_0)p(\\mathbf{x}_{1}|\\mathbf{x}_{0}),\n",
    "$$\n",
    "\n",
    "which is the desired formula.\n",
    "For $n=2$, we have by applying the product rule again:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{0:2}) = p(\\mathbf{x}_{0:1})p(\\mathbf{x}_2|\\mathbf{x}_{0:1}).\n",
    "$$\n",
    "\n",
    "Now, we can use the formula we derived for $n=1$ and the Markov property to write this as:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{0:2}) = p(\\mathbf{x}_0)p(\\mathbf{x}_{1}|\\mathbf{x}_{0})p(\\mathbf{x}_{2}|\\mathbf{x}_{1}).\n",
    "$$\n",
    "\n",
    "So the formula holds for $n=2$.\n",
    "Similarly, you can prove this for an arbitrary $n$ assuming that it holds for $n-1$.\n",
    "Then the proof is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov model with observations\n",
    "Let's now add some observations to our system.\n",
    "We assume that we have some sensors that measure something on every timestep.\n",
    "Say that they measure the variables $\\mathbf{y}_t$.\n",
    "The assumption is that $\\mathbf{y}_t$ can only depend on the state of the system $\\mathbf{x}_t$ and on nothing else.\n",
    "Mathematically, the assumption is:\n",
    "$$\n",
    "p(\\mathbf{y}_t|\\mathbf{x}_{0:t}) = p(\\mathbf{y}_t|\\mathbf{x}_t).\n",
    "$$\n",
    "So, to describe the statistics of $\\mathbf{y}_t$ we need to define the so-called *emission probability* $p(\\mathbf{y}_t|\\mathbf{x}_t)$.\n",
    "Now, we can write the joint probability density of the system states and the observations as:\n",
    "$$\n",
    "p(\\mathbf{x}_{0:n}, \\mathbf{y}_{1:n}) = p(\\mathbf{x}_0)\\prod_{t=0}^{n-1}p(\\mathbf{x}_{t+1}|\\mathbf{x}_t)p(\\mathbf{y}_t|\\mathbf{x}_t).\n",
    "$$\n",
    "This is an important formula that you should spend some time on.\n",
    "You can prove it by induction very easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov model with observations and controls\n",
    "Now assume that at every timestep $t$ we can pass a control command to the system $\\mathbf{u}_t$.\n",
    "For example, if we are dealing with a rocket, we can decide which thrusters to activate.\n",
    "The control command will affect where the system state goes in the next timestep.\n",
    "We say that the system is Markovian if the following equation holds:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{t+1}|\\mathbf{x}_{0:t},\\mathbf{u}_{0:t}) = p(\\mathbf{x}_{t+1}|\\mathbf{x}_t,\\mathbf{u}_t).\n",
    "$$\n",
    "\n",
    "As before, the probability density $p(\\mathbf{x}_{t+1}|\\mathbf{x}_t,\\mathbf{u}_t)$ is known as the *transition probability*.\n",
    "Remember that the entire history of controls $\\mathbf{u}_{0:n-1}$ is known (we pick it).\n",
    "So, when we write down the joint probability density of states and observations we can condition on it.\n",
    "We have:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{0:n}, \\mathbf{y}_{1:n}|\\mathbf{u}_{0:n-1}) = p(\\mathbf{x}_0)\\prod_{t=0}^{n-1}p(\\mathbf{x}_{t+1}|\\mathbf{x}_t,\\mathbf{u}_t)p(\\mathbf{y}_t|\\mathbf{x}_t).\n",
    "$$\n",
    "\n",
    "The proof is similar to the case without any controls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical definition of the filtering problem \n",
    "\n",
    "We have all the ingredients to define the filtering problem mathematically.\n",
    "The problem is to characterize the states $\\mathbf{x}_{0:n}$ given the available observations $\\mathbf{y}_{1:n}$ and the applied controls $\\mathbf{u}_{0:n-1}$.\n",
    "The best you can say about the states comes from applying Bayes' rule.\n",
    "It is:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{0:n}|\\mathbf{y}_{1:n},\\mathbf{u}_{0:n-1}) = \\frac{p(\\mathbf{x}_{0:n}, \\mathbf{y}_{1:n}|\\mathbf{u}_{0:n-1})}{p(\\mathbf{y}_{1:n}|\\mathbf{u}_{0:n-1})}\n",
    "\\propto p(\\mathbf{x}_0)\\prod_{t=0}^{n-1}p(\\mathbf{x}_{t+1}|\\mathbf{x}_t,\\mathbf{u}_t)p(\\mathbf{y}_t|\\mathbf{x}_t).\n",
    "$$\n",
    "\n",
    "This the formal answer and it is the starting point for developing specific algorithms.\n",
    "\n",
    ":::{note}\n",
    "Strictly speaking the filtering problem is actually to estimate the current state given all data, i.e., $p(\\mathbf{x}_n | \\mathbf{y}_{1:n},\\mathbf{u}_{0:n-1})$.\n",
    "The estimation of all states (including the past) is known as *smoothing*.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear systems with Gaussian probabilities\n",
    "\n",
    "Let's now give a specific example of transition and emission probabilities.\n",
    "All transitions will be linear and all probabilities will be Gaussian.\n",
    "There are two possible ways to write this down. The equations and the probabilistic way.\n",
    "We will give both of them, starting from the equations.\n",
    "\n",
    "### The equations way\n",
    "+ **Intial conditions:**\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_0 = \\boldsymbol{\\mu}_0 + \\mathbf{z}_0,\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\mu}_0$ is a parameter and $\\mathbf{z}_0\\sim N(\\mathbf{0},\\mathbf{V}_0)$ with $\\mathbf{V}_0$ an properly sized covariance matrix.\n",
    "+ **Transitions:**\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = \\mathbf{A}\\mathbf{x}_t + \\mathbf{B}\\mathbf{u}_t + \\mathbf{z}_t,\n",
    "$$\n",
    "\n",
    "where $\\mathbf{A}$ and $\\mathbf{B}$ are matrices and $\\mathbf{z}_t\\sim N(\\mathbf{0},\\mathbf{Q})$ with $\\mathbf{Q}$ a properly sized covariance matrix (known as process covariance).\n",
    "+ **Emissions:**\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_t = \\mathbf{C}\\mathbf{x}_t + \\mathbf{w}_t,\n",
    "$$\n",
    "\n",
    "where $\\mathbf{C}$ is a matrix and $\\mathbf{w}_t\\sim N(\\mathbf{0},\\mathbf{R})$ with $\\mathbf{R}$ a properly sized covariance matrix (known as process covariance).\n",
    "\n",
    "### The probabilistic way\n",
    "+ **Initial conditions:**\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_0) = N(\\mathbf{x}_0|\\boldsymbol{\\mu}_0,\\mathbf{V}_0),\n",
    "$$\n",
    "\n",
    "+ **Transitions:**\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{t+1}|\\mathbf{x}_t,\\mathbf{u}_t) = N(\\mathbf{x}_{t+1}|\\mathbf{A}\\mathbf{x}_t+\\mathbf{B}\\mathbf{u}_t,\\mathbf{Q}). \n",
    "$$\n",
    "\n",
    "+ **Emissions:**\n",
    "\n",
    "$$\n",
    "p(\\mathbf{y}_{t}|\\mathbf{x}_t) = N(\\mathbf{y}_t|\\mathbf{C}\\mathbf{x}_t,\\mathbf{R}).\n",
    "$$\n",
    "\n",
    "**Note:** The parameters $\\mathbf{A}, \\mathbf{B}, \\mathbf{C}, \\boldsymbol{\\mu}_0,\\mathbf{V}_0, \\mathbf{Q}$ and $\\mathbf{R}$ are assumed to be known in the context of our class.\n",
    "However, in realistic situations they maybe unknown (or partially known).\n",
    "If that's the case, they would have to be estimated along with the states.\n",
    "In that case, we say that we have a *parameter estimation and filtering problem*.\n",
    "These are much harder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
