
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Example: Priors on function spaces &#8212; Introduction to Scientific Machine Learning (Lecture Book)</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lecture 22 - Gaussian Process Regression: Conditioning on Data" href="../lecture22/intro.html" />
    <link rel="prev" title="Gaussian Process Theory" href="reading-21.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Introduction to Scientific Machine Learning (Lecture Book)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Preface
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../introduction.html">
   Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture01/intro.html">
     Lecture 1 - Introduction to Predictive Modeling
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture01/reading-01.html">
       Predictive Modeling and Scientific Machine Learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture01/hands-on-01.1.html">
       The Uncertainty Propagation Problem
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture01/hands-on-01.2.html">
       The Model Calibration Problem
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../review_probability.html">
   Review of Probability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture02/intro.html">
     Lecture 2 - Basics of Probability Theory
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture02/reading-02.html">
       Basics of Probability Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture02/hands-on-02.html">
       Experiment with “Ranomness”
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture03/intro.html">
     Lecture 3 - Discrete Random Variables
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture03/reading-03.html">
       Discrete Random Variables
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture03/hands-on-03.html">
       Discrete Random Variables in Python
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture04/intro.html">
     Lecture 4 - Continuous Random Variables
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture04/reading-04.html">
       Continuous Random Variables
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture04/hands-on-04.1.html">
       The Uniform Distribution
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture04/hands-on-04.2.html">
       The Gaussian Distribution
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture05/intro.html">
     Lecture 5 - Collections of Random Variables
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture05/reading-05.html">
       Collections of Random Variables: Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture05/hands-on-05.html">
       Practicing with joint probability mass functions
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture06/intro.html">
     Lecture 6 - Random Vectors
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/reading-06.html">
       Random Vectors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/hands-on-06.1.html">
       The Multivariate Normal - Diagonal Covariance Case
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/hands-on-06.2.html">
       The Multivariate Normal - Full Covariance Case
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/hands-on-06.3.html">
       The Multivariate Normal - Marginalization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/hands-on-06.4.html">
       The Multivariate Normal - Conditioning
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../uncertainty_propagation.html">
   Uncertainty Propagation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture07/intro.html">
     Lecture 7 - Basic Sampling
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture07/hands-on-07.1.html">
       Pseudo-random number generators
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture07/hands-on-07.2.html">
       Sampling the uniform
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture07/hands-on-07.3.html">
       Sampling the categorical
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture07/hands-on-07.4.html">
       Sampling from continuous distributions - Inverse sampling
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture08/intro.html">
     Lecture 8 - The Monte Carlo Method for Estimating Expectations
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture08/hands-on-08.3.html">
       Sampling Estimates of Expectations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture08/hands-on-08.4.html">
       Sampling Estimates of Variance
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture09/intro.html">
     Lecture 9 - Monte Carlo Estimates of Various Statistics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture09/hands-on-09.1.html">
       Sampling Estimates of the Cumulative Distribution Function
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture09/hands-on-09.2.html">
       Sampling Estimates of the Probability Density via Histograms
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture09/hands-on-09.3.html">
       Hands-on Activity 9.3: Sampling Estimates of Predictive Quantiles
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture09/hands-on-09.4.html">
       Propagating Uncertainties through an Ordinrary Differential Equation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture10/intro.html">
     Lecture 10 - Quantify Uncertainty in Monte Carlo Estimates
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture10/hands-on-10.1.html">
       Visualizing Monte Carlo Uncertainty
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture10/hands-on-10.2.html">
       The Central Limit Theorem
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture10/hands-on-10.3.html">
       Quanifying Epistemic Uncertainty in Monte Carlo estimates
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture10/hands-on-10.4.html">
       Uncertainty Propagation Through a Boundary Value Problem
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../principles_of_bi.html">
   Principles of Bayesian Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture11/intro.html">
     Lecture 11 - Selecting Prior Information
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture11/reading-11.html">
       Selecting Prior Information
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture11/hands-on-11.1.html">
       Information Entropy
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture11/hands-on-11.2.html">
       The Principle of Maximum Entropy for Discrete Random Variables
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture11/hands-on-11.3.html">
       The Principle of Maximum Entropy for Continuous Random Variables
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture12/intro.html">
     Lecture 12 - Analytical Examples of Bayesian Inference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
    <label for="toctree-checkbox-16">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/reading-12.html">
       Analytical Examples of Bayesian Inference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/hands-on-12.1.html">
       Bayesian Parameter Estimation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/hands-on-12.2.html">
       Credible Intervals
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/hands-on-12.3.html">
       Decision-Making
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/hands-on-12.4.html">
       Posterior Predictive Checking
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../supervised_learning.html">
   Supervised Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture13/intro.html">
     Lecture 13 - Linear Regression via Least Squares
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/reading-13.html">
       Linear Regression via Least Squares
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/hands-on-13.1.html">
       Linear regression with a single variable
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/hands-on-13.2.html">
       Polynomial Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/hands-on-13.3.html">
       The Generalized Linear Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/hands-on-13.4.html">
       Measures of Predictive Accuracy
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture14/intro.html">
     Lecture 14 - Bayesian Linear Regression
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/reading-14.html">
       Bayesian Linear Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/hands-on-14.1.html">
       Probabilistic Interpretation of Least Squares - Estimating the Measurement Noise
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/hands-on-14.2.html">
       Maximum a Posteriori Estimate - Avoiding Overfitting
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/hands-on-14.3.html">
       Bayesian Linear Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/hands-on-14.4.html">
       The point-predictive Distribution - Separating Epistmic and Aleatory Uncertainty
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture15/intro.html">
     Lecture 15 - Advanced Topics in Bayesian Linear Regression
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture15/reading-15.html">
       Advanced Topics in Bayesian Linear Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture15/hands-on-15.1.html">
       Evidence approximation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture15/hands-on-15.2.html">
       Automatic Relevance Determination
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture15/hands-on-15.3.html">
       Diagnostics for Posterior Predictive
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture16/intro.html">
     Lecture 16 - Classification
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/reading-16.html">
       Theoretical Background on Classification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.1.html">
       Logistic regression with one variable (High melting explosives)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.2.html">
       Logistic Regression with Many Features
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.3.html">
       Decision making
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.4.html">
       Diagnostics for Classifications
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.5.html">
       Multi-class Logistic Regression
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unsupervised_learning.html">
   Unsupervised Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture17/intro.html">
     Lecture 17 - Clustering and Density Estimation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
    <label for="toctree-checkbox-23">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture17/reading-17.html">
       Unsupervised Learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture17/hands-on-17.1.html">
       Clustering using k-means
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture17/hands-on-17.2.html">
       Density Estimation via Gaussian mixtures
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture18/intro.html">
     Lecture 18 - Dimensionality Reduction
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture18/reading-18.html">
       Dimensionality Reduction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture18/hands-on-18.1.html">
       Dimensionality Reduction Examples
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture18/hands-on-18.2.html">
       Clustering High-dimensional Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture18/hands-on-18.3.html">
       Density Estimation with High-dimensional Data
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../state_space_models.html">
   State Space Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
  <label for="toctree-checkbox-25">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture19/intro.html">
     Lecture 19 - State Space Models - Filtering Basics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
    <label for="toctree-checkbox-26">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture19/reading-19.html">
       State Space Models - Filtering Basics
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture19/hands-on-19.1.html">
       Object Tracking Example
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture20/intro.html">
     Lecture 20 - State Space Models - Kalman Filters
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
    <label for="toctree-checkbox-27">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture20/reading-20.html">
       State Space Models - Kalman Filters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture20/hands-on-20.1.html">
       Kalman Filter for Object Tracking Example
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../gaussian_process_regression.html">
   Gaussian Process Regression
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
  <label for="toctree-checkbox-28">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="intro.html">
     Lecture 21 - Gaussian Process Regression: Priors on Function Spaces
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="reading-21.html">
       Gaussian Process Theory
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Example: Priors on function spaces
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture22/intro.html">
     Lecture 22 - Gaussian Process Regression: Conditioning on Data
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
    <label for="toctree-checkbox-30">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/reading-22.html">
       Gaussian Process Regression - Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/hands-on-22.1.html">
       Gaussian Process Regression Without Noise
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/hands-on-22.2.html">
       Gaussian Process Regression with Noise
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/hands-on-22.3.html">
       Tuning the Hyperparameters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/hands-on-22.4.html">
       Multivariate Gaussian Process Regression
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture23/intro.html">
     Lecture 23 - Bayesian Global Optimization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
    <label for="toctree-checkbox-31">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/reading-23.html">
       Bayesian Global Optimization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/hands-on-23.1.html">
       Maximum Mean - A Bad Information Acquisition Function
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/hands-on-23.2.html">
       Maximum Upper Interval
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/hands-on-23.3.html">
       Probability of Improvement
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/hands-on-23.4.html">
       Expected Improvement
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../neural_networks.html">
   Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
  <label for="toctree-checkbox-32">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture24/intro.html">
     Lecture 24 - Deep Neural Networks
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/>
    <label for="toctree-checkbox-33">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture24/reading-24.html">
       Deep Neural Networks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture24/hands-on-24.html">
       Regression with Deep Neural Networks
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture25/intro.html">
     Lecture 25 - Deep Neural Networks Continued
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/>
    <label for="toctree-checkbox-34">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture25/reading-25.html">
       Deep Neural Networks Continued
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture25/hands-on-25.html">
       Classification with Deep Neural Networks
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture26/intro.html">
     Lecture 26 - Physics-informed Deep Neural Networks
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/>
    <label for="toctree-checkbox-35">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture26/reading-26.html">
       Physics-informed Deep Neural Networks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture26/hands-on-26.1.html">
       Physics-informed regularization: Solving ODEs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture26/hands-on-26.2.html">
       Physics-informed regularization: Solving PDEs
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../advanced_methods.html">
   Advanced Methods for Characterizing Posteriors
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/>
  <label for="toctree-checkbox-36">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture27/intro.html">
     Lecture 27 - Sampling Methods
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/>
    <label for="toctree-checkbox-37">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/reading-27.html">
       Sampling Methods
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.1.html">
       Probabilistic programming with
       <code class="docutils literal notranslate">
        <span class="pre">
         PyMC3
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.2.html">
       Sampling From the Distributions With Random Walk Metropolis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.3.html">
       The Metropolis-Hastings Algorithm
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.4.html">
       Gibbs Sampling
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.5.html">
       Sequential Monte Carlo
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture28/intro.html">
     Lecture 28 - Variational Inference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/>
    <label for="toctree-checkbox-38">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture28/reading-28.html">
       Variational Inference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture28/hands-on-28.html">
       Variational Inference Examples
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lecture21/hands-on-21.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/PredictiveScienceLab/data-analytics-se/master?urlpath=lab/tree/lecturebook/lecture21/hands-on-21.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/PredictiveScienceLab/data-analytics-se/blob/master/lecturebook/lecture21/hands-on-21.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objectives">
   Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-process-code">
   Gaussian process code
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#squared-exponential-covariance-function">
   Squared exponential covariance function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-1-plotting-a-covariance-function">
   Example 1: Plotting a covariance function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#questions">
     Questions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-2-properties-of-the-covariance-matrix">
   Example 2: Properties of the covariance matrix
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-3-sampling-from-a-gaussian-process">
   Example 3: Sampling from a Gaussian process
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Questions
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Example: Priors on function spaces</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objectives">
   Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-process-code">
   Gaussian process code
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#squared-exponential-covariance-function">
   Squared exponential covariance function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-1-plotting-a-covariance-function">
   Example 1: Plotting a covariance function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#questions">
     Questions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-2-properties-of-the-covariance-matrix">
   Example 2: Properties of the covariance matrix
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Questions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-3-sampling-from-a-gaussian-process">
   Example 3: Sampling from a Gaussian process
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Questions
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;figure.dpi&quot;</span><span class="p">:</span><span class="mi">100</span><span class="p">,</span> <span class="s2">&quot;savefig.dpi&quot;</span><span class="p">:</span><span class="mi">300</span><span class="p">})</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;ticks&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="example-priors-on-function-spaces">
<h1>Example: Priors on function spaces<a class="headerlink" href="#example-priors-on-function-spaces" title="Permalink to this headline">¶</a></h1>
<div class="section" id="objectives">
<h2>Objectives<a class="headerlink" href="#objectives" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Sample from a Gaussian process</p></li>
<li><p>Understand the effect of the mean function</p></li>
<li><p>Understand the effect of the covariance function</p></li>
</ul>
</div>
<div class="section" id="gaussian-process-code">
<h2>Gaussian process code<a class="headerlink" href="#gaussian-process-code" title="Permalink to this headline">¶</a></h2>
<p>In this and the next couple of lectures we will be using the Python module <a class="reference external" href="https://sheffieldml.github.io/GPy/">GPy</a>.
We need to make sure that it is installed before we proceed.
On Google Colab make sure you run the following:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install GPy
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="squared-exponential-covariance-function">
<h2>Squared exponential covariance function<a class="headerlink" href="#squared-exponential-covariance-function" title="Permalink to this headline">¶</a></h2>
<p>Squared expnential (SE) is the most commonly used covariance function.
Its formula is as follows:</p>
<div class="math notranslate nohighlight">
\[
k(\mathbf{x}, \mathbf{x}') = v\exp\left\{-\frac{1}{2}\sum_{i=1}^d\frac{(x_i - x_i')^2}{\ell_i^2}\right\},
\]</div>
<p>where <span class="math notranslate nohighlight">\(v,\ell_i&gt;0, i=1,\dots,d\)</span> are parameters.
The interpretation of the parameters is as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(v\)</span> is known as the <em>signal strength</em>. The bigger it is, the more the GP <span class="math notranslate nohighlight">\(f(\cdot)\)</span> will vary
about the mean.</p></li>
<li><p><span class="math notranslate nohighlight">\(\ell_i\)</span> is known as the <em>length scale</em> of the <span class="math notranslate nohighlight">\(i\)</span>-th input dimension of the GP.
The bigger it is, the smoother the samples of <span class="math notranslate nohighlight">\(f(\cdot)\)</span> appear along the <span class="math notranslate nohighlight">\(i\)</span>-th input dimension.</p></li>
</ul>
<p>Let’s experiment with this for a while:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the GPy module:</span>
<span class="kn">import</span> <span class="nn">GPy</span>
<span class="c1"># The input dimension</span>
<span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># The variance of the covariance kernel</span>
<span class="n">variance</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="c1"># The lengthscale of the covariance kernel</span>
<span class="n">ell</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="c1"># Generate the covariance object</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="n">variance</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="n">ell</span><span class="p">)</span>
<span class="c1"># Print it</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="c1"># and plot it</span>
<span class="n">k</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  <span class=" -Color -Color-Bold">rbf.       </span>  |  value  |  constraints  |  priors
  <span class=" -Color -Color-Bold">variance   </span>  |    1.0  |      +ve      |        
  <span class=" -Color -Color-Bold">lengthscale</span>  |    0.3  |      +ve      |        
</pre></div>
</div>
<img alt="../_images/hands-on-21_4_1.png" src="../_images/hands-on-21_4_1.png" />
</div>
</div>
</div>
<div class="section" id="example-1-plotting-a-covariance-function">
<h2>Example 1: Plotting a covariance function<a class="headerlink" href="#example-1-plotting-a-covariance-function" title="Permalink to this headline">¶</a></h2>
<p>Remember:</p>
<blockquote>
<div><p>The covariance function <span class="math notranslate nohighlight">\(k(x,x')\)</span> measures the similarity of <span class="math notranslate nohighlight">\(f(x)\)</span> and <span class="math notranslate nohighlight">\(f(x')\)</span>.</p>
</div></blockquote>
<p>Here is some code to draw <span class="math notranslate nohighlight">\(k(\mathbf{x}, \mathbf{x}'=0)\)</span> in one dimension:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_kernel</span><span class="p">(</span><span class="n">variance</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">ell</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span>
        <span class="n">dim</span><span class="p">,</span>
        <span class="n">variance</span><span class="o">=</span><span class="n">variance</span><span class="p">,</span>
        <span class="n">lengthscale</span><span class="o">=</span><span class="n">ell</span>
    <span class="p">)</span>
    <span class="n">k</span><span class="o">.</span><span class="n">plot_covariance</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_kernel</span><span class="p">(</span><span class="n">variance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">ell</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/hands-on-21_7_0.png" src="../_images/hands-on-21_7_0.png" />
</div>
</div>
<div class="section" id="questions">
<h3>Questions<a class="headerlink" href="#questions" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>What happens as you increase <span class="math notranslate nohighlight">\(\ell\)</span>?</p></li>
<li><p>What happens as you decrease <span class="math notranslate nohighlight">\(v\)</span>?</p></li>
<li><p>There are many other covariance functions that we could be using. Try changing <code class="docutils literal notranslate"><span class="pre">RBF</span></code> to <code class="docutils literal notranslate"><span class="pre">Exponential</span></code> in the <code class="docutils literal notranslate"><span class="pre">plot_kernel()</span></code> function. What changes do you nottice?</p></li>
</ul>
<p>Now here is some code to plot a 2D covariance function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_kernel_2d</span><span class="p">(</span><span class="n">variance</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">ell1</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">ell2</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span>
        <span class="mi">2</span><span class="p">,</span>
        <span class="n">ARD</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">variance</span><span class="o">=</span><span class="n">variance</span><span class="p">,</span>
        <span class="n">lengthscale</span><span class="o">=</span><span class="p">[</span><span class="n">ell1</span><span class="p">,</span> <span class="n">ell2</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">k</span><span class="o">.</span><span class="n">plot_covariance</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>You can use it like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_kernel_2d</span><span class="p">(</span><span class="n">variance</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">ell1</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">ell2</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> /opt/homebrew/lib/python3.9/site-packages/GPy/plotting/matplot_dep/plot_definitions.py:184: UserWarning:The following kwargs were not used by contour: &#39;label&#39;, &#39;linewidth&#39;
</pre></div>
</div>
<img alt="../_images/hands-on-21_12_1.png" src="../_images/hands-on-21_12_1.png" />
</div>
</div>
</div>
<div class="section" id="id1">
<h3>Questions<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>What happens as you increase <span class="math notranslate nohighlight">\(\ell\)</span>?</p></li>
<li><p>What happens as you decrease <span class="math notranslate nohighlight">\(v\)</span>?</p></li>
<li><p>Try a couple of other covariances, e.g., <code class="docutils literal notranslate"><span class="pre">Matern32</span></code>, <code class="docutils literal notranslate"><span class="pre">Matern52</span></code>.</p></li>
</ul>
</div>
</div>
<div class="section" id="example-2-properties-of-the-covariance-matrix">
<h2>Example 2: Properties of the covariance matrix<a class="headerlink" href="#example-2-properties-of-the-covariance-matrix" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{x}_{1:n}\)</span> be an arbitrary set of input points. The covariance matrix <span class="math notranslate nohighlight">\(\mathbf{K}\in\mathbb{R}^{n\times n}\)</span> defined by:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{K}\equiv\mathbf{K}(\mathbf{x}_{1:n}, \mathbf{x}_{1:n}) = \left(
\begin{array}{ccc}
k(\mathbf{x}_1,\mathbf{x}_1) &amp; \dots &amp; k(\mathbf{x}_1, \mathbf{x}_n)\\
\vdots &amp; \ddots &amp; \vdots\\
k(\mathbf{x}_n, \mathbf{x}_1) &amp; \dots &amp; k(\mathbf{x}_n, \mathbf{x}_n)
\end{array}
\right),
\end{split}\]</div>
<p>must be <a class="reference external" href="https://en.wikipedia.org/wiki/Positive-definite_matrix">positive definite</a>. Mathematically this can be expressed in two equivalent ways:</p>
<ul class="simple">
<li><p>For all vectors <span class="math notranslate nohighlight">\(\mathbf{v}\in\mathbb{R}^T\)</span>, we have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbf{v}^t\mathbf{K}\mathbf{v} &gt; 0,
\]</div>
<ul class="simple">
<li><p>All the eigenvalues of <span class="math notranslate nohighlight">\(\mathbf{K}\)</span> are positive.</p></li>
</ul>
<div class="section" id="id2">
<h3>Questions<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Using the code provided:</p>
<ul class="simple">
<li><p>Verify that the the sum of two covariance functions is a valid covariance function.</p></li>
<li><p>Verify that the product of two covariance functions is a valid covariance function.</p></li>
<li><p>Is the following function a covariance function:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
k(x, x') = k_1(x, x')k_2(x, x') + k_3(x, x') + k_4(x, x'),
\]</div>
<p>where all <span class="math notranslate nohighlight">\(k_i(x, x')\)</span>’s are covariance functions.</p>
<ul class="simple">
<li><p>What about:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
k(x, x') = k_1(x, x') / k_2(x, x')?
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Number of dimensions</span>
<span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Number of input points</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>

<span class="c1"># The lengthscale</span>
<span class="n">ell</span> <span class="o">=</span> <span class="mf">.1</span>

<span class="c1"># The variance </span>
<span class="n">variance</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="c1"># The covariance function</span>
<span class="n">k1</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="n">ell</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="n">variance</span><span class="p">)</span>

<span class="c1"># Draw a random set of inputs points in [0, 1]^dim</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

<span class="c1"># Evaluate the covariance matrix on these points</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">k1</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Compute the eigenvalues of this matrix</span>
<span class="n">eig_val</span><span class="p">,</span> <span class="n">eig_vec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>

<span class="c1"># Plot the eigenvalues (they should all be positive)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;&gt; plotting eigenvalues of K&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;&gt; they must all be positive&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">eig_val</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$i$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$\lambda_i$&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&gt; plotting eigenvalues of K
&gt; they must all be positive
</pre></div>
</div>
<img alt="../_images/hands-on-21_15_1.png" src="../_images/hands-on-21_15_1.png" />
</div>
</div>
<p>Now create another covariance function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k2</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Create a new covariance function that is the sum of <span class="math notranslate nohighlight">\(k_1\)</span> and <span class="math notranslate nohighlight">\(k_2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k_new</span> <span class="o">=</span> <span class="n">k1</span> <span class="o">+</span> <span class="n">k2</span>
</pre></div>
</div>
</div>
</div>
<p>If this is a valid covariance function, then it must be positive definite.
Let’s test it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the covariance matrix:</span>
<span class="n">K_new</span> <span class="o">=</span> <span class="n">k_new</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># and its eigenvalues</span>
<span class="n">eig_val_new</span><span class="p">,</span> <span class="n">eig_vec_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">K_new</span><span class="p">)</span>

<span class="c1"># Plot the eigenvalues (they should all be positive)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;&gt; plotting eigenvalues of K&#39;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;&gt; they must all be positive&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">eig_val_new</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$i$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$\lambda_i$&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&gt; plotting eigenvalues of K
&gt; they must all be positive
</pre></div>
</div>
<img alt="../_images/hands-on-21_21_1.png" src="../_images/hands-on-21_21_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="example-3-sampling-from-a-gaussian-process">
<h2>Example 3: Sampling from a Gaussian process<a class="headerlink" href="#example-3-sampling-from-a-gaussian-process" title="Permalink to this headline">¶</a></h2>
<p>Samples from a Gaussian process are functions. But, functions are infinite dimensional objects?
We cannot sample directly from a GP….
However, if we are interested in the values of <span class="math notranslate nohighlight">\(f(\cdot)\)</span> at any given set of test points <span class="math notranslate nohighlight">\(\mathbf{x}_{1:n} = \{\mathbf{x}_1,\dots,\mathbf{x}_b\}\)</span>, then we have that:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{f} | \mathbf{x}_{1:n} \sim \mathcal{N}\left(\mathbf{m}(\mathbf{x}_{1:n}), \mathbf{K}(\mathbf{x}_{1:n}, \mathbf{x}_{1:n}) \right),
\]</div>
<p>where all the quantities have been introduced above.
This is
What we are going to do is pick a dense set of points <span class="math notranslate nohighlight">\(\mathbf{x}_{1:n}\in\mathbb{R}^{n\times d}\)</span>
sample the value of the GP, <span class="math notranslate nohighlight">\(\mathbf{f} = (f(\mathbf{x}_1),\dots,f(\mathbf{x}_n))\)</span> on these points.
We saw above that the probability density of <span class="math notranslate nohighlight">\(\mathbf{f}\)</span> is just a multivariate normal
with a mean vector that is specified from the mean function and a covariance matrix
that is specified by the covariance function.
Therefore, all we need to know is how to sample from the multivariate normal.
This is how we do it:</p>
<ul class="simple">
<li><p>Compute the Cholesky of <span class="math notranslate nohighlight">\(\mathbf{L}\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbf{K} = \mathbf{L}\mathbf{L}^T.
\]</div>
<ul class="simple">
<li><p>Draw <span class="math notranslate nohighlight">\(n\)</span> random samples <span class="math notranslate nohighlight">\(\mathbf{z} = (z_1,\dots,z_n)\)</span> independently from a standard normal.</p></li>
<li><p>Get one sample by:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbf{f} = \mathbf{m} + \mathbf{L}\mathbf{z}.
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># To gaurantee reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123456</span><span class="p">)</span>

<span class="c1"># Number of test points</span>
<span class="n">num_test</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Pick a covariance function</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="mf">.1</span><span class="p">)</span>

<span class="c1"># Pick a mean function</span>
<span class="n">mean_func</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Pick a bunch of points over which you want to sample the GP</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_test</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

<span class="c1"># Evaluate the mean function at X</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">mean_func</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Compute the covariance function at these points</span>
<span class="n">nugget</span> <span class="o">=</span> <span class="mf">1e-6</span> <span class="c1"># This is a small number required for stability</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">nugget</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Compute the Cholesky of the covariance</span>
<span class="c1"># Notice that we need to do this only once</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>

<span class="c1"># Number of samples to take</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># Take 3 samples from the GP and plot them:</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="c1"># Plot the mean function</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>    <span class="c1"># Draw from standard normal</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">m</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>                  <span class="c1"># f = m + L * z</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#ax.set_ylim(-6., 6.)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/hands-on-21_23_0.png" src="../_images/hands-on-21_23_0.png" />
</div>
</div>
<p>The solid line is the mean function and the dashed lines are 3 samples of   f . These don’t look like functions yet. This is because we have used only 10 test points to represent the GP.</p>
<div class="section" id="id3">
<h3>Questions<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Edit the code above changing the number of test points <code class="docutils literal notranslate"><span class="pre">num_test</span></code> to 20, 50, 100. Rerun the example. How do your samples of   f look like now? Do they look more like functions to you? Imagine that the true nature of the GP appears when these test points become infinitely dense.</p></li>
<li><p>Edit the code above and change the random seed to an arbitrary integer (just make up one). Rerun the example and notice how the sampled functions change.</p></li>
<li><p>Edit the code above and change the variance first to 0.1 and then to 5 each time rerunning the example. Notice the values on the vertical axis of the plot. What happens to the sampled functions as you do this? What does the variance parameter of the SE control?</p></li>
<li><p>Edit the code above and now change the length-scale parameter first to 0.05 and then to 1. What happens to the sampled functions as you do this? What does the length- scale parameter of the SE control?</p></li>
<li><p>Now set the variance and the length-scale back to their original values (1. and 0.1, respectively). Edit the code and change the mean function to:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="n">mean_fun</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">x</span>
</pre></div>
</div>
<p>Re-run the example. What do you observe? Try a couple more. For example, try:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>     <span class="n">mean_fun</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>So far, all the samples we have seen are smooth. There is this theorem that says that the samples of the GP will be as smooth as the covariance function we use. Since the SE covariance is infinitely smooth, the samples we draw are infinitely smooth. The <a class="reference external" href="https://en.wikipedia.org/wiki/Mat%C3%A9rn_covariance_function">Matern 3-2 covariance function</a> is twice differentiable. Edit the code and
change <code class="docutils literal notranslate"><span class="pre">RBF</span></code> to <code class="docutils literal notranslate"><span class="pre">Matern32</span></code>. Rerun the example. How smooth are the samples now?</p></li>
<li><p>The exponential covariance function is continuous but not differentiable. Edit the code and change <code class="docutils literal notranslate"><span class="pre">RBF</span></code> to <code class="docutils literal notranslate"><span class="pre">Exponential</span></code>. Rerun the example. How smooth are the samples now?</p></li>
<li><p>The covariance function can also be used to model invariances. The periodic exponential covariance function is… a periodic covariance function. Edit line 29 and change <code class="docutils literal notranslate"><span class="pre">RBF</span></code> to</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="n">GPy</span><span class="o">.</span><span class="n">kern</span><span class="o">.</span><span class="n">PeriodicMatern32</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="mf">500.</span><span class="p">,</span> <span class="n">lengthscale</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<p>Rerun the example. Do you notice the periodic pattern?</p>
<ul class="simple">
<li><p>How can you encode the information that there are two lengthscales in <span class="math notranslate nohighlight">\(f(\cdot)\)</span>. There are many ways to do this.
Try summing or multiplying covariance functions.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The code above does scales as <span class="math notranslate nohighlight">\(N^2\)</span> where <span class="math notranslate nohighlight">\(N\)</span> is the number of test points.
The memory requirements is similar.
So, it is not efficient to sample like this when <span class="math notranslate nohighlight">\(N\)</span> is bigger than 2,000.
In that case, we have to resort to approximate techniques.
In particular, there are some neat techniques developed by A. Wilson from NYU.
See <a class="reference external" href="https://gpytorch.ai">https://gpytorch.ai</a> if you want to learn more.</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lecture21"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="reading-21.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Gaussian Process Theory</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../lecture22/intro.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lecture 22 - Gaussian Process Regression: Conditioning on Data</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Ilias Bilionis (ibilion[at]purdue.edu)<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>