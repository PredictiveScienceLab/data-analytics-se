

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Discrete Random Variables &#8212; Introduction to Scientific Machine Learning (Lecture Book)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lecture03/reading-03';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Discrete Random Variables in Python" href="hands-on-03.html" />
    <link rel="prev" title="Lecture 3 - Discrete Random Variables" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">Introduction to Scientific Machine Learning (Lecture Book)</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Preface
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../introduction.html">Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture01/intro.html">Lecture 1 - Introduction to Predictive Modeling</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture01/reading-01.html">The Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture01/hands-on-01.1.html">The Uncertainty Propagation Problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture01/hands-on-01.2.html">The Model Calibration Problem</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../review_probability.html">Review of Probability</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture02/intro.html">Lecture 2 - Basics of Probability Theory</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture02/reading-02.html">Basics of Probability Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture02/hands-on-02.html">Experiment with “Randomness”</a></li>
</ul>
</li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="intro.html">Lecture 3 - Discrete Random Variables</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Discrete Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="hands-on-03.html">Discrete Random Variables in Python</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture04/intro.html">Lecture 4 - Continuous Random Variables</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture04/reading-04.html">Continuous Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture04/hands-on-04.1.html">The Uniform Distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture04/hands-on-04.2.html">The Gaussian Distribution</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture05/intro.html">Lecture 5 - Collections of Random Variables</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture05/reading-05.html">Collections of Random Variables: Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture05/hands-on-05.html">Practicing with Joint Probability Mass Functions</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture06/intro.html">Lecture 6 - Random Vectors</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/reading-06.html">Random Vectors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.1.html">The Multivariate Normal - Diagonal Covariance Case</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.2.html">The Multivariate Normal - Full Covariance Case</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.3.html">The Multivariate Normal - Marginalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture06/hands-on-06.4.html">The Multivariate Normal - Conditioning</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../uncertainty_propagation.html">Uncertainty Propagation</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture07/intro.html">Lecture 7 - Basic Sampling</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.1.html">Pseudo-random number generators</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.2.html">Sampling the uniform distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.3.html">Sampling the categorical</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture07/hands-on-07.4.html">Sampling from continuous distributions - Inverse sampling</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture08/intro.html">Lecture 8 - The Monte Carlo Method for Estimating Expectations</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture08/reading-08.html">The Uncertainty Propagation Problem</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture08/hands-on-08.3.html">The Monte Carlo Method for Estimating Expectations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture08/hands-on-08.4.html">Sampling Estimates of Variance</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture09/intro.html">Lecture 9 - Monte Carlo Estimates of Various Statistics</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.1.html">Sampling Estimates of the Cumulative Distribution Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.2.html">Sampling Estimates of the Probability Density via Histograms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.3.html">Estimating Predictive Quantiles</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture09/hands-on-09.4.html">Uncertainty propagation through an ordinary differential equation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture10/intro.html">Lecture 10 - Quantify Uncertainty in Monte Carlo Estimates</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.1.html">Visualizing Monte Carlo Uncertainty</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.2.html">The Central Limit Theorem</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.3.html">Quantifying Epistemic Uncertainty in Monte Carlo Estimates</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture10/hands-on-10.4.html">Uncertainty Propagation Through a Boundary Value Problem</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../principles_of_bi.html">Principles of Bayesian Inference</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture11/intro.html">Lecture 11 - Selecting Prior Information</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/reading-11.html">Selecting Prior Information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/hands-on-11.1.html">Information Entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/hands-on-11.2.html">The Principle of Maximum Entropy for Discrete Random Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture11/hands-on-11.3.html">The Principle of Maximum Entropy for Continuous Random Variables</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture12/intro.html">Lecture 12 - Analytical Examples of Bayesian Inference</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/reading-12.html">Bayesian inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.1.html">Example: Inferring the probability of a coin toss from data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.2.html">Credible Intervals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.3.html">Decision Making</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture12/hands-on-12.4.html">Posterior Predictive Checking</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../supervised_learning.html">Supervised Learning</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture13/intro.html">Lecture 13 - Linear Regression via Least Squares</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/reading-13.html">Linear Regression via Least Squares</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.1.html">Linear regression with a single variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.2.html">Polynomial Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.3.html">The Generalized Linear Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture13/hands-on-13.4.html">Measures of Predictive Accuracy</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture14/intro.html">Lecture 14 - Bayesian Linear Regression</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/reading-14.html">Bayesian Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.1.html">Probabilistic Interpretation of Least Squares - Estimating the Measurement Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.2.html">Maximum a Posteriori Estimate - Avoiding Overfitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.3.html">Bayesian Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture14/hands-on-14.4.html">The point-predictive Distribution - Separating Epistemic and Aleatory Uncertainty</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture15/intro.html">Lecture 15 - Advanced Topics in Bayesian Linear Regression</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/reading-15.html">Advanced Topics in Bayesian Linear Regression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/hands-on-15.1.html">Evidence approximation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/hands-on-15.2.html">Automatic Relevance Determination</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture15/hands-on-15.3.html">Diagnostics for Posterior Predictive</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture16/intro.html">Lecture 16 - Classification</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/reading-16.html">Theoretical Background on Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.1.html">Logistic regression with one variable (High melting explosives)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.2.html">Logistic Regression with Many Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.3.html">Decision making</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.4.html">Diagnostics for Classifications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture16/hands-on-16.5.html">Multi-class Logistic Regression</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../unsupervised_learning.html">Unsupervised Learning</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture17/intro.html">Lecture 17 - Clustering and Density Estimation</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture17/reading-17.html">Unsupervised Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture17/hands-on-17.1.html">Clustering using k-means</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture17/hands-on-17.2.html">Density Estimation via Gaussian mixtures</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture18/intro.html">Lecture 18 - Dimensionality Reduction</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/reading-18.html">Dimensionality Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/hands-on-18.1.html">Dimensionality Reduction Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/hands-on-18.2.html">Clustering High-dimensional Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture18/hands-on-18.3.html">Density Estimation with High-dimensional Data</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../state_space_models.html">State Space Models</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture19/intro.html">Lecture 19 - State Space Models - Filtering Basics</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture19/reading-19.html">State Space Models - Filtering Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture19/hands-on-19.1.html">Object Tracking Example</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture20/intro.html">Lecture 20 - State Space Models - Kalman Filters</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture20/reading-20.html">State Space Models - Kalman Filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture20/hands-on-20.1.html">Kalman Filter for the Object Tracking Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../gaussian_process_regression.html">Gaussian Process Regression</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture21/intro.html">Lecture 21 - Gaussian Process Regression: Priors on Function Spaces</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture21/reading-21.html">Gaussian Process Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture21/hands-on-21.html">Example: Priors on function spaces</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture22/intro.html">Lecture 22 - Gaussian Process Regression: Conditioning on Data</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/reading-22.html">Gaussian Process Regression - Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.1.html">Gaussian Process Regression Without Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.2.html">Gaussian Process Regression with Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.3.html">Tuning the Hyperparameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture22/hands-on-22.4.html">Multivariate Gaussian Process Regression</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture23/intro.html">Lecture 23 - Bayesian Global Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/reading-23.html">Bayesian Global Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.1.html">Maximum Mean - A Bad Information Acquisition Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.2.html">Maximum Upper Interval</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.3.html">Probability of Improvement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.4.html">Expected Improvement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.5.html">Expected Improvement - With Observation Noise</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture23/hands-on-23.6.html">Quantifying Epistemic Uncertainty about the Solution of the Optimization problem</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../neural_networks.html">Neural Networks</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture24/intro.html">Lecture 24 - Deep Neural Networks</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-33"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture24/reading-24.html">Deep Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture24/hands-on-24.html">Regression with Deep Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture25/intro.html">Lecture 25 - Deep Neural Networks Continued</a><input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-34"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture25/reading-25.html">Deep Neural Networks Continued</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture25/hands-on-25.html">Classification with Deep Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture26/intro.html">Lecture 26 - Physics-informed Deep Neural Networks</a><input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-35"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture26/reading-26.html">Physics-informed Deep Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture26/hands-on-26.1.html">Physics-informed regularization: Solving ODEs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture26/hands-on-26.2.html">Physics-informed regularization: Solving PDEs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../advanced_methods.html">Advanced Methods for Characterizing Posteriors</a><input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-36"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture27/intro.html">Lecture 27 - Sampling Methods</a><input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-37"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/reading-27.html">Sampling Methods</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/hands-on-27.1.html">Probabilistic programming with <code class="docutils literal notranslate"><span class="pre">PyMC</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/hands-on-27.2.html">Sampling From the Distributions With Random Walk Metropolis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/hands-on-27.3.html">The Metropolis-Hastings Algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/hands-on-27.4.html">Gibbs Sampling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture27/hands-on-27.5.html">Sequential Monte Carlo</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../lecture28/intro.html">Lecture 28 - Variational Inference</a><input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-38"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../lecture28/reading-28.html">Variational Inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="../lecture28/hands-on-28.html">Variational Inference Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../homework/intro.html">Homework</a><input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-39"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-01.html">Homework 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-02.html">Homework 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-03.html">Homework 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-04.html">Homework 4</a></li>



<li class="toctree-l2"><a class="reference internal" href="../homework/homework-05.html">Homework 5</a></li>



<li class="toctree-l2"><a class="reference internal" href="../homework/homework-06.html">Homework 6</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-07.html">Homework 7</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/homework-08.html">Homework 8</a></li>












</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/PredictiveScienceLab/data-analytics-se/blob/master/lecturebook/lecture03/reading-03.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lecture03/reading-03.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Discrete Random Variables</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-spaces">Probability spaces</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mathematical-definition-of-a-random-variable">The mathematical definition of a random variable</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-1-2">Example: The random variable corresponding to the result of a coin toss (1/2)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-probability-mass-function">The probability mass function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties-of-the-probability-mass-function">Properties of the probability mass function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-2-2">Example: The random variable corresponding to the result of a coin toss (2/2)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#functions-of-discrete-random-variables">Functions of discrete random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-of-random-variables">Expectation of random variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-expectation-of-a-coin-toss">Example: Expectation of a coin toss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties-of-the-expectation">Properties of the expectation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variance-of-random-variables">Variance of random variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-variance-of-a-coin-toss">Example: Variance of a coin toss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties-of-the-variance">Properties of the variance</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="discrete-random-variables">
<span id="id1"></span><h1>Discrete Random Variables<a class="headerlink" href="#discrete-random-variables" title="Permalink to this heading">#</a></h1>
<section id="probability-spaces">
<h2>Probability spaces<a class="headerlink" href="#probability-spaces" title="Permalink to this heading">#</a></h2>
<p>We condition the probabilities on our current information <span class="math notranslate nohighlight">\(I\)</span> in whatever we write below.
Because this information is always in the background, we will not explicitly show it in our notation.</p>
<p>Let’s suppose we are doing an experiment.
It doesn’t matter what precisely the experiment is.
The result of the experiment depends on a bunch of things denoted by <span class="math notranslate nohighlight">\(\omega\)</span>.
Some people call <span class="math notranslate nohighlight">\(\omega\)</span> the <strong>state of nature</strong>.
This variable may be more than is needed for our experiment, but it is an excellent way to think about it.
In any case, the state of nature includes the physical variables that determine the result of the experiment.</p>
<p>The state of nature takes values in an enormous set <span class="math notranslate nohighlight">\(\Omega\)</span>.
So an <span class="math notranslate nohighlight">\(\omega_1\)</span> may happen, an <span class="math notranslate nohighlight">\(\omega_2\)</span> may occur, and so on, all included in <span class="math notranslate nohighlight">\(\Omega\)</span>.
We do not know which <span class="math notranslate nohighlight">\(\omega\)</span> will happen.
We describe this uncertainty using something called a <strong>probability measure</strong>.</p>
<p>What is this probability measure?
It is a function that takes a subset <span class="math notranslate nohighlight">\(A\)</span> of <span class="math notranslate nohighlight">\(\Omega\)</span> and tells us how probable the state of nature will be in <span class="math notranslate nohighlight">\(A\)</span>.
We write this probability as <span class="math notranslate nohighlight">\(p(A)\)</span>.
When equipped with the probability measure <span class="math notranslate nohighlight">\(p\)</span>, the set <span class="math notranslate nohighlight">\(\Omega\)</span> is called a <strong>probability space</strong>.</p>
<div class="dropdown admonition">
<p class="admonition-title">Okay, it is a bit more complicated than that.</p>
<p>The probability measure cannot always be defined over all subsets of <span class="math notranslate nohighlight">\(\Omega\)</span>.
It can only be defined over a particular set <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> of subsets of <span class="math notranslate nohighlight">\(\Omega\)</span>, which mathematicians call a <strong><span class="math notranslate nohighlight">\(\sigma\)</span>-algebra</strong>.
Then the probability measure <span class="math notranslate nohighlight">\(p\)</span> is a function from <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> to <span class="math notranslate nohighlight">\([0,1]\)</span> satisfying specific properties called the <strong>Kolmogorov axioms</strong>.
The triplet <span class="math notranslate nohighlight">\((\Omega, \mathcal{F}, \mathbb{P})\)</span> is called a <strong>probability space</strong>.
We will not go into the details of this.
You will have to take a course in measure theory to learn more about this.</p>
</div>
</section>
<section id="the-mathematical-definition-of-a-random-variable">
<h2>The mathematical definition of a random variable<a class="headerlink" href="#the-mathematical-definition-of-a-random-variable" title="Permalink to this heading">#</a></h2>
<p>Call <span class="math notranslate nohighlight">\(X\)</span> the result of the experiment.
It is, say, the number we read in a measuring device.
What does the measuring device do?
Well, it takes the state of nature <span class="math notranslate nohighlight">\(\omega\)</span> and maps it to a number <span class="math notranslate nohighlight">\(X(\omega)\)</span>.
That’s why the mathematicians define a random variable as a function from <span class="math notranslate nohighlight">\(\Omega\)</span> to some set of values.</p>
<div class="dropdown admonition">
<p class="admonition-title">Okay again, it is a bit more complicated than that.</p>
<p>The set of values is not just any set.
It is a set that is equipped with a <span class="math notranslate nohighlight">\(\sigma\)</span>-algebra and a probability measure.
This set is called the <strong>state space</strong> of the random variable.
The random variable has to be a measurable function from <span class="math notranslate nohighlight">\(\Omega\)</span> to the state space.</p>
</div>
<p>Depending on the values that <span class="math notranslate nohighlight">\(X\)</span> takes, we can classify it into several types:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(X(\omega)\)</span> takes discrete values, like heads or tails, <span class="math notranslate nohighlight">\(0, 1, 2\)</span>, etc., then we say that <span class="math notranslate nohighlight">\(X\)</span> is a discrete random variable.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(X(\omega)\)</span> takes continuous values, like values from zero to one, or all positive real numbers, we say that <span class="math notranslate nohighlight">\(X\)</span> is a continuous random variable.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(X(\omega)\)</span> is a vector, then we say that <span class="math notranslate nohighlight">\(X\)</span> is a random vector.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(X(\omega)\)</span> is a matrix, then we say that <span class="math notranslate nohighlight">\(X\)</span> is a random matrix.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(X(\omega)\)</span> is a function, then we say that <span class="math notranslate nohighlight">\(X\)</span> is a random process (or a stochastic process or a random field), and so on.</p></li>
</ul>
<p>Notation:</p>
<ul class="simple">
<li><p>We will use upper case letters to represent random variables, like <span class="math notranslate nohighlight">\(X, Y, Z\)</span>.</p></li>
<li><p>We will use lowercase letters to represent the values of random variables, like <span class="math notranslate nohighlight">\(x, y, z\)</span>.</p></li>
</ul>
<section id="example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-1-2">
<h3>Example: The random variable corresponding to the result of a coin toss (1/2)<a class="headerlink" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-1-2" title="Permalink to this heading">#</a></h3>
<p>Let’s consider the coin tossing example we introduced in <a class="reference internal" href="../lecture02/hands-on-02.html#coin-toss"><span class="std std-ref">the previous lecture</span></a> again.
Recall that we denoted with <span class="math notranslate nohighlight">\(v_0\)</span> and <span class="math notranslate nohighlight">\(\omega_0\)</span> the coin’s initial velocity and angular velocity.
These two ultimately determine the result of the experiment.
So <span class="math notranslate nohighlight">\(\omega = (v_0, \omega_0)\)</span>.
The result of the experiment <span class="math notranslate nohighlight">\(X\)</span> is a function of <span class="math notranslate nohighlight">\(v_0\)</span> and <span class="math notranslate nohighlight">\(\omega_0\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X(v_0,\omega_0) = 
\begin{cases}
T,&amp;\;\text{if}\;\frac{2v_0\omega_0}{g} (\text{mod}\;2\pi) \in \left(\frac{\pi}{2},\frac{3\pi}{2}\right),\\
H,&amp;\;\text{otherwise}.
\end{cases}
\end{split}\]</div>
<p>You see that the result of the coin toss <span class="math notranslate nohighlight">\(X\)</span> is nothing more but a function of the <em>true state of nature</em> <span class="math notranslate nohighlight">\(\omega = (v_0, \omega_0)\)</span>.
We reproduce the causal graph:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gct</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">(</span><span class="s1">&#39;coin_toss_g&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;omega0&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;&lt;&amp;omega;&lt;sub&gt;0&lt;/sub&gt;&gt;&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;&lt;v&lt;sub&gt;0&lt;/sub&gt;&gt;&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">&#39;filled&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;omega0&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">&#39;coin_toss_g&#39;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">)</span>
<span class="n">gct</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/8c19b88e5a9e9949f2485289dfc37ec172771224aca184fd1f9c268cb66d4555.svg" src="../_images/8c19b88e5a9e9949f2485289dfc37ec172771224aca184fd1f9c268cb66d4555.svg" /></div>
</div>
</section>
<section id="the-probability-mass-function">
<h3>The probability mass function<a class="headerlink" href="#the-probability-mass-function" title="Permalink to this heading">#</a></h3>
<p>We will now focus on the discrete random variable <span class="math notranslate nohighlight">\(X\)</span>.
The probability mass function of <span class="math notranslate nohighlight">\(X\)</span> is a function that gives the probability of <span class="math notranslate nohighlight">\(X\)</span> taking a particular value, say <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>Mathematicians write <span class="math notranslate nohighlight">\(f_X(x)\)</span> for the probability mass function of <span class="math notranslate nohighlight">\(X\)</span>.
The subscript <span class="math notranslate nohighlight">\(X\)</span> reminds us we are talking about the random variable <span class="math notranslate nohighlight">\(X\)</span>.
Everyone else writes <span class="math notranslate nohighlight">\(p(x)\)</span> if there is no confusion about which random variable we are talking about.
We are going to follow the latter convention.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If we wanted to show the background information, we would write <span class="math notranslate nohighlight">\(p(x|I)\)</span>.</p>
</div>
<p>We define the probability mass function in terms of the underlying probability space.
Here is how.
We define the set of states of nature that give an experiment with value <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="math notranslate nohighlight">
\[
(X=x) \equiv \{\omega \in \Omega: X(\omega) = x\}.
\]</div>
<p>Then the probability mass function is defined as:</p>
<div class="math notranslate nohighlight">
\[
p(x) \equiv f_X(x) := p\left(X=x\right).
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>No one, except the mathematicians, cares about the underlying probability space.
It is there to rigorously define the probability mass function so that we can prove things about it.
In practice, we only care about the probability mass function.
If we have it, we can calculate any probability we want about the random variable.</p>
</div>
</section>
<section id="properties-of-the-probability-mass-function">
<h3>Properties of the probability mass function<a class="headerlink" href="#properties-of-the-probability-mass-function" title="Permalink to this heading">#</a></h3>
<p>There are some standard properties of the probability mass function that is worth memorizing:</p>
<ul class="simple">
<li><p>It is nonnegative:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p(x) \ge 0,
\]</div>
<p>for all <span class="math notranslate nohighlight">\(x\)</span>.</p>
<ul class="simple">
<li><p>It is normalized:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\sum_x p(x) = 1,
\]</div>
<p>where the summation is over all possible values <span class="math notranslate nohighlight">\(x\)</span>.</p>
<ul class="simple">
<li><p>It is additive. Take any set of possible values of <span class="math notranslate nohighlight">\(X\)</span>, say <span class="math notranslate nohighlight">\(A\)</span>. The probability of <span class="math notranslate nohighlight">\(X\)</span> taking values in <span class="math notranslate nohighlight">\(A\)</span> is:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p(X\in A) = \sum_{x\in A} p(x).
\]</div>
</section>
<section id="example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-2-2">
<h3>Example: The random variable corresponding to the result of a coin toss (2/2)<a class="headerlink" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-2-2" title="Permalink to this heading">#</a></h3>
<p>Suppose <span class="math notranslate nohighlight">\(X\)</span> is the random variable corresponding to the result of the coin toss.
We will write <span class="math notranslate nohighlight">\(X=0\)</span> if the result is heads and <span class="math notranslate nohighlight">\(X=1\)</span> if the result is tails.
As mentioned earlier, we can directly work with the probability mass function instead of trying to define the underlying probability space.
For a fair coin, it makes intuitive sense that:</p>
<div class="math notranslate nohighlight">
\[
p(X=0) = \text{probability of heads} = \frac{1}{2}.
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
p(X=1) = \frac{1}{2}.
\]</div>
<p>The probability that <span class="math notranslate nohighlight">\(X\)</span> takes any other value is zero.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We should be careful about the notation.
I said that <span class="math notranslate nohighlight">\(p(x)\)</span> is the probability mass function of <span class="math notranslate nohighlight">\(X\)</span>.
It is a good notation when I want to talk about the entire function.
There is no ambiguity as <span class="math notranslate nohighlight">\(p(x)\)</span> is the probability mass function of the random variable labeled by the capitalization of the letter <span class="math notranslate nohighlight">\(x\)</span>, i.e., <span class="math notranslate nohighlight">\(X\)</span>, evaluated at the lower case <span class="math notranslate nohighlight">\(x\)</span>.
But I cannot write <span class="math notranslate nohighlight">\(p(0)\)</span> or <span class="math notranslate nohighlight">\(p(1)\)</span> because then I do not know which random variable I am talking about.
So I wrote <span class="math notranslate nohighlight">\(p(X=0)\)</span> and <span class="math notranslate nohighlight">\(p(X=1)\)</span>.
Some people write <span class="math notranslate nohighlight">\(p(x=0)\)</span> and <span class="math notranslate nohighlight">\(p(x=1)\)</span>.
Mathematicians point out that this is an argument for using <span class="math notranslate nohighlight">\(f_X(x)\)</span> instead of <span class="math notranslate nohighlight">\(p(x)\)</span>.
They have a point, but I’d save myself the trouble of always writing <span class="math notranslate nohighlight">\(f_X(x)\)</span>.</p>
</div>
</section>
</section>
<section id="functions-of-discrete-random-variables">
<h2>Functions of discrete random variables<a class="headerlink" href="#functions-of-discrete-random-variables" title="Permalink to this heading">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a discrete random variable and <span class="math notranslate nohighlight">\(g\)</span> be a function from the state space of <span class="math notranslate nohighlight">\(X\)</span> to some other set.
We can now define a new random variable:</p>
<div class="math notranslate nohighlight">
\[
Y = g(X).
\]</div>
<p>Let <span class="math notranslate nohighlight">\(g^{-1}(y)\)</span> be the set of values of <span class="math notranslate nohighlight">\(X\)</span> that map to <span class="math notranslate nohighlight">\(y\)</span> through <span class="math notranslate nohighlight">\(g\)</span>:</p>
<div class="math notranslate nohighlight">
\[
g^{-1}(y) := \{x: g(x) = y\}.
\]</div>
<p>Then, the probability mass function (pmf) of <span class="math notranslate nohighlight">\(Y\)</span> is:</p>
<div class="math notranslate nohighlight">
\[
p(y) = p(Y = y) = p(X\in g^{-1}(y)) = \sum_{x\in g^{-1}(y)} p(x),
\]</div>
<p>We have given the formal definition of the uncertainty propagation problem.
The correspondence is that <span class="math notranslate nohighlight">\(X\)</span> represents the parameters of a causal model, and <span class="math notranslate nohighlight">\(Y = g(X)\)</span> is the uncertain result of the causal model.</p>
</section>
<section id="expectation-of-random-variables">
<h2>Expectation of random variables<a class="headerlink" href="#expectation-of-random-variables" title="Permalink to this heading">#</a></h2>
<p>The expectation of a random variable is defined by:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[X] = \sum_{x=0}^\infty x p(x).
\]</div>
<p>You can think of the expectation as the value of the random variable that one should “expect” to get.</p>
<section id="example-expectation-of-a-coin-toss">
<h3>Example: Expectation of a coin toss<a class="headerlink" href="#example-expectation-of-a-coin-toss" title="Permalink to this heading">#</a></h3>
<p>The expectation of the coin toss random variable is:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[X] = 0\cdot p(X=0) + 1\cdot p(X=1) = 0.5.
\]</div>
<p>We should take the interpretation of the expectation with a grain of salt.
The expectation is not necessarily a value that the random variable can take.
It is weird to say that we “expect” to get <span class="math notranslate nohighlight">\(0.5\)</span> when we toss a coin.</p>
</section>
<section id="properties-of-the-expectation">
<span id="properties-expectation"></span><h3>Properties of the expectation<a class="headerlink" href="#properties-of-the-expectation" title="Permalink to this heading">#</a></h3>
<p>Here are some properties of the expectation.</p>
<ul class="simple">
<li><p>Take any constant <span class="math notranslate nohighlight">\(c\)</span>. Then we have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[X + c] = \mathbb{E}[X] + c.
\]</div>
<div class="dropdown admonition">
<p class="admonition-title">Proof</p>
<p>This proof is a little bit trickier than it looks.
First, define the random variable:</p>
<div class="math notranslate nohighlight">
\[
Y = X + c.
\]</div>
<p>The PMF of <span class="math notranslate nohighlight">\(Y\)</span> is:</p>
<div class="math notranslate nohighlight">
\[
p(y) = p(Y = y) = p(X + c = y) = p(X = y - c).
\]</div>
<p>Then we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{E}[X + c] &amp;= \mathbb{E}[Y]\\
&amp;= \sum_y y p(y)\\
&amp;= \sum_y y p(Y = y)\\
&amp;= \sum_y y p(X = y - c).
\end{align}
\end{split}\]</div>
<p>Now we change the variable of summation to <span class="math notranslate nohighlight">\(x = y - c\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{E}[X + c] &amp;= \sum_y (x + c) p(X = x)\\
&amp;= \sum_x x p(X = x) + c \sum_x p(X = x)\\
&amp;= \mathbb{E}[X] + c,
\end{align}
\end{split}\]</div>
<p>where in the last step we used the fact that the sum of the PMF is <span class="math notranslate nohighlight">\(1\)</span>.</p>
</div>
<ul class="simple">
<li><p>For any <span class="math notranslate nohighlight">\(\lambda\)</span> real number, we also have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[\lambda X] = \lambda \mathbb{E}[X].
\]</div>
<div class="dropdown admonition">
<p class="admonition-title">Proof</p>
<p>The proof is similar to the previous one.
But we need to work with the random variable:</p>
<div class="math notranslate nohighlight">
\[
Y = \lambda X.
\]</div>
</div>
<ul class="simple">
<li><p>Now consider any function <span class="math notranslate nohighlight">\(g(x)\)</span>.
We can now define the expectation of <span class="math notranslate nohighlight">\(g(X)\)</span> as the expectation of the random variable <span class="math notranslate nohighlight">\(Y = g(X)\)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[g(X)] = \sum_x g(x) p(x).
\]</div>
<div class="dropdown admonition">
<p class="admonition-title">Proof</p>
<p>The proof is the same as before but we are going with the more general random variable:</p>
<div class="math notranslate nohighlight">
\[
Y = g(X).
\]</div>
<p>We have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{E}[g(X)] &amp;= \mathbb{E}[Y]\\
&amp;= \sum_y y p(y)\\
&amp;= \sum_y y p(Y = y)\\
&amp;= \sum_y y p(X\in g^{-1}(y))\\
&amp;= \sum_y y \sum_{x\in g^{-1}(y)} p(x)\\
&amp;= \sum_x \sum_{y=g(x)} y p(x)\\
&amp;= \sum_x g(x) p(x).
\end{align}
\end{split}\]</div>
</div>
<ul class="simple">
<li><p>Assume that <span class="math notranslate nohighlight">\(g(x)\)</span> is a convex function.
Recall that a convex function is a function that looks like a bowl.
Then we have the Jensen’s inequality:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
g\left(\mathbb{E}[X]\right) \le \mathbb{E}[g(X)].
\]</div>
<p>The proof is not trivial.</p>
</section>
</section>
<section id="variance-of-random-variables">
<h2>Variance of random variables<a class="headerlink" href="#variance-of-random-variables" title="Permalink to this heading">#</a></h2>
<p>The variance of a random variable <span class="math notranslate nohighlight">\(X\)</span> is defined as the expectation of the square deviation from its expectation, i.e.:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[X] := \mathbb{E}\left[(X - \mathbb{E}[X])^2\right].
\]</div>
<p>You can think of the variance as the spread of the random variable around its expectation.
However, take this with a grain of salt for discrete random variables.</p>
<section id="example-variance-of-a-coin-toss">
<h3>Example: Variance of a coin toss<a class="headerlink" href="#example-variance-of-a-coin-toss" title="Permalink to this heading">#</a></h3>
<p>Let’s calculate the variance of the coin toss.
We need:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}\left[X^2\right] = 0^2\cdot p(X=0) + 1^2 \cdot p(X=1) = 0.5.
\]</div>
<p>So, using the formula above, we get the following:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[X] = \mathbb{E}\left[X^2\right] - \left(\mathbb{E}[X]\right)^2 = 0.5 - (0.5)^2 = 0.5 - 0.25 = 0.25.
\]</div>
</section>
<section id="properties-of-the-variance">
<span id="properties-variance"></span><h3>Properties of the variance<a class="headerlink" href="#properties-of-the-variance" title="Permalink to this heading">#</a></h3>
<p>Here are some properties of the variance.</p>
<ul class="simple">
<li><p>It holds that:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[X] = \mathbb{E}\left[X^2\right] - \left(\mathbb{E}[X]\right)^2.
\]</div>
<div class="dropdown admonition">
<p class="admonition-title">Proof</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{V}[X] &amp;= \mathbb{E}\left[(X - \mathbb{E}[X])^2\right]\\
&amp;= \mathbb{E}\left[X^2 - 2X\mathbb{E}[X] + \left(\mathbb{E}[X]\right)^2\right]\\
&amp;= \mathbb{E}\left[X^2\right] - 2\mathbb{E}[X]\mathbb{E}[X] + \left(\mathbb{E}[X]\right)^2\\
&amp;= \mathbb{E}\left[X^2\right] - \left(\mathbb{E}[X]\right)^2.
\end{align}
\end{split}\]</div>
</div>
<p>We use this formula we use to calculate the variance in practice.</p>
<ul class="simple">
<li><p>For any constant <span class="math notranslate nohighlight">\(c\)</span>, we have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[X + c] = \mathbb{V}[X].
\]</div>
<div class="dropdown admonition">
<p class="admonition-title">Proof</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{V}[X + c] &amp;= \mathbb{E}\left[(X + c - \mathbb{E}[X + c])^2\right]\\
&amp;= \mathbb{E}\left[(X + c - \mathbb{E}[X] - c)^2\right]\\
&amp;= \mathbb{E}\left[(X - \mathbb{E}[X])^2\right]\\
&amp;= \mathbb{V}[X].
\end{align}
\end{split}\]</div>
</div>
<ul class="simple">
<li><p>For any constant <span class="math notranslate nohighlight">\(c\)</span>, we have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[cX] = c^2\mathbb{V}[X].
\]</div>
<div class="dropdown admonition">
<p class="admonition-title">Proof</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathbb{V}[cX] &amp;= \mathbb{E}\left[(cX - \mathbb{E}[cX])^2\right]\\
&amp;= \mathbb{E}\left[(cX - c\mathbb{E}[X])^2\right]\\
&amp;= \mathbb{E}\left[c^2(X - \mathbb{E}[X])^2\right]\\
&amp;= c^2\mathbb{E}\left[(X - \mathbb{E}[X])^2\right]\\
&amp;= c^2\mathbb{V}[X].
\end{align}
\end{split}\]</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lecture03"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture 3 - Discrete Random Variables</p>
      </div>
    </a>
    <a class="right-next"
       href="hands-on-03.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Discrete Random Variables in Python</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-spaces">Probability spaces</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-mathematical-definition-of-a-random-variable">The mathematical definition of a random variable</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-1-2">Example: The random variable corresponding to the result of a coin toss (1/2)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-probability-mass-function">The probability mass function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties-of-the-probability-mass-function">Properties of the probability mass function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-2-2">Example: The random variable corresponding to the result of a coin toss (2/2)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#functions-of-discrete-random-variables">Functions of discrete random variables</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-of-random-variables">Expectation of random variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-expectation-of-a-coin-toss">Example: Expectation of a coin toss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties-of-the-expectation">Properties of the expectation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#variance-of-random-variables">Variance of random variables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-variance-of-a-coin-toss">Example: Variance of a coin toss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#properties-of-the-variance">Properties of the variance</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ilias Bilionis (ibilion[at]purdue.edu)
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>