
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Discrete Random Variables &#8212; Introduction to Scientific Machine Learning (Lecture Book)</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Discrete Random Variables in Python" href="hands-on-03.html" />
    <link rel="prev" title="Lecture 3 - Discrete Random Variables" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Introduction to Scientific Machine Learning (Lecture Book)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Preface
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../introduction.html">
   Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture01/intro.html">
     Lecture 1 - Introduction to Predictive Modeling
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture01/reading-01.html">
       Predictive Modeling and Scientific Machine Learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture01/hands-on-01.1.html">
       The Uncertainty Propagation Problem
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture01/hands-on-01.2.html">
       The Model Calibration Problem
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../review_probability.html">
   Review of Probability
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture02/intro.html">
     Lecture 2 - Basics of Probability Theory
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture02/reading-02.html">
       Basics of Probability Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture02/hands-on-02.html">
       Experiment with “Ranomness”
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="intro.html">
     Lecture 3 - Discrete Random Variables
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Discrete Random Variables
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hands-on-03.html">
       Discrete Random Variables in Python
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture04/intro.html">
     Lecture 4 - Continuous Random Variables
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture04/reading-04.html">
       Continuous Random Variables
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture04/hands-on-04.1.html">
       The Uniform Distribution
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture04/hands-on-04.2.html">
       The Gaussian Distribution
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture05/intro.html">
     Lecture 5 - Collections of Random Variables
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture05/reading-05.html">
       Collections of Random Variables: Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture05/hands-on-05.html">
       Practicing with joint probability mass functions
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture06/intro.html">
     Lecture 6 - Random Vectors
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/reading-06.html">
       Random Vectors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/hands-on-06.1.html">
       The Multivariate Normal - Diagonal Covariance Case
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/hands-on-06.2.html">
       The Multivariate Normal - Full Covariance Case
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/hands-on-06.3.html">
       The Multivariate Normal - Marginalization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture06/hands-on-06.4.html">
       The Multivariate Normal - Conditioning
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../uncertainty_propagation.html">
   Uncertainty Propagation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture07/intro.html">
     Lecture 7 - Basic Sampling
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture07/hands-on-07.1.html">
       Pseudo-random number generators
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture07/hands-on-07.2.html">
       Sampling the uniform
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture07/hands-on-07.3.html">
       Sampling the categorical
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture07/hands-on-07.4.html">
       Sampling from continuous distributions - Inverse sampling
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture08/intro.html">
     Lecture 8 - The Monte Carlo Method for Estimating Expectations
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture08/hands-on-08.3.html">
       Sampling Estimates of Expectations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture08/hands-on-08.4.html">
       Sampling Estimates of Variance
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture09/intro.html">
     Lecture 9 - Monte Carlo Estimates of Various Statistics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture09/hands-on-09.1.html">
       Sampling Estimates of the Cumulative Distribution Function
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture09/hands-on-09.2.html">
       Sampling Estimates of the Probability Density via Histograms
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture09/hands-on-09.3.html">
       Hands-on Activity 9.3: Sampling Estimates of Predictive Quantiles
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture09/hands-on-09.4.html">
       Propagating Uncertainties through an Ordinrary Differential Equation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture10/intro.html">
     Lecture 10 - Quantify Uncertainty in Monte Carlo Estimates
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture10/hands-on-10.1.html">
       Visualizing Monte Carlo Uncertainty
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture10/hands-on-10.2.html">
       The Central Limit Theorem
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture10/hands-on-10.3.html">
       Quanifying Epistemic Uncertainty in Monte Carlo estimates
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture10/hands-on-10.4.html">
       Uncertainty Propagation Through a Boundary Value Problem
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../principles_of_bi.html">
   Principles of Bayesian Inference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture11/intro.html">
     Lecture 11 - Selecting Prior Information
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
    <label for="toctree-checkbox-15">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture11/reading-11.html">
       Selecting Prior Information
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture11/hands-on-11.1.html">
       Information Entropy
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture11/hands-on-11.2.html">
       The Principle of Maximum Entropy for Discrete Random Variables
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture11/hands-on-11.3.html">
       The Principle of Maximum Entropy for Continuous Random Variables
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture12/intro.html">
     Lecture 12 - Analytical Examples of Bayesian Inference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
    <label for="toctree-checkbox-16">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/reading-12.html">
       Analytical Examples of Bayesian Inference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/hands-on-12.1.html">
       Bayesian Parameter Estimation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/hands-on-12.2.html">
       Credible Intervals
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/hands-on-12.3.html">
       Decision-Making
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture12/hands-on-12.4.html">
       Posterior Predictive Checking
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../supervised_learning.html">
   Supervised Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture13/intro.html">
     Lecture 13 - Linear Regression via Least Squares
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/reading-13.html">
       Linear Regression via Least Squares
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/hands-on-13.1.html">
       Linear regression with a single variable
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/hands-on-13.2.html">
       Polynomial Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/hands-on-13.3.html">
       The Generalized Linear Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture13/hands-on-13.4.html">
       Measures of Predictive Accuracy
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture14/intro.html">
     Lecture 14 - Bayesian Linear Regression
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/reading-14.html">
       Bayesian Linear Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/hands-on-14.1.html">
       Probabilistic Interpretation of Least Squares - Estimating the Measurement Noise
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/hands-on-14.2.html">
       Maximum a Posteriori Estimate - Avoiding Overfitting
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/hands-on-14.3.html">
       Bayesian Linear Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture14/hands-on-14.4.html">
       The point-predictive Distribution - Separating Epistmic and Aleatory Uncertainty
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture15/intro.html">
     Lecture 15 - Advanced Topics in Bayesian Linear Regression
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
    <label for="toctree-checkbox-20">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture15/reading-15.html">
       Advanced Topics in Bayesian Linear Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture15/hands-on-15.1.html">
       Evidence approximation
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture15/hands-on-15.2.html">
       Automatic Relevance Determination
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture15/hands-on-15.3.html">
       Diagnostics for Posterior Predictive
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture16/intro.html">
     Lecture 16 - Classification
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
    <label for="toctree-checkbox-21">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/reading-16.html">
       Theoretical Background on Classification
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.1.html">
       Logistic regression with one variable (High melting explosives)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.2.html">
       Logistic Regression with Many Features
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.3.html">
       Decision making
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.4.html">
       Diagnostics for Classifications
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture16/hands-on-16.5.html">
       Multi-class Logistic Regression
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../unsupervised_learning.html">
   Unsupervised Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture17/intro.html">
     Lecture 17 - Clustering and Density Estimation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
    <label for="toctree-checkbox-23">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture17/reading-17.html">
       Unsupervised Learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture17/hands-on-17.1.html">
       Clustering using k-means
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture17/hands-on-17.2.html">
       Density Estimation via Gaussian mixtures
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture18/intro.html">
     Lecture 18 - Dimensionality Reduction
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture18/reading-18.html">
       Dimensionality Reduction
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture18/hands-on-18.1.html">
       Dimensionality Reduction Examples
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture18/hands-on-18.2.html">
       Clustering High-dimensional Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture18/hands-on-18.3.html">
       Density Estimation with High-dimensional Data
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../state_space_models.html">
   State Space Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
  <label for="toctree-checkbox-25">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture19/intro.html">
     Lecture 19 - State Space Models - Filtering Basics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
    <label for="toctree-checkbox-26">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture19/reading-19.html">
       State Space Models - Filtering Basics
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture19/hands-on-19.1.html">
       Object Tracking Example
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture20/intro.html">
     Lecture 20 - State Space Models - Kalman Filters
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
    <label for="toctree-checkbox-27">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture20/reading-20.html">
       State Space Models - Kalman Filters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture20/hands-on-20.1.html">
       Kalman Filter for Object Tracking Example
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../gaussian_process_regression.html">
   Gaussian Process Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
  <label for="toctree-checkbox-28">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture21/intro.html">
     Lecture 21 - Gaussian Process Regression: Priors on Function Spaces
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture21/reading-21.html">
       Gaussian Process Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture21/hands-on-21.html">
       Example: Priors on function spaces
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture22/intro.html">
     Lecture 22 - Gaussian Process Regression: Conditioning on Data
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
    <label for="toctree-checkbox-30">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/reading-22.html">
       Gaussian Process Regression - Theory
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/hands-on-22.1.html">
       Gaussian Process Regression Without Noise
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/hands-on-22.2.html">
       Gaussian Process Regression with Noise
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/hands-on-22.3.html">
       Tuning the Hyperparameters
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture22/hands-on-22.4.html">
       Multivariate Gaussian Process Regression
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture23/intro.html">
     Lecture 23 - Bayesian Global Optimization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
    <label for="toctree-checkbox-31">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/reading-23.html">
       Bayesian Global Optimization
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/hands-on-23.1.html">
       Maximum Mean - A Bad Information Acquisition Function
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/hands-on-23.2.html">
       Maximum Upper Interval
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/hands-on-23.3.html">
       Probability of Improvement
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture23/hands-on-23.4.html">
       Expected Improvement
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../neural_networks.html">
   Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
  <label for="toctree-checkbox-32">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture24/intro.html">
     Lecture 24 - Deep Neural Networks
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/>
    <label for="toctree-checkbox-33">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture24/reading-24.html">
       Deep Neural Networks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture24/hands-on-24.html">
       Regression with Deep Neural Networks
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture25/intro.html">
     Lecture 25 - Deep Neural Networks Continued
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/>
    <label for="toctree-checkbox-34">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture25/reading-25.html">
       Deep Neural Networks Continued
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture25/hands-on-25.html">
       Classification with Deep Neural Networks
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture26/intro.html">
     Lecture 26 - Physics-informed Deep Neural Networks
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/>
    <label for="toctree-checkbox-35">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture26/reading-26.html">
       Physics-informed Deep Neural Networks
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture26/hands-on-26.1.html">
       Physics-informed regularization: Solving ODEs
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture26/hands-on-26.2.html">
       Physics-informed regularization: Solving PDEs
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../advanced_methods.html">
   Advanced Methods for Characterizing Posteriors
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/>
  <label for="toctree-checkbox-36">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture27/intro.html">
     Lecture 27 - Sampling Methods
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/>
    <label for="toctree-checkbox-37">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/reading-27.html">
       Sampling Methods
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.1.html">
       Probabilistic programming with
       <code class="docutils literal notranslate">
        <span class="pre">
         PyMC3
        </span>
       </code>
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.2.html">
       Sampling From the Distributions With Random Walk Metropolis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.3.html">
       The Metropolis-Hastings Algorithm
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.4.html">
       Gibbs Sampling
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture27/hands-on-27.5.html">
       Sequential Monte Carlo
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../lecture28/intro.html">
     Lecture 28 - Variational Inference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/>
    <label for="toctree-checkbox-38">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture28/reading-28.html">
       Variational Inference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../lecture28/hands-on-28.html">
       Variational Inference Examples
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/lecture03/reading-03.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/PredictiveScienceLab/data-analytics-se/master?urlpath=lab/tree/lecturebook/lecture03/reading-03.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/PredictiveScienceLab/data-analytics-se/blob/master/lecturebook/lecture03/reading-03.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-spaces">
   Probability spaces
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-mathematical-definition-of-a-random-variable">
   The mathematical definition of a random variable
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-1-2">
     Example: The random variable corresponding to the result of a coin toss (1/2)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-probability-mass-function">
   The probability mass function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#properties-of-the-probability-mass-function">
     Properties of the probability mass function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-2-2">
     Example: The random variable corresponding to the result of a coin toss (2/2)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#functions-of-discrete-random-variables">
   Functions of discrete random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#expectation-of-random-variables">
   Expectation of random variables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-expectation-of-a-coin-toss">
     Example: Expectation of a coin toss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#properties-of-the-expectation">
     Properties of the expectation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#variance-of-random-variables">
   Variance of random variables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-variance-of-a-coin-toss">
     Example: Variance of a coin toss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#properties-of-the-variance">
     Properties of the variance
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Discrete Random Variables</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-spaces">
   Probability spaces
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-mathematical-definition-of-a-random-variable">
   The mathematical definition of a random variable
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-1-2">
     Example: The random variable corresponding to the result of a coin toss (1/2)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-probability-mass-function">
   The probability mass function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#properties-of-the-probability-mass-function">
     Properties of the probability mass function
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-2-2">
     Example: The random variable corresponding to the result of a coin toss (2/2)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#functions-of-discrete-random-variables">
   Functions of discrete random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#expectation-of-random-variables">
   Expectation of random variables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-expectation-of-a-coin-toss">
     Example: Expectation of a coin toss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#properties-of-the-expectation">
     Properties of the expectation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#variance-of-random-variables">
   Variance of random variables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-variance-of-a-coin-toss">
     Example: Variance of a coin toss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#properties-of-the-variance">
     Properties of the variance
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="discrete-random-variables">
<h1>Discrete Random Variables<a class="headerlink" href="#discrete-random-variables" title="Permalink to this headline">¶</a></h1>
<div class="section" id="probability-spaces">
<h2>Probability spaces<a class="headerlink" href="#probability-spaces" title="Permalink to this headline">¶</a></h2>
<p>In whatever we write below, everything is conditioned on our current information <span class="math notranslate nohighlight">\(I\)</span>.
Because this information is always on the background, we will not be explictily showing it in our notation.</p>
<p>Assume that we are doing an experiment.
It doesn’t matter what exactly the experiment is.
The result of the experiment depends on the values of some physical variables <span class="math notranslate nohighlight">\(\omega\)</span> which may be unknown to us (epistemic uncertainty) or truly random (aleatory uncertainty).
In the language of mathematical probability theory, this <span class="math notranslate nohighlight">\(\omega\)</span> is called an <strong>event</strong>.
The space of all possible <span class="math notranslate nohighlight">\(\omega\)</span>’s, denoted by <span class="math notranslate nohighlight">\(\Omega\)</span>, is called the <strong>event space</strong>.
For today, assume that <span class="math notranslate nohighlight">\(\Omega\)</span> is a discrete space (otherwise things become a little bit more complicated).</p>
<p>Since, we are uncertain about which <span class="math notranslate nohighlight">\(\omega\)</span> will appear in nature, we need to assign probabilities over the possible values.
Ideally, what we would like to have is some function <span class="math notranslate nohighlight">\(\mathbb{P}(A)\)</span> that takes an arbitrary subset <span class="math notranslate nohighlight">\(A\)</span> of <span class="math notranslate nohighlight">\(\Omega\)</span> and tells us how probable it is.
That is <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> is a function from all subsets of <span class="math notranslate nohighlight">\(\Omega\)</span>, <span class="math notranslate nohighlight">\(\mathcal{F} = \mathcal{P}(\Omega)\)</span>, to the real numbers:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}: \mathcal{F} \rightarrow \mathbb{R},
\]</div>
<p>There are a few things that this function should satisfy for all <span class="math notranslate nohighlight">\(A\)</span> in <span class="math notranslate nohighlight">\(\mathcal{F}\)</span></p>
<ul class="simple">
<li><p>It should be nonnegative, i.e., <span class="math notranslate nohighlight">\(\mathbb{P}(A)\ge 0\)</span>.</p></li>
<li><p>One of the <span class="math notranslate nohighlight">\(\omega\)</span>’s must happen, <span class="math notranslate nohighlight">\(\mathbb{P}(\Omega) = 1\)</span>.</p></li>
<li><p>The obvious rule <span class="math notranslate nohighlight">\(\mathbb{P}(A^c) = 1 - \mathbb{P}(A)\)</span>, where <span class="math notranslate nohighlight">\(A^c = \Omega\setminus A\)</span> is the complement of <span class="math notranslate nohighlight">\(A\)</span>.
When these properties are satisfied, we say that <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> is a probability measure on <span class="math notranslate nohighlight">\(\mathcal{F}\)</span>.</p></li>
</ul>
<p>The triplet <span class="math notranslate nohighlight">\((\Omega, \mathcal{F}, \mathbb{P})\)</span> is called a <strong>probability space</strong>.</p>
<p>Note: If we wanted to show the background information we would be writting <span class="math notranslate nohighlight">\(\mathbb{P}[A|I]\)</span>.</p>
</div>
<div class="section" id="the-mathematical-definition-of-a-random-variable">
<h2>The mathematical definition of a random variable<a class="headerlink" href="#the-mathematical-definition-of-a-random-variable" title="Permalink to this headline">¶</a></h2>
<p>Now assume that we are doing a specific experiment that measures something, say an integer.
Assume that the physical variables that determine what is the result of the experiment are <span class="math notranslate nohighlight">\(\omega\)</span> and they take values in a set <span class="math notranslate nohighlight">\(\Omega\)</span>.
We are uncertain about the <span class="math notranslate nohighlight">\(\omega\)</span>’s and we have described this uncertainty using a probability measure <span class="math notranslate nohighlight">\(\mathbb{P}\)</span> on some subsets <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> of <span class="math notranslate nohighlight">\(\Omega\)</span>.
Call <span class="math notranslate nohighlight">\(X\)</span> the result of the experiment.
The graph is as follows:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graphviz</span> <span class="kn">import</span> <span class="n">Digraph</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">(</span><span class="s1">&#39;omega_X&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;omega&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;&lt;&amp;omega;&gt;&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;omega&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">g</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">&#39;omega_X&#39;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">)</span>
<span class="n">g</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/reading-03_1_0.svg" src="../_images/reading-03_1_0.svg" /></div>
</div>
<p>This brings us to the mathematical definition of a random variable:</p>
<blockquote>
<div><p>A random variable is a function of the event space <span class="math notranslate nohighlight">\(X(\omega)\)</span>.</p>
</div></blockquote>
<p>Note: if the event space is not discrete, we need some more restrictions on these functions.
You need to take a probability theory course to learn about the technical details.</p>
<p>Now, if <span class="math notranslate nohighlight">\(X(\omega)\)</span> takes discrete values, like heads or tails, <span class="math notranslate nohighlight">\(0, 1, 2\)</span>, etc., then we say that <span class="math notranslate nohighlight">\(X\)</span> is a discrete random variable.
If <span class="math notranslate nohighlight">\(X(\omega)\)</span> takes continuous values, like real numbers, then we say that <span class="math notranslate nohighlight">\(X\)</span> is a continuous random variables.
Today, we are only going to work with discrete random variables.</p>
<p>Notation:</p>
<ul class="simple">
<li><p>We will be using upper case letters to represent random variables, like <span class="math notranslate nohighlight">\(X, Y, Z\)</span>.</p></li>
<li><p>We will be using lower case letters to represent the values of random variables, like <span class="math notranslate nohighlight">\(x, y, z\)</span>.</p></li>
</ul>
<div class="section" id="example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-1-2">
<h3>Example: The random variable corresponding to the result of a coin toss (1/2)<a class="headerlink" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-1-2" title="Permalink to this headline">¶</a></h3>
<p>Let’s consider again the coin tossing example we introduced in the previous lecture.
Remember that we denoted with <span class="math notranslate nohighlight">\(v_0\)</span> and <span class="math notranslate nohighlight">\(\omega_0\)</span> the initial velocity and angular velocity of the coin.
Then, we showed that the variable <span class="math notranslate nohighlight">\(X\)</span> representing the coin toss can be predicted exactly, if we knew <span class="math notranslate nohighlight">\(v_0\)</span> and <span class="math notranslate nohighlight">\(\omega_0\)</span>.
Specifically, we derived the following relationship between the result of the coin toss and the initial conditions:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X = 
\begin{cases}
T,&amp;\;\text{if}\;\frac{2v_0\omega_0}{g} (\text{mod}\;2\pi) \in \left(\frac{\pi}{2},\frac{3\pi}{2}\right),\\
H,&amp;\;\text{otherwise}.
\end{cases}
\end{split}\]</div>
<p>Graphically, this relationship can be represented by:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gct</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">(</span><span class="s1">&#39;coin_toss_g&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;omega0&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;&lt;&amp;omega;&lt;sub&gt;0&lt;/sub&gt;&gt;&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;&lt;v&lt;sub&gt;0&lt;/sub&gt;&gt;&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">&#39;filled&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;v0&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;omega0&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">)</span>
<span class="n">gct</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">&#39;coin_toss_g&#39;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">)</span>
<span class="n">gct</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/reading-03_3_0.svg" src="../_images/reading-03_3_0.svg" /></div>
</div>
<p>Then, we argued that the uncertainty about the value of <span class="math notranslate nohighlight">\(X\)</span> is induced by our uncertainty about the values of <span class="math notranslate nohighlight">\(v_0\)</span> and <span class="math notranslate nohighlight">\(\omega_0\)</span>.
It is not that the coin toss is random.
It is described in extreme detail by Newton’s laws.
It is that we do not know what the initial conditions are.
So, the state of nature is captured by <span class="math notranslate nohighlight">\((v_0,\omega_0)\)</span>.
Notice that essentially the variable <span class="math notranslate nohighlight">\(X\)</span> is a function of <span class="math notranslate nohighlight">\((v_0,\omega_0)\)</span>.
We can write:</p>
<div class="math notranslate nohighlight">
\[
X = X(v_0, \omega_0).
\]</div>
<p>You see that the result of the coin toss <span class="math notranslate nohighlight">\(X\)</span> is nothing more but a function of the <em>true state of nature</em> <span class="math notranslate nohighlight">\((v_0, \omega_0)\)</span>.
It is just that the value of <span class="math notranslate nohighlight">\(X\)</span> is uncertain because the state of nature is uncertain.
<span class="math notranslate nohighlight">\(X\)</span> is an example of a random variable.</p>
</div>
</div>
<div class="section" id="the-probability-mass-function">
<h2>The probability mass function<a class="headerlink" href="#the-probability-mass-function" title="Permalink to this headline">¶</a></h2>
<p>Take a discrete random variable <span class="math notranslate nohighlight">\(X\)</span> defined on some probability space <span class="math notranslate nohighlight">\((\Omega, \mathcal{F}, \mathbb{P})\)</span>.
Without loss of generality, assume that <span class="math notranslate nohighlight">\(X\)</span> can potentially take infinite <span class="math notranslate nohighlight">\(\mathbb{N} = \{1,2,\dots\}\)</span>.
Why is this sufficient?</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(X\)</span> takes finite values then we can simply set the probability of values after a given number equal to zero.</p></li>
<li><p>If the values are of another type (e.g., heads and tails) you can just map them to the natural numbers.</p></li>
</ul>
<p>The probability mass function of the random variable <span class="math notranslate nohighlight">\(X\)</span>, denoted by <span class="math notranslate nohighlight">\(f_X(x)\)</span>, gives the probability of <span class="math notranslate nohighlight">\(X\)</span> taking the value <span class="math notranslate nohighlight">\(x\)</span>.
Mathematically, it is defined by:</p>
<div class="math notranslate nohighlight">
\[
f_X(x) := \mathbb{P}(X=x) = \mathbb{P}\left(\{\omega: X(\omega) = x\}\right).
\]</div>
<p>Notice that we are just gathering in a set all the states of nature <span class="math notranslate nohighlight">\(\omega\)</span> that give an experiment with value <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(X=k\)</span>, and then we find probability of that set.</p>
<p>If you are 100% sure about which random variable you are talking about,
feel free to use the much simpler notation:</p>
<div class="math notranslate nohighlight">
\[
p(x) \equiv p(X=x) \equiv f_X(x) = \mathbb{P}\left(\{\omega: X(\omega) = x\}\right).
\]</div>
<p>This is the notation we will employ from this point on.
We will only use the strict mathematical notation when we have no choice.</p>
<p>Note: If we wanted to show the background information we would be writing <span class="math notranslate nohighlight">\(p(x|I)\)</span>.</p>
<div class="section" id="properties-of-the-probability-mass-function">
<h3>Properties of the probability mass function<a class="headerlink" href="#properties-of-the-probability-mass-function" title="Permalink to this headline">¶</a></h3>
<p>There are some standard properties of the probability mass function that is worth memorizing:</p>
<ul class="simple">
<li><p>The probability mass function is nonnegative:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p(x) \ge 0,
\]</div>
<p>for all <span class="math notranslate nohighlight">\(x\)</span> in <span class="math notranslate nohighlight">\(\mathbb{N}\)</span>.</p>
<ul class="simple">
<li><p>The probability mass function is normalized:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\sum_{x=0}^\infty p(x) = 1.
\]</div>
<p>This is a direct consequence of the fact that <span class="math notranslate nohighlight">\(X\)</span> must take a value.</p>
<ul class="simple">
<li><p>Take any set of possible values of <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(A\)</span>. The probability of <span class="math notranslate nohighlight">\(X\)</span> taking values in <span class="math notranslate nohighlight">\(A\)</span> is:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p(X\in A) = \sum_{x\in A} p(x).
\]</div>
</div>
<div class="section" id="example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-2-2">
<h3>Example: The random variable corresponding to the result of a coin toss (2/2)<a class="headerlink" href="#example-the-random-variable-corresponding-to-the-result-of-a-coin-toss-2-2" title="Permalink to this headline">¶</a></h3>
<p>Let’s write down the probability mass function of the coin toss random variable <span class="math notranslate nohighlight">\(X\)</span>.
Without loss of generality, we can map heads to the number <span class="math notranslate nohighlight">\(0\)</span> and tails to the number <span class="math notranslate nohighlight">\(1\)</span>.
We need to specify the probability of one of these events, as the probability of the other one is trivially defined.
For a fair coin we have:</p>
<div class="math notranslate nohighlight">
\[
p(X=0) = \text{probability of heads} = \frac{1}{2}.
\]</div>
<p>From this, because of the normalization constraint:</p>
<div class="math notranslate nohighlight">
\[
p(X=0) + p(X=1) = 1,
\]</div>
<p>we get that:</p>
<div class="math notranslate nohighlight">
\[
p(X=1) = \frac{1}{2}.
\]</div>
<p>This is an example of a special random variable taking two discrete values <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>, which we call the Bernoulli random variable.
We will see it in an example later on.</p>
</div>
</div>
<div class="section" id="functions-of-discrete-random-variables">
<h2>Functions of discrete random variables<a class="headerlink" href="#functions-of-discrete-random-variables" title="Permalink to this headline">¶</a></h2>
<p>Consider a random variable <span class="math notranslate nohighlight">\(X\)</span> taking values in <span class="math notranslate nohighlight">\(\mathbb{N}\)</span> with probability mass function <span class="math notranslate nohighlight">\(p(x)\)</span>.
Now, consider a function <span class="math notranslate nohighlight">\(g(x)\)</span>.
We can now define a new random variable:</p>
<div class="math notranslate nohighlight">
\[
Y = g(X).
\]</div>
<p>The this random variable takes values in:</p>
<div class="math notranslate nohighlight">
\[
g(\mathbb{N}) := \{g(x): x \in \mathbb{N}\}.
\]</div>
<p>It has its own probability mass function (pmf) which we can define using the pmf of <span class="math notranslate nohighlight">\(X\)</span>:</p>
<div class="math notranslate nohighlight">
\[
p(y) = p(Y = y) = p(X\in g^{-1}(y)) = \sum_{x\in g^{-1}(y)} p(x),
\]</div>
<p>where <span class="math notranslate nohighlight">\(g^{-1}(y)\)</span> is the set of <span class="math notranslate nohighlight">\(x\)</span>’s that map to <span class="math notranslate nohighlight">\(y\)</span> through <span class="math notranslate nohighlight">\(g\)</span>, i.e.,</p>
<div class="math notranslate nohighlight">
\[
g^{-1}(y) := \{x\in\mathbb{N}: g(x) = y\}.
\]</div>
<p>This is formal definition of the uncertainty propagation problem.
The correspondence is that <span class="math notranslate nohighlight">\(X\)</span> represents the parameters of a physical model, and <span class="math notranslate nohighlight">\(Y = g(X)\)</span> is the uncertain result of the physical model.</p>
</div>
<div class="section" id="expectation-of-random-variables">
<h2>Expectation of random variables<a class="headerlink" href="#expectation-of-random-variables" title="Permalink to this headline">¶</a></h2>
<p>The expectation of a random variable is defined to be:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[X] = \sum_{x=0}^\infty x p(x).
\]</div>
<p>You can think of the expectation as the value of the random variable that one should “expect” to get.
However, take this interpretation with a grain of salt because it may be a value that the random variable has a zero probability of getting…</p>
<div class="section" id="example-expectation-of-a-coin-toss">
<h3>Example: Expectation of a coin toss<a class="headerlink" href="#example-expectation-of-a-coin-toss" title="Permalink to this headline">¶</a></h3>
<p>The expectation of the coin toss random variable is:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[X] = 0\cdot p(X=0) + 1\cdot p(X=1) = 0.5.
\]</div>
<p>Of course, this is not a value that the random variable can get.</p>
</div>
<div class="section" id="properties-of-the-expectation">
<h3>Properties of the expectation<a class="headerlink" href="#properties-of-the-expectation" title="Permalink to this headline">¶</a></h3>
<p>Here are some properties of the expectation.
The proof of some of these properties will be given as homework.</p>
<ul class="simple">
<li><p>Take any constant <span class="math notranslate nohighlight">\(c\)</span>. Then we have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[X + c] = \mathbb{E}[X] + c.
\]</div>
<ul class="simple">
<li><p>For any <span class="math notranslate nohighlight">\(\lambda\)</span> real number, we also have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[\lambda X] = \lambda \mathbb{E}[X].
\]</div>
<ul class="simple">
<li><p>Take two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. Then we have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[X + Y] = \mathbb{E}[X] + \mathbb{E}[Y].
\]</div>
<ul class="simple">
<li><p>Now consider any function <span class="math notranslate nohighlight">\(g(x)\)</span>.
We can now define the expectation of <span class="math notranslate nohighlight">\(g(X)\)</span> as the expectation of the random variable <span class="math notranslate nohighlight">\(Y = g(X)\)</span>.
It is quite easy to show that:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[g(X)] = \sum_{x=0}^\infty g(x) p(x).
\]</div>
<ul class="simple">
<li><p>Assume that <span class="math notranslate nohighlight">\(g(x)\)</span> is a convex function, then:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
g\left(\mathbb{E}[X]\right) \le \mathbb{E}[g(X)].
\]</div>
<p>This is known as Jensen’s inequality.</p>
</div>
</div>
<div class="section" id="variance-of-random-variables">
<h2>Variance of random variables<a class="headerlink" href="#variance-of-random-variables" title="Permalink to this headline">¶</a></h2>
<p>The variance of a random variable <span class="math notranslate nohighlight">\(X\)</span> is defined as the expectation of the square deviation from its expectation, i.e.:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[X] := \mathbb{E}\left[(X - \mathbb{E}[X])^2\right].
\]</div>
<p>You can think of the variance as the spread of the random variable around its expectation.
However, do not take this too literally for discrete random variables.</p>
<div class="section" id="example-variance-of-a-coin-toss">
<h3>Example: Variance of a coin toss<a class="headerlink" href="#example-variance-of-a-coin-toss" title="Permalink to this headline">¶</a></h3>
<p>Let’s calculate the variance of the coin toss.
We need:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}\left[X^2\right] = 0^2\cdot p(X=0) + 1^2 \cdot p(X=1) = 0.5.
\]</div>
<p>So, using the formula above we get:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[X] = \mathbb{E}\left[X^2\right] - \left(\mathbb{E}[X]\right)^2 = 0.5 - (0.5)^2 = 0.5 - 0.25 = 0.25.
\]</div>
</div>
<div class="section" id="properties-of-the-variance">
<h3>Properties of the variance<a class="headerlink" href="#properties-of-the-variance" title="Permalink to this headline">¶</a></h3>
<p>Here are some properties of the variance.</p>
<ul class="simple">
<li><p>It holds that:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[X] = \mathbb{E}\left[X^2\right] - \left(\mathbb{E}[X]\right)^2.
\]</div>
<ul class="simple">
<li><p>For any constant <span class="math notranslate nohighlight">\(c\)</span>, we have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[X + c] = \mathbb{V}[X].
\]</div>
<ul class="simple">
<li><p>For any constant <span class="math notranslate nohighlight">\(c\)</span>, we have:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathbb{V}[cX] = c^2\mathbb{V}[X].
\]</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lecture03"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Lecture 3 - Discrete Random Variables</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="hands-on-03.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Discrete Random Variables in Python</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Ilias Bilionis (ibilion[at]purdue.edu)<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>