{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Topics in Bayesian Linear Regression\n",
    "\n",
    "## Probabilistic regression IV (The evidence approximation)\n",
    "\n",
    "Using Bayesian linear regression, we could quantify epistemic uncertainty induced by limited data.\n",
    "The method was quite powerful, but we had to pick the precision $\\alpha$ of the weights, the measurement noise variance $\\sigma^2$ by hand, or any basis function parameters such as the lengthscale $\\ell$ of the radial basis functions.\n",
    "The *evidence approximation* enables us to identify these parameters using the data.\n",
    "\n",
    "Typically, we call all these parameters **hyper-parameters** of the model.\n",
    "For convenience, let us denote all the hyper-parameters by $\\theta$:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta} = \\{\\sigma, \\alpha, \\ell,\\dots\\}.\n",
    "$$\n",
    "\n",
    "Like before, our model is:\n",
    "\n",
    "$$\n",
    "y(\\mathbf{x};\\mathbf{w}) = \\sum_{j=1}^{m} w_{j}\\phi_{j}(\\mathbf{x}) = \\mathbf{w^{T}\\boldsymbol{\\phi}(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "with data likelihood:\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_{1:n} | \\mathbf{x}_{1:n}, \\mathbf{w}, \\boldsymbol{\\theta} \\sim p(\\mathbf{y}_{1:n}|\\mathbf{x}_{1:n}, \\mathbf{w}, \\boldsymbol{\\theta}).\n",
    "$$\n",
    "\n",
    "The prior of the weights is:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} | \\boldsymbol{\\theta} \\sim p(\\mathbf{w}| \\boldsymbol{\\theta}).\n",
    "$$\n",
    "\n",
    "However, we now have to add a *hyper-prior*:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta} \\sim p(\\boldsymbol{\\theta}).\n",
    "$$\n",
    "\n",
    "Graphically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n",
       " -->\n",
       "<!-- Title: full_bayes_regression_2 Pages: 1 -->\n",
       "<svg width=\"206pt\" height=\"227pt\"\n",
       " viewBox=\"0.00 0.00 206.00 227.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 223)\">\n",
       "<title>full_bayes_regression_2</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-223 202,-223 202,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"64,-8 64,-155 134,-155 134,-8 64,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">j=1,...,n</text>\n",
       "</g>\n",
       "<!-- alpha -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>alpha</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-201\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"23\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">α</text>\n",
       "</g>\n",
       "<!-- w -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>w</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"22\" y=\"-126.3\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">w</text>\n",
       "</g>\n",
       "<!-- alpha&#45;&gt;w -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>alpha&#45;&gt;w</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-182.7C27,-174.98 27,-165.71 27,-157.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-157.1 27,-147.1 23.5,-157.1 30.5,-157.1\"/>\n",
       "</g>\n",
       "<!-- yj -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>yj</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"99\" cy=\"-57\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"93.5\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "<text text-anchor=\"start\" x=\"100.5\" y=\"-54.3\" font-family=\"Times,serif\" baseline-shift=\"sub\" font-size=\"14.00\">j</text>\n",
       "</g>\n",
       "<!-- w&#45;&gt;yj -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>w&#45;&gt;yj</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M41.57,-113.83C51.75,-103.94 65.52,-90.55 77.03,-79.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.47,-81.87 84.2,-72.38 74.59,-76.85 79.47,-81.87\"/>\n",
       "</g>\n",
       "<!-- sigma -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>sigma</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"167\" y=\"-125.3\" font-family=\"Times,serif\" font-size=\"14.00\">σ</text>\n",
       "</g>\n",
       "<!-- sigma&#45;&gt;yj -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>sigma&#45;&gt;yj</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.43,-113.83C146.25,-103.94 132.48,-90.55 120.97,-79.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.41,-76.85 113.8,-72.38 118.53,-81.87 123.41,-76.85\"/>\n",
       "</g>\n",
       "<!-- xj -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>xj</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"99\" cy=\"-129\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"93.5\" y=\"-126.3\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">x</text>\n",
       "<text text-anchor=\"start\" x=\"100.5\" y=\"-126.3\" font-family=\"Times,serif\" baseline-shift=\"sub\" font-size=\"14.00\">j</text>\n",
       "</g>\n",
       "<!-- xj&#45;&gt;yj -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>xj&#45;&gt;yj</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-110.7C99,-102.98 99,-93.71 99,-85.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-85.1 99,-75.1 95.5,-85.1 102.5,-85.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x104992d90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np",
    "import scipy.stats as st",
    "from graphviz import Digraph",
    "g2 = Digraph('full_bayes_regression_2')",
    "g2.node('alpha', label='<&alpha;>')",
    "g2.node('w', label='<<b>w</b>>')",
    "g2.node('sigma', label='<&sigma;>')",
    "with g2.subgraph(name='cluster_0') as sg:",
    "    sg.node('xj', label='<<b>x</b><sub>j</sub>>', style='filled')",
    "    sg.node('yj', label='<y<sub>j</sub>>', style='filled')",
    "    sg.attr(label='j=1,...,n')",
    "    sg.attr(labelloc='b')",
    "g2.edge('alpha', 'w')",
    "g2.edge('sigma', 'yj')",
    "g2.edge('w', 'yj')",
    "g2.edge('xj', 'yj')",
    "g2.render('full_bayes_regression_2', format='png')",
    "g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now $\\alpha$ and $\\sigma$ are not shaded because we do not fix them.\n",
    "\n",
    "If we wanted to be fully Bayesian, we would write down the posterior of everything:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{w}, \\boldsymbol{\\theta}|\\mathbf{x}_{1:n}, \\mathbf{y}_{1:n}) \\propto p(\\mathbf{y}_{1:n}|\\mathbf{x}_{1:n}|\\mathbf{w},\\boldsymbol{\\theta})p(\\mathbf{w}|\\boldsymbol{\\theta})p(\\boldsymbol{\\theta}).\n",
    "$$\n",
    "\n",
    "and, somehow, sample from it. We have yet to learn how to do this.\n",
    "We will do it in [](lecture27) and [](lecture28).\n",
    "Here, we will develop an approximation to fully Bayesian inference.\n",
    "\n",
    "### The Evidence Approximation\n",
    "Look at the marginal posterior of $\\boldsymbol{\\theta}$:\n",
    "\n",
    "$$\n",
    "p(\\boldsymbol{\\theta}|\\mathbf{x}_{1:n}, \\mathbf{y}_{1:n}) \\propto \n",
    "\\int p(\\mathbf{y}_{1:n}|\\mathbf{x}_{1:n}|\\mathbf{w},\\boldsymbol{\\theta})p(\\mathbf{w}|\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})d\\mathbf{w}.\n",
    "$$\n",
    "\n",
    "Assume that the hyper-prior is relatively flat:\n",
    "\n",
    "$$\n",
    "p(\\boldsymbol{\\theta}) \\propto 1.\n",
    "$$\n",
    "\n",
    "Then use a maximum a posteriori estimate for $\\boldsymbol{\\theta}$:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta}_{\\text{EV}} = \\arg\\max_{\\boldsymbol{\\theta}}\\int p(\\mathbf{y}_{1:n}|\\mathbf{x}_{1:n}|\\mathbf{w},\\boldsymbol{\\theta})p(\\mathbf{w}|\\boldsymbol{\\theta})d\\mathbf{w}.\n",
    "$$\n",
    "\n",
    "The nice thing is that the right-hand side's integral is analytically available for Gaussian likelihood and prior.\n",
    "What we did is called the *evidence approximation* of the hyper-parameters.\n",
    "\n",
    "### Examples\n",
    "\n",
    "See [this example](evidence_approximation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic regression V (Automatic relevance determination)\n",
    "\n",
    "The evidence approximation gave us a way to estimate the hyperparameters.\n",
    "We now look at the problem of determining which basis functions to keep and which not.\n",
    "The idea is to use a different precision $\\alpha_i$ for each weight.\n",
    "That is, the prior of the weight $w_j$ corresponding to the basis function $\\phi_i(\\mathbf{x})$ is: \n",
    "\n",
    "$$\n",
    "p(w_i | \\alpha_i) \\propto \\exp\\left\\{-\\alpha_iw_i^2\\right\\}.\n",
    "$$\n",
    "\n",
    "Graphically, the model is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n",
       " -->\n",
       "<!-- Title: full_bayes_regression_3 Pages: 1 -->\n",
       "<svg width=\"228pt\" height=\"246pt\"\n",
       " viewBox=\"0.00 0.00 228.00 246.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 242)\">\n",
       "<title>full_bayes_regression_3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-242 224,-242 224,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"64,-8 64,-158 134,-158 134,-8 64,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-15.8\" font-family=\"Times,serif\" font-size=\"14.00\">j=1,...,n</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"142,-83 142,-230 212,-230 212,-83 142,-83\"/>\n",
       "<text text-anchor=\"middle\" x=\"177\" y=\"-90.8\" font-family=\"Times,serif\" font-size=\"14.00\">i=1,...,m</text>\n",
       "</g>\n",
       "<!-- sigma -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>sigma</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-132\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"23\" y=\"-128.3\" font-family=\"Times,serif\" font-size=\"14.00\">σ</text>\n",
       "</g>\n",
       "<!-- yj -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>yj</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"99\" cy=\"-57\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"93.5\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "<text text-anchor=\"start\" x=\"100.5\" y=\"-54.3\" font-family=\"Times,serif\" baseline-shift=\"sub\" font-size=\"14.00\">j</text>\n",
       "</g>\n",
       "<!-- sigma&#45;&gt;yj -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>sigma&#45;&gt;yj</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.98,-114.66C41.94,-104.76 50.41,-92.29 60,-83 63.06,-80.04 66.51,-77.24 70.07,-74.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"72.08,-77.52 78.44,-69.05 68.18,-71.71 72.08,-77.52\"/>\n",
       "</g>\n",
       "<!-- xj -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>xj</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"99\" cy=\"-132\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"93.5\" y=\"-129.3\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">x</text>\n",
       "<text text-anchor=\"start\" x=\"100.5\" y=\"-129.3\" font-family=\"Times,serif\" baseline-shift=\"sub\" font-size=\"14.00\">j</text>\n",
       "</g>\n",
       "<!-- xj&#45;&gt;yj -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>xj&#45;&gt;yj</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-113.7C99,-105.25 99,-94.87 99,-85.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-85.18 99,-75.18 95.5,-85.18 102.5,-85.18\"/>\n",
       "</g>\n",
       "<!-- alphai -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>alphai</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"177\" cy=\"-204\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"171\" y=\"-201.3\" font-family=\"Times,serif\" font-size=\"14.00\">α</text>\n",
       "<text text-anchor=\"start\" x=\"179\" y=\"-201.3\" font-family=\"Times,serif\" baseline-shift=\"sub\" font-size=\"14.00\">i</text>\n",
       "</g>\n",
       "<!-- wi -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>wi</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"177\" cy=\"-132\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"start\" x=\"170\" y=\"-129.3\" font-family=\"Times,serif\" font-size=\"14.00\">w</text>\n",
       "<text text-anchor=\"start\" x=\"180\" y=\"-129.3\" font-family=\"Times,serif\" baseline-shift=\"sub\" font-size=\"14.00\">i</text>\n",
       "</g>\n",
       "<!-- alphai&#45;&gt;wi -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>alphai&#45;&gt;wi</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M177,-185.7C177,-177.98 177,-168.71 177,-160.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.5,-160.1 177,-150.1 173.5,-160.1 180.5,-160.1\"/>\n",
       "</g>\n",
       "<!-- wi&#45;&gt;yj -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>wi&#45;&gt;yj</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.18,-115.22C158.91,-105.29 148.73,-92.59 138,-83 134.83,-80.17 131.3,-77.44 127.71,-74.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"129.58,-71.93 119.31,-69.31 125.71,-77.76 129.58,-71.93\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x104997d60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g3 = Digraph('full_bayes_regression_3')\n",
    "g3.node('sigma', label='<&sigma;>')\n",
    "with g3.subgraph(name='cluster_0') as sg:\n",
    "    sg.node('xj', label='<<b>x</b><sub>j</sub>>', style='filled')\n",
    "    sg.node('yj', label='<y<sub>j</sub>>', style='filled')\n",
    "    sg.attr(label='j=1,...,n')\n",
    "    sg.attr(labelloc='b')\n",
    "with g3.subgraph(name='cluster_1') as sg:\n",
    "    sg.node('alphai', label='<&alpha;<sub>i</sub>>')\n",
    "    sg.node('wi', label='<w<sub>i</sub>>')\n",
    "    sg.attr(label='i=1,...,m')\n",
    "    sg.attr(labelloc='b')\n",
    "\n",
    "g3.edge('alphai', 'wi')\n",
    "g3.edge('sigma', 'yj')\n",
    "g3.edge('wi', 'yj')\n",
    "g3.edge('xj', 'yj')\n",
    "g3.render('full_bayes_regression_3', format='png')\n",
    "g3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we need advanced techniques to carry out full Bayesian inference.\n",
    "However, we can apply the evidence approximation to find all the hyper-parameters.\n",
    "Now, here is what happens in this kind of model.\n",
    "The precisions of the basis functions that are not needed will automatically become very large. Consequently, the posteriors of the corresponding basis function weights will collapse to a delta function centered at zero.\n",
    "\n",
    "### Examples\n",
    "\n",
    "See [this example](automatic_relevance_determination)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics: How do you know if the fit is good?\n",
    "\n",
    "To objectively test the resulting model we need a *validation dataset* consisting of inputs:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^v_{1:n^v} = \\left(\\mathbf{x}^v_1,\\dots,\\mathbf{x}^v_{n^v}\\right),\n",
    "$$\n",
    "\n",
    "and corresponding, observed outputs:\n",
    "\n",
    "$$\n",
    "\\mathbf{y}^v_{1:n^v} = \\left(y^v_1,\\dots,y^v_{n^v}\\right).\n",
    "$$\n",
    "\n",
    "We will use this validation dataset to define some statistical diagnostics.\n",
    "\n",
    "Statistical diagnostics compare the predictive distribution to the distribution of the validation dataset.\n",
    "Assume that the predictive distribution is a Gaussian (as in all the examples above) with posterior predictive mean $m(\\mathbf{x})$ and posterior predictive variance $\\sigma(\\mathbf{x})$ (including both aleatory and epistemic uncertainty).\n",
    "Then, define the standardized errors:\n",
    "\n",
    "$$\n",
    "e_i = \\frac{y_i^v - m\\left(\\mathbf{x}^v_i\\right)}{\\sigma\\left(\\mathbf{x}^v_i\\right)}.\n",
    "$$\n",
    "\n",
    "If our model is correct, the standardized errors must be distributed as a standard Normal $N(0,1)$.\n",
    "Why?\n",
    "Well, if the model is correct $y_i^v$ must come from $N(m\\left(\\mathbf{x}^v_i\\right), \\sigma^2\\left(\\mathbf{x}^v_i\\right))$.\n",
    "Then it follows that $e_i\\sim N(0,1)$.\n",
    "To see this, consider the expectation:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[e_i] = \\dots = 0,\n",
    "$$\n",
    "\n",
    "and the variance:\n",
    "\n",
    "$$\n",
    "\\mathbb{V}[e_i] = \\dots = 1.\n",
    "$$\n",
    "\n",
    "You can prove these formulas using standard expectation and variance properties.\n",
    "\n",
    "So, to test if the posterior predictive distribution is good, you do this:\n",
    "+ Calculate the standardized errors of a validation dataset\n",
    "+ Compare the standardized errors' empirical statistics to the standard Normal $N(0,1)$ statistics.\n",
    "\n",
    "### Examples\n",
    "\n",
    "See [this example](diagnostic_posterior_predictive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}